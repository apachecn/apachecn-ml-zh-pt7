

# 十五、大平台背景下的规模化 H2O

在前一章中，我们通过介绍 H2O AI 云拓宽了我们对 H2O **机器学习** ( **ML** )技术的看法，这是一个由多个模型构建引擎组成的**端到端** ML 平台，一个用于模型部署、监控和管理的 MLOps 平台，一个用于重用和操作模型功能的功能库，以及一个用于构建**人工智能** ( **的低代码**软件开发套件** ( **SDK** )这本书的重点是我们所说的**大规模 H2O**，或使用 H2O 核心(H2O-3 和苏打水)在大规模数据集上构建准确可信的模型，H2O 企业蒸汽管理 H2O 核心用户及其环境，以及 H2O MOJO 轻松灵活地将模型部署到不同的目标环境。我们了解到，这些 H2O 规模的组件原本是更大的 H2O 人工智能云平台的一部分，尽管它们可以单独部署。**

在这一章中，我们将探讨作为 H2O 人工智能云平台的一员，H2O 如何实现更大的能力。更具体地说，我们将涵盖以下主题:

*   H2O 人工智能云快速回顾
*   探索大规模 H2O 基线参考解决方案
*   探索 H2O 大规模发展的新可能性
*   作为企业人工智能集成架构的参考 H2O Wave 应用

# 技术要求

这个链接将带你开始开发 H2O 波应用:[https://wave.h2o.ai/docs/installation](https://wave.h2o.ai/docs/installation)。H2O 波是开源的，可以在你的本地机器上开发。为了全面熟悉 H2O 人工智能云平台，你可以在 https://h2o.ai/freetrial[报名参加为期 90 天的 H2O 人工智能云试用。](https://h2o.ai/freetrial)

# H2O 人工智能云快速回顾

本章的目标是探索作为本书重点的大规模 H2O 如何在用作 H2O 人工智能云平台的一部分时获得新的功能。让我们首先通过重温下图来快速回顾一下 H2O 人工智能云，这是我们在上一章中遇到的:

![ Figure 14.1 – Components of the H2O AI Cloud platform
](img/B16721_14_001.jpg)

图 14.1-H2O 人工智能云平台的组件

作为一个快速的总结，我们看到 H2O 人工智能云有四个专门的建模引擎。H2O 核心(H2O-3，H2O 苏打水)代表 H2O 分布式 ML 用于在大规模数据集上建立水平比例模型。在这种情况下，H2O 企业 Steam 代表了一个管理和提供建模引擎的更通用的工具。

我们在看到，从 H2O 核心模型构建导出的 H2O MOJO 可以直接部署到 H2O MLOps 模型部署、监控和管理平台(尽管如此，正如在 [*第 10 章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178) 、 *H2O 模型部署模式*中所看到的，MOJO 也可以公开部署到其他目标)。请注意，H2O 专门的**自动 ML** ( **AutoML** )引擎称为无人驾驶 AI 也可以产生 MOJO，并可以按照 [*第 10 章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178) 、 *H2O 模型部署模式*所示的方式部署。我们还看到，H2O 人工智能特征库可用于在模型构建和模型部署环境中共享和操作特征。

最后，我们看到 H2O Wave SDK 可用于在 H2O 人工智能云平台的其他组件上构建人工智能应用，然后作为平台的一部分发布到 H2O 应用商店。

现在，让我们开始将这些碎片组合成各种 H2O 规模的解决方案。

# 探索大规模 H2O 基线参考解决方案

因此，现在让我们来探索 H2O 规模的组件如何从参与 H2O 人工智能云平台中受益。为此，让我们首先从 H2O 人工智能云之外的 H2O 规模的基线解决方案开始。基线解决方案如下图所示。我们将使用此基准来比较大规模 H2O 与人工智能云组件相集成的解决方案:

![Figure 14.2 – Baseline solution for H2O at scale
](img/B16721_14_002.jpg)

图 14.2–大规模 H2O 基线解决方案

重要说明

对于本章中的这个解决方案和所有解决方案，假设数据科学家使用 H2O 企业 Steam 来启动 H2O-3 或 H2O 苏打水环境。请参见 [*第 3 章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042) 、*基础工作流-数据到可部署模型*，了解该步骤的概述。

其解决方案流程的快速概述如下:

1.  数据科学家导入一个大型数据集，并使用它来构建大规模的 ML 模型。参见*第二部分*、*中的章节，使用 H2O* 在大数据量上构建最先进的模型，深入探讨这个主题。
2.  运营团队将模型工件(称为 H2O MOJO)部署到评分环境中。参见 [*第十章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178) 、 *H2O 模式部署模式*，探讨 H2O 模式部署的多种目标系统。
3.  预测由业务环境中的软件或工具消费和执行。(这里，我们假设部署的模型是一个**监督学习**模型，尽管它可能是一个生成非预测输出的非监督模型；例如，输入的聚类成员)。

让我们使用这一基线解决方案开始添加 H2O 人工智能云组件，从而了解 H2O 如何通过成为这一更大平台的成员来获得额外的功能。

# 探索 H2O 规模化的新可能性

现在，让我们一步一步地了解我们可以大规模集成 H2O(这本书的重点)与 H2O 人工智能云平台的其余部分的不同方式，从而实现更大的能力和价值。

## 利用 H2O 无人驾驶人工智能进行原型开发和功能发现

H2O 的 AutoML 无人驾驶人工智能组件是一个高度自动化的模型构建工具，它使用(除其他功能外)遗传算法、人工智能试探法和彻底自动化的**特征工程**来构建准确和可解释的模型——通常在几个小时内——然后部署到生产系统。然而，无人驾驶人工智能无法在 H2O-3 和苏打水处理的数百 GB 到 TBs 大小的数据集上进行训练。

然而，对于数据科学家来说，将这些大规模数据集中的采样数据提供给无人驾驶人工智能，然后使用 AutoML 工具来(a)快速建立模型原型以获得早期理解，以及(b)发现有助于精确模型的自动工程特征，否则很难从纯手动和领域知识手段中找到这些特征，这是非常有用的。在这个工作流程中，从无人驾驶人工智能中获得的知识随后被用作起点，使用 H2O-3 或苏打水，根据原始未采样数据建立大规模模型。

下图显示了这一点，并对其进行了总结:

![Figure 14.3 – Leveraging H2O Driverless AI for prototyping and feature discovery
](img/B16721_14_003.jpg)

图 14.3–利用 H2O 无人驾驶人工智能进行原型开发和功能发现

这里提供了利用无人驾驶人工智能快速原型化和发现大规模模型构建特征的工作流程步骤:

1.  将大容量数据集导入大规模 H2O 环境中固有的分布式内存架构。使用 H2O-3 `split_frame`方法(此处为 Python 语言)将导入的数据采样成一个更小的子集(通常为 10 到 100 GB ),并将适当的比率定义为输入参数，以获得所需的样本大小。将输出写入无人驾驶 AI 可以访问的暂存位置。
2.  将采样数据集导入无人驾驶 AI。使用默认值快速建立精确模型的原型。根据您的领域和数据科学经验，使用不同的设置继续进行原型设计。探索模型的解释技巧。探索对模型贡献最大的工程特征。使用**自动化模型文档** ( **AutoDoc** )来更深入地理解模型，并将工程特征的名称翻译成它们底层的数学和逻辑表示。
3.  使用来自*步骤 2* 的知识来指导你在 H2O-3 或苏打水上建立完整的大规模数据集的模型。

无人驾驶 AI 在 [*第十三章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241) ，*介绍 H2O AI 云*中有概述。下面的屏幕截图显示了一个朝着最终精确模型迭代的实验:

![Figure 14.4 – Driverless AI finding an accurate model
](img/B16721_14_004.jpg)

图 14.4-无人驾驶人工智能寻找精确的模型

注意*图 14.4* 的左下面板，它显示了遗传算法在模型间迭代的进度。每个方块都是一个独立的 ML 模型。这些模型中的每一个都使用一个自动选择的算法(例如，XGBoost**光线渐变增强模型**(**Light GBM**)；**广义线性模型** ( **GLM** ))，探索极广的超参数空间(例如，学习率、树深度、树数量等的组合)。

重要的是，由遗传算法构建的每个模型还探索了从原始导入数据集中设计的极其广泛的特征空间。实验将在最终的最佳模型上停止，通常是前面的顶级模型的堆叠集合。用户可以在短时间内运行许多实验，通过改变许多高级和低级设置并评估结果来进行探索。

从这些快速探索中获得的知识，包括对最终模型很重要的特征工程，可以用作用 H2O-3 或苏打水按比例建立模型的起点。

注意，对于较小的数据集，无人驾驶 AI 在短时间内找到高度预测的模型是相当有效的。然而，H2O-3 和苏打水是扩展到大规模数据集或采取更可控的基于代码的方法来建立模型所必需的。如此处所示，对于基于代码的方法，首先用无人驾驶人工智能原型化一个问题，然后使用由此产生的见解和设计的功能作为基于代码的方法的指南是有价值的。

无人驾驶人工智能(AutoML)与 H2O-3 (DistributedML):何时使用哪个？

无人驾驶 AI 是 H2O AI Cloud 的一个高度自动化的**用户界面** ( **UI** )(或**应用编程接口**(**API**))AutoML 组件，旨在快速找到准确可信的模型进行生产评分。当您需要高度自动化的方法(具有广泛的用户控制)来构建模型时，以及当数据集大小小于 100 GB 时(尽管更多资源密集型服务器实例可以处理更大的数据集)，可以使用它。

当您的数据集大于 100 GB(并进入 TBs)时，使用 H2O-3 或苏打水，或者当您想要更多地控制模型构建过程时，使用基于代码的方法来构建模型。请注意，H2O-3 和苏打水具有 AutoML 功能，如第五章 、*高级模型构建-第一部分*中所述，但无人驾驶 AI 中的那些要复杂得多，广泛得多，自动化程度也高得多。

使用无人驾驶人工智能来原型化一个问题，并利用由此产生的见解和工程特征的发现来指导你在 H2O-3 或苏打水上建立模型。

我们已经看到了我们的第一个 H2O 比例模型建筑的例子，它通过与 H2O 人工智能云平台中的一个组件进行交互来获得能力。现在让我们看看下一个例子。

## 集成 H2O MLOps 进行模型监控、管理和治理

用 H2O-3 和苏打水制作的模型产生了他们自己的随时可以部署的低延迟评分神器，称为 H2O MOJO。正如我们在 [*第十章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178) 、 *H2O 模型部署模式*中所展示的，这个评分工件可以部署到各种各样的生产系统中，从来自**代表性状态转移** ( **REST** )服务器的实时评分，到来自数据库的批量评分，再到来自流队列的评分(仅举几个例子)。在那一章中，我们还展示了部署到 REST 服务器提供了一个有用的集成模式，用于将评分预测集成到常见的**商业智能** ( **BI** )工具中，如 Microsoft Excel 或 Tableau。

H2O 人工智能云的 H2O MLOps 组件是部署 H2O-3 或苏打水模型(或无人驾驶人工智能模型和非 H2O 模型——例如，scikit-learn 模型)的绝佳选择。集成非常简单，如下图所示:

![Figure 14.5 – Deployment of H2O-at-scale models to the H2O MLOps platform
](img/B16721_14_005.jpg)

图 14.5-H2O 比例模型在 H2O MLOps 平台上的部署

集成这些模型的步骤非常简单，如下所示:

1.  用 H2O-3 或苏打水建立你的模型，然后输出 MOJO 进行部署。
2.  在 H2O MLOps 中，从 UI 或 MLOps API 部署暂存 MOJO。回想一下 [*第十三章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241) ，*介绍 H2O AI 云，*有很多部署选项，包括实时对批量，单个模型对冠军/挑战者，或者 A/B 测试。
3.  现在可以从一个唯一的 REST 端点对模型进行评分。带有可选原因代码的预测已经准备好供您的系统使用，无论是 web 应用、BI 工具等等。

对于此流程期间和之后的所有模型，MLOps 执行重要的任务，包括监控、管理和治理模型。例如，以下屏幕截图显示了 H2O MLOps 的数据漂移监控屏幕:

![Figure 14.6 – Model-monitoring screen for H2O MLOps
](img/B16721_14_006.jpg)

图 14.6–H2O m lops 的模型监控屏幕

监控数据漂移的目的是检测实时评分数据中的特征值分布是否偏离了用于构建模型的训练数据中的特征值分布。数据漂移的存在表明或指示该模型应该用更近的数据重新训练，然后重新部署以与当前评分数据一致。

在*图 14.6* 的左下面板中，所有模型特征的数据漂移以两个维度表示:垂直轴上的漂移和水平轴上的特征重要性。该视图允许将漂移划分为漂移重要性象限，高漂移和高特性重要性是最重要的漂移。有多种设置可用于定义漂移统计、测量的时间范围以及观察漂移的其他方面。还有一个工作流程来配置漂移的自动警报消息。这些既可用于数据科学家手动决定是否重新训练模型，也可用于通过 H2O API 进行全自动模型重新训练和部署的。

漂移检测只是 H2O MLOps 的功能之一。请参见 https://docs.h2o.ai/mlops/[的 H2O 文档，了解 H2O MLOps 模型部署、监控、管理和治理功能的完整描述。](https://docs.h2o.ai/mlops/)

现在让我们看看 H2O-3 和苏打水是如何融入 H2O 人工智能特色商店的。

## 利用 H2O 人工智能特征库实现特征操作化和重用

企业通常通过在整个组织内集中和共享环境或资产来实现规模经济。H2O 人工智能特征库通过工程管道集中模型特征及其管理的可操作性来实现规模经济，以便在整个组织中重用。

通过特征库的重用发生在模型构建和模型评分上下文中。例如，假设整个组织的一个有价值的特征是资产价格与前一天相比的百分比变化。但是，想象一下，资产价格存储为每日价格，并且资产价格存储在多个源系统中。特征存储处理来自源系统的特征的检索和来自原始系统的新值的计算(即特征工程管道),并缓存结果(工程特征)以共享用于模型训练和模型评分。模型构建使用离线模式，即批量历史数据，并使用在线模式进行模型评分，即最近的数据。如下图所示:

![Figure 14.7 – Integration of H2O AI Feature Store with H2O-3 or Sparkling Water
](img/B16721_14_007.jpg)

图 14.7–H2O 人工智能特色商店与 H2O-3 或苏打水的整合

下面是图 14.7 中的*工作流程总结:*

1.  数据科学家建立一个模型。
2.  在模型构建阶段，数据科学家可能会以两种不同的方式与要素存储进行交互，如下所述:
    *   数据科学家可以将要素发布到要素存储中，并包含相关元数据以帮助其他人进行搜索和操作。ML 工程师操作来自数据源的特征的工程，以在特征存储中提供特征值。每个功能都配置了更新前的生存时间，例如，每分钟、每天或每月更新一次。
    *   数据科学家可能会在模型构建期间搜索特征存储中的特征。他们使用功能存储 API 将功能及其值导入到 H2O-3 或苏打水加载的训练数据中(更具体地说，导入到内存中的 H2OFrame，类似于 DataFrame)。
3.  该模型被部署到 H2O MLOps，该 MLOps 被配置为使用来自功能存储的功能。该功能会按照配置的时间间隔进行更新。
4.  消耗预测和可选的原因代码。

我们已结束工作流，预测已被使用。现在，让我们展示数据科学家和 ML 工程师如何使用 H2O Wave SDK 快速构建具有复杂可视化和围绕模型预测的工作流的 AI 应用。

## 来自 Wave AI 应用的商业环境中的消费预测

当 ML 模型的输出被角色或自动化执行工作流消费时，它们最终获得价值。这些工作流可以基于单个预测和潜在的原因代码本身，或者基于从中获得的见解和情报。例如，客户服务代表识别出很有可能离开企业的客户，并根据模型预测可能流失的原因，主动向他们提出改进或激励措施，以留住客户。或者，分析师探索过去 6 个月中做出的客户流失预测的多个交互式仪表板，以深入了解客户流失的原因，并确定业务可以改进的地方以防止客户流失。

正如我们在 [*第 13 章*](B16721_13_Final_SK_ePub.xhtml#_idTextAnchor241) 、*介绍 H2O 人工智能云*中了解到的，H2O Wave 是一款低代码 SDK，数据科学家和 ML 工程师使用它来轻松构建人工智能应用，并将其发布到应用商店供企业或外部使用。我们所说的人工智能应用是什么意思？这里的 AI 应用是一个 web 应用，它将 ML 生命周期的一个或多个阶段呈现为丰富的可视化、用户交互和工作流序列。H2O Wave SDK 通过将 UI 元素(仪表板模板、对话框和小部件)公开为基于属性的 Python 代码，同时抽象出构建 web 应用的复杂性，使这些易于构建。

在我们的例子中，业务角色专门使用 Wave 应用来进行消费预测，如下图所示。请注意，我们的下一个例子将是一个 Wave 应用，数据科学家使用它来管理模型再训练，而不是消耗预测:

![Figure 14.8 – Prediction consumption in Wave AI applications
](img/B16721_14_008.jpg)

图 14.8–Wave 人工智能应用中的预测消耗

图 14.8 中的 ML 工作流是一个熟悉的工作流，但是有一个 Wave 应用来消耗预测。Wave 的低代码 SDK 支持多种集成协议，因此允许从 REST 端点实时使用预测和原因代码，或者从文件上传或数据仓库连接批量使用。如上图所示，从业务上下文来看，使用预测的 Wave 应用可以执行以下操作:

*   从历史和单个预测视图中可视化预测
*   从全局(模型级别)和单个(单一模型评分)视图中可视化潜在预测原因代码的洞察力
*   对预测和见解进行商业智能分析
*   在循环中为人类执行工作流，以进行可视化和分析

我们来看一个具体的例子。下面的屏幕截图显示了 Wave 应用的一个页面，该页面使用并显示员工流失预测的可视化效果，换句话说，就是员工离开公司的预测可能性:

![Figure 14.9 – A Wave app visualizing employee churn
](img/B16721_14_009.jpg)

图 14.9–可视化员工流失的 Wave 应用

这个页面显示了最新一批员工流失预测的视图。左上角的面板显示了这些预测的概率分布。我们可以看到，被模型评分的大多数员工离开的概率都很低，尽管有一个长尾巴的高概率员工。右上方的面板提供了员工离开公司的原因:它显示了 Shapley 值或特征对预测的贡献(原因代码)。我们看到加班、工作角色和轮班时间表是影响模型预测流失的三大因素。底部的面板显示了帮助更好地理解这些预测的可视化效果:左边的面板显示了流失可能性的地理分布，右边的面板显示了按工作角色的细分。地图上方的薄面板允许用户交互，从而滑块定义将员工分类为流失或不流失的概率阈值:结果底部的两个面板相应地刷新。

Wave 应用的前一个屏幕截图显示了批量级别的预测，即一段时间内所有员工的得分。该应用还有一个页面，显示个人级别的可视化预测。当用户点击单个员工(显示相关的流失概率和其他员工数据)时，会显示 Shapley 值，显示导致该员工流失的可能性最大的特征。例如，一个特定的个人可能显示月收入是对预测的较大贡献，加班实际上是对个人*而不是*的贡献。这种观点表明，员工可能会离开公司，因为他们没有赚到足够的钱，并试图赚更多。这使得员工的经理可以评估加薪情况，以帮助保证他们留在公司。

*图 14.9* 中的用户界面显示了商业环境中的预测，个人可以据此采取行动。请记住，H2O 波是非常可扩展的，可以将您喜欢的 Python 包，包括 Python APIs，合并到非 H2O 组件中。此外，请记住，这里显示的示例 Wave 应用是一个功能演示器:它不是管理员工流失的现成解决方案，而是数据科学家和 ML 工程师如何使用 Wave SDK 轻松构建人工智能应用的一个示例。

H2O Wave SDK 是非常可扩展的

图 14.9 中的用户界面相当简单，但仍然可以有效地将预测放入商业和分析环境中。H2O Wave SDK 是非常可扩展的，因此允许在基于它构建的应用中包含更高级别的功能。

例如，你可以实现 HTML **级联样式表** ( **CSS** )来给**用户体验** ( **UX** )一个更现代或者公司特有的外观。因为 Wave 应用是容器化的，彼此隔离，所以可以安装任何 Python 包，并在应用中使用。例如，你可以实现**散景**来实现强大的交互式可视化，或者**熊猫**来实现数据操作，或者一个供应商或自己开发的 Python API 来与你的技术生态系统的一部分进行交互。

请注意，H2O Wave 的主要意图是让你用它的 SDK 构建自己的人工智能应用，并使它们为你的需要而专门构建。应用在本地开发，可以由目标用户快速原型化，然后定稿、润色并发布到 H2O 应用商店，供企业基于角色的消费。然而，H2O 将为您提供示例应用作为代码加速器。

你可以在[https://h2o.ai/freetrial/](https://h2o.ai/freetrial/)注册 90 天免费试用 H2O 人工智能云，探索 live Wave 应用。你也可以通过访问[https://wave.h2o.ai/](https://wave.h2o.ai/)来探索和使用 H2O Wave SDK，它是开源的。

我们刚刚探索了如何构建 Wave 应用，以将预测作为业务分析和决策工作流程的一部分。企业用户不必是唯一的 Wave 应用用户。现在让我们来看一个 Wave 应用，它由数据科学家使用，用于驱动 ML 生命周期的模型构建和模型部署阶段。

## 在 Wave AI 应用中集成自动化再训练管道

H2O Wave SDK 包括其他 H2O 人工智能云组件的原生 API。这允许数据科学家构建 Wave 应用来完成数据科学工作流(与在业务用户环境中构建应用相比，如前面的示例所示)。

例如，数据科学中的一个常见需求是识别已部署模型中的数据漂移，然后用最近的数据重新训练模型，并重新部署更新后的模型。下图显示了如何使用 Wave 应用作为自动化协调器和用户界面来跟踪再训练的历史并对历史进行分析。这是一个应用的想法，可以有不同的定义，但总的想法应该是有帮助的。

在这里，您可以看到完整 ML 工作流程的概述:

![Figure 14.10 – A Wave app for automated model retraining 
](img/B16721_14_010.jpg)

图 14.10-自动化模型再训练的 Wave 应用

工作流程总结如下:

1.  该模型是在 H2O-3 或苏打水(或其他 H2O 模型构建引擎，如无人驾驶 AI)中构建和评估的。
2.  该模型被部署到 H2O MLOps，并且预测被使用。MLOps 配置为检测模型上的数据漂移。
3.  在某个时间点，漂移超过了模型的配置阈值，就会向您构建的模型再训练 Wave 应用发送警报。
4.  模型再训练 Wave 应用在 H2O 模型构建引擎上触发模型的再训练(在我们的例子中，H2O-3 或苏打水)。Wave 应用将重新训练的模型部署为 H2O MLOps 中的挑战者(使用 MLOps API)，一段时间后，Wave 应用评估新重新训练的挑战者与现有冠军模型的性能。如果挑战者的表现优于冠军，他就会被提升来代替冠军。循环(*步骤 3 和 4* )从这一点继续。

模型再训练 Wave 应用可以提供关于模型再训练的报告、可视化和分析。例如，可以有一个再训练历史表，包括再训练时间、漂移测量、当前状态(例如，训练进行中、部署的模型、处于挑战者状态或冠军状态)等等。可以提供可视化，提供对数据漂移、模型再训练和部署管道的更深入的了解。作为替代方案，自动化可以被人在回路中的工作流所取代，在这种工作流中，管道中的步骤是基于数据科学家的评估手动完成的。

作为一个应用构建框架，H2O Wave 的目标是让你根据自己的规范轻松构建应用，并将生态系统中的其他组件集成到应用中。因此，您可能会想到一个与这里所示略有不同的模型再训练应用。H2O Wave SDK 允许你构建你预想的应用。

在我们的示例模型再训练应用中，我们将多个 H2O 组件集成到一个具有可视化和分析功能的 Wave 应用工作流中。在下一节中，我们将把集成扩展到你的生态系统的非 H2O 组件，从而提供一个强大的框架，以在你的人工智能生态系统中构建 Wave 应用。

# 作为企业人工智能集成架构的参考 H2O Wave 应用

低代码 Wave SDK 允许数据科学家、ML 工程师和软件开发人员构建应用，将参与 ML 生命周期的一个或多个 H2O 组件集成到单个应用中。因此，H2O 浪潮是一个强大的整合故事。

然而，有两个 Wave 设计事实需要重新审视，因为它们使得这个集成故事更加强大。首先，Wave 应用部署在容器中，因此与其他 Wave 应用隔离。其次，开发人员可以将公开可用或专有的 Python 包和 API 安装并集成到应用中。这意味着 H2O Wave 应用可以将 H2O 和非 H2O 的组件集成到一个应用中。这可以有效地重申如下:H2O 应用可以作为单一窗格构建在整个人工智能相关的企业生态系统中。如下图所示:

![Figure 14.11 – H2O Wave AI app as a layer across your enterprise ecosystem
](img/B16721_14_011.jpg)

图 14.11–H2O Wave AI 应用作为一个层跨越您的企业生态系统

数据科学家、工程师和软件开发人员因此可以构建 Wave 应用，将 H2O 人工智能云的端到端 ML 平台与企业生态系统及其底层云服务的人工智能相关和非人工智能相关组件相结合。多样化的应用托管在 H2O 应用商店，具有基于角色的访问权限，因此可供多样化的企业利益相关者消费者使用。让我们通过研究下图来进一步分解这一点。

![Figure 14.12 – Reference H2O Wave AI app layering across your enterprise ecosystem
](img/B16721_14_012.jpg)

图 14.12–参考 H2O Wave AI 应用在整个企业生态系统中的分层

这是一款参考 H2O Wave 人工智能应用，展示了其作为整个人工智能相关生态系统的 UI 集成层的全部潜力。我们的目标是展示这方面的全套功能，并让您发挥想象力，将这一通用参考实例化到适合您特定 AI 需求的特定应用中。

让我们回顾一下这些功能，如下所示:

*   **低代码 Python SDK** : Wave 的低代码 Python SDK 允许数据科学家、ML 工程师和软件开发人员以熟悉的 Python 风格开发 AI 应用，专注于在小部件和模板中填充数据，忽略 web 应用的复杂性。如果需要，可以用 CSS 样式表扩展 SDK，以实现特定的外观。
*   **数据连接器**:Wave SDK 有超过 140 个连接器连接到不同的数据源和目标，这使得将 Wave 应用集成到您的数据生态系统变得非常容易。
*   **H2O 人工智能云 API**:Wave SDK 拥有 H2O 人工智能云平台中所有组件的 API:四个模型构建引擎及其供应工具，以及 MLOps 和 Feature Store 组件。从应用的角度来看，这些集成提供了与 ML 生命周期的所有方面进行交互的强大方法。我们已经在前面讨论的评分消费和模型再训练 Wave 应用中快速浏览了这些可能性。
*   **已安装的 Python 包**:Wave SDK 可扩展到您想要安装的任何 Python 包。例如，这允许您使用更专业的绘图或交互式可视化功能来扩展本机 Wave UI 组件，或者使用熟悉的包来操作数据。
*   **已安装的 Python API**:您还可以安装 Python 库，作为企业生态系统其余部分的 API，无论是您自己的组件、非 H2O 供应商的组件，还是应用和原生云服务。这是一种非常强大的方式来编排由连接到 H2O 人工智能云组件的 API 驱动的 ML 工作流，以及您企业生态系统其余部分的功能。

刚刚概述的功能和集成为 Wave 应用实现企业人工智能分析和工作流开辟了近乎无限的途径。例如，您可以将 H2O MLOps 上的模型部署和监控集成到现有的多步骤治理流程工作流中。您可以构建用户界面工作流，让用户在数据目录中搜索授权的数据源，选择数据源，然后启动并访问加载了数据源的 H2O 模型构建环境。这只是让你开始思考的两个例子。如图*图 14.11* 所示，您可以用自己独特而有创意的方式将许多部分结合在一起，将 ML 扩展到模型构建和评分之外，并扩展到更大的工作流和多利益相关方商业价值的环境中。

# 总结

在本章中，我们探讨了 H2O 规模技术公司(H2O-3、H2O 苏打水、H2O 企业蒸汽和 H2O MOJO)如何通过参与更大的 H2O 人工智能云端到端机器学习 ML 平台来扩展其能力。例如，我们看到了 H2O-3 和苏打水是如何从最初的快速原型制作和自动特征发现中获益的。同样，我们看到了 H2O-3 和苏打水模型如何轻松部署到 H2O MLOps 平台，并从其模型评分、监控和管理功能中获得价值。我们还看到了 H2O 人工智能功能商店如何实现功能共享，包括使用 H2O-3 或苏打水建立模型以及在 H2O MLOps 上进行模型评分。

我们开始探索 H2O 开源低代码 Wave SDK 的强大功能，以及数据科学家、ML 工程师和软件开发人员如何使用它来轻松创建跨 H2O 组件的可视化、分析和工作流，从而实现完整的 ML 生命周期。这些应用被发布到 H2O 平台的应用商店组件，在那里它们被企业利益相关者或外部合作伙伴或企业的客户消费。我们开发的一个 Wave 应用示例是一个员工流失应用，用于消费、理解和响应关于个人离开公司的可能性的预测。另一个是模型再训练应用，数据科学家通过利用 Wave 应用的底层 SDK 与 H2O-3 和 H2O MLOps 的集成来管理和跟踪自动化模型再训练工作负载。

最后，我们引入了一个参考 Wave 人工智能应用来构建跨 H2O 和非 H2O 企业人工智能生态系统部分的应用，从而形成一个企业人工智能集成结构。

因此，我们通过将 H2O 的人工智能规模化，并将其置于 H2O 更大的端到端机器学习人工智能平台 H2O 人工智能云的背景下，完成了这本书。通过将其成熟和成熟的 H2O at scale 技术与快速创新的 H2O 人工智能云平台相结合，H2O.ai 继续证明自己是定义和创造企业新的人工智能可能性和价值的前沿参与者。