

# 三、基础工作流程——数据到可部署模型

在这一章中，我们将为 H2O 按比例创建一个最小的模型。我们将称之为*基本工作流程*，因为它忽略了构建准确、可信模型的广泛功能和用户选择，但仍然触及了主要步骤。

基本工作流程将作为建立您对 H2O 技术和编码步骤理解的基础，以便在本书的下一部分中，您可以完全投入到构建最先进模型的高级技术中。

为了开发基本的工作流程，我们将在本章中讨论以下主要主题:

*   用例及数据概述
*   基本工作流程
*   变化点——基本工作流程的替代和扩展

# 技术要求

在本章中，我们将重点介绍如何使用 Enterprise Steam 在企业服务器集群上启动 H2O 集群。从技术上讲，启动 H2O 集群并不需要 Enterprise Steam，但是企业利益相关方通常会将 Enterprise Steam 视为在企业环境中实现 H2O 的安全、治理和管理员要求。

Enterprise Steam 需要从 H2O.ai 购买许可证。如果您的组织没有安装 Enterprise Steam 的实例，您可以通过更大的 H2O 平台的临时试用许可证来访问 Enterprise Steam 和企业服务器集群。或者，为了便于进行本书中的练习，您可能希望在您的本地环境中(例如，在您的笔记本或桌面工作站上)启动 H2O 集群作为沙箱，并绕过企业级 Steam 的使用。

请参见 [*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)*–本书启动 H2O 集群的替代方法*以帮助您决定如何启动 H2O 集群来完成本书中的练习，以及如何设置您的环境来完成此操作。

企业蒸汽:企业环境与书中的编码练习

企业利益相关者通常将企业 Steam 视为在企业环境中实现 H2O 的安全、治理和管理员需求。本章展示了数据科学家如何在这个企业环境中使用企业 Steam。然而，Enterprise Steam 需要一个 H2O.ai 许可证才能实现，并且不会向本书的所有读者提供。

一个简单的沙盒(非企业)体验是在您的本地环境(笔记本或工作站)上专门使用 H2O，这不需要企业级 Steam。后续章节中的编码练习将利用本地沙盒环境，但也可以使用本章中演示的 Enterprise Steam 来执行。

请注意，使用和不使用 Enterprise Steam 的 data scientist 工作流之间的区别仅限于工作流的第一步(启动 H2O 集群),我们将在本章的稍后部分对此进行详细介绍。参见 [*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)*——启动 H2O 集群的替代方法*。

# 用例及数据概述

为了演示基本工作流，我们将实现一个二元分类问题，在这里我们预测贷款是否违约的可能性。我们在本章中使用的数据集可以在[https://github . com/packt publishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt 3/loans-lite . CSV](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt3/loans-lite.csv)中找到。(这是简化版的 Kaggle *借贷俱乐部贷款*数据集:[https://www . ka ggle . com/imsparsh/Lending-Club-Loan-dataset-2007-2011](https://www.kaggle.com/imsparsh/lending-club-loan-dataset-2007-2011)。)

我们使用数据集的简化版本来简化本章中的工作流程。在*第 2 部分，构建最先进的大规模模型*中，我们将在原始贷款数据集上使用高级 H2O 模型构建功能开发此用例。

# 基本工作流程

我们的基本工作流程将通过以下步骤进行:

1.  启动 H2O 集群(企业 Steam UI)
2.  连接到 H2O 集群(从现在开始就是您的 IDE)
3.  构建模型
4.  评估和解释模型
5.  为生产部署导出模型
6.  关闭 H2O·克鲁斯号

## 步骤 1–启动 H2O 集群

这个步骤是从企业 Steam 用户界面完成的。您将选择是需要 H2O-3 集群还是苏打水集群，然后配置 H2O 集群的行为，例如超时和终止前的空闲时间，以及是否要在终止时保存状态，以便可以重新启动集群并从停止的地方开始(这必须由管理员启用)。很好，Enterprise Steam 会根据您的数据大小自动调整 H2O 集群的大小(节点数量、每个节点的内存、CPU)。

### 登录到 Steam

打开一个网络浏览器并转到`https://steam-url:9555/login`并登录到企业 Steam，其中`steam-url`是您的特定 Steam 实例的 URL。(您的管理员可能已经更改了端口号，但通常是 URL 中显示的`9555`。)

### 为 H2O-3(对比苏打水)集群选择 H2O

在这里，我们将启动 H2O-3 集群(而不是苏打水，我们将在本书的下一部分中进行)，因此单击左侧面板中的 **H2O** 链接，然后单击**启动新集群**。

### 配置 H2O-3 集群

这个将我们带到下面的表单，您将配置它:

![Figure 3.1 – UI to launch an H2O-3 cluster on Kubernetes
](img/B16721_03_01.jpg)

图 3.1–在 Kubernetes 上启动 H2O-3 集群的用户界面

现在，我们将忽略大多数配置。这些将在 [*第 11 章*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207) 、*管理员和操作视图*中更全面地介绍，其中详细概述了企业 Steam。请注意，配置页面使用术语 *H2O 星团*来具体表示 H2O-3 星团，而在本书中，我们使用术语 H2O 星团来表示 H2O-3 或苏打水星团。

关于“配置 H2O-3 集群”屏幕截图的说明

根据 H2O 集群是在 Kubernetes 环境还是在基于 YARN 的 Hadoop 或 Spark 环境中启动，图 3.1 中显示的屏幕细节会有所不同。根据 H2O 星团是 H2O-3 星团还是苏打水星团，细节也会有所不同。然而，在所有情况下，H2O 集群大小(节点数量、每个节点的 CPU/GPU 和每个节点的内存)和最大空闲/正常运行时间的基本概念始终是通用的。

为您的集群命名，对于**数据集参数**，单击**设置参数**出现以下弹出窗口:

![Figure 3.2 – Popup to automatically size the H2O-3 cluster
](img/B16721_03_02.jpg)

图 3.2–自动调整 H2O-3 集群大小的弹出窗口

Enterprise Steam 使用这里的输入来自动调整 H2O 集群的大小(也就是说，确定 H2O 节点的数量、为每个节点分配的内存以及为每个节点分配的 CPU)。回想一下前一章中介绍的 H2O 集群的*关键概念*。

### 短暂等待集群启动

UI 中的**状态**字段将显示**开始**，表示 H2O 集群正在企业服务器集群上启动。这需要一两分钟。当状态变为**正在运行**时，您的 H2O 集群就可以使用了。

### 查看集群的详细信息

让我们首先通过点击**动作**和**细节**来了解一些关于集群的事情。这将生成一个描述集群的弹出窗口。

请注意，在这种情况下，节点的**数量为 **6** ，每个节点**的**内存为 **48 GB** ，这是由 Enterprise Steam 针对 50 GB 的数据集大小自动调整的，如图*图 3.1* 所示。回想一下上一章的 *H2O 关键概念*部分，我们的数据集被分区并分布在企业服务器集群上的这个数量的 H2O 集群节点的内存中，并且计算是在这些 H2O 节点上并行完成的。**

关于 H2O 集群规模的说明

一般来说，H2O 集群的大小是这样确定的，即分配给该集群的总内存(即每个节点的 *N* H2O 节点和 *X* GB 内存的乘积)大约是将用于建模的未压缩数据集大小的 5 倍。该计算最大限度地减少了节点数量(即节点越少，每个节点的内存越多越好)。

Enterprise Steam 将根据您对数据集的描述来计算这一规模，但是您也可以通过 Enterprise Steam UI 自己调整集群的规模。当 H2O 集群终止时，分配给 H2O 集群的总内存将被释放。

请注意，企业 Steam 管理员设置用户在启动 H2O 集群时可能拥有的最小和最大配置值(请参见*图 3.1* )，从而设置用户可以启动的最大 H2O 集群大小。管理员设置的这些边界可以针对不同的用户进行不同的配置。

## 步骤 2–连接到 H2O 集群

这一步和所有后续步骤都来自您的 IDE。我们将使用 Jupyter 笔记本并用 Python 编写代码(尽管其他选项包括使用您喜欢的 IDE 用 R、Java 或 Scala 编写 H2O)。

打开笔记本，通过编写以下代码连接到您在 Enterprise Steam 中启动的 H2O 集群:

```py
import h2o
```

```py
import h2osteam
```

```py
from h2osteam.clients import H2oKubernetesClient
```

```py
conn = h2osteam.login(url="https://steam-url:9555",
```

```py
                      username="my-steam-username",
```

```py
                      password="my-steam-password")
```

```py
cluster = H2oKubernetesClient().get_cluster("cluster-name")
```

```py
cluster.connect()
```

您现在已经连接到 H2O 集群，可以开始构建模型了。请注意，连接后，您将看到 H2O 集群的详细信息，类似于在启动前配置集群时从 Enterprise Steam UI 中看到的信息。

让我们了解一下代码在做什么:

1.  您引用了从 H2O 下载并在 IDE 环境中实现的`h2osteam`和`h2o` Python 库。(`h2o`库没有被这里显示的代码使用，但是将被随后的模型构建步骤使用。)
2.  然后你通过`h2osteam` API(库)登录到企业 Steam 服务器。您使用了与登录到 Enterprise Steam 的 UI 相同的 URL、用户名和密码。
3.  然后，您通过`h2osteam` API 从 Enterprise Steam 中检索您的 H2O 集群信息。
4.  请注意，这里使用的是`H2oKubernetesClient`,因为您正在连接到一个在 Kubernetes 环境中启动的 H2O 集群。或者，如果您的企业环境是 Hadoop 或 Spark，您可以分别使用`H2oClient`或`SparklingClient`。
5.  You connected to your H2O cluster using `cluster.connect()` and passed the cluster information to the `h2o` API. Note that you did not have to specify any URL to the H2O cluster because Steam returned this behind the scenes with `H2oKubernetesClient().get_cluster("cluster-name")`.

    创建 H2O 沙盒环境

    如果您希望在您的本地机器上创建一个小型 H2O 沙盒，而不是使用企业 Steam 和您的企业服务器集群，只需在您的 IDE 中实现以下两行代码:

    `import h2o`

    `h2o.init()`

    结果与使用 Enterprise Steam 执行*步骤 1–2*相同，除了它在本地机器上启动一个带有一个节点的 H2O 集群并连接到它。

    无论是在企业环境中还是在本地机器上连接到 H2O 集群，现在都可以从 IDE 中针对相应的集群编写相同的建模步骤。对于沙箱，当然，您将被限制到更小的数据量，因为它只有一个低内存节点的集群大小。

## 第 3 步–建立模型

既然我们已经连接到我们的 H2O 集群，现在是时候构建模型了。从现在开始，您将使用`h2o` API 与您启动并连接的 H2O 集群进行通信。

在我们的基本工作流程中，我们将采用最简单的方法来导入数据、清理数据、设计数据中的特征，然后训练模型。

### 导入数据

使用`h2o.import_file`命令将贷款数据集从源加载到 H2O-3 集群存储器，如下所示:

```py
input_csv = "https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt3/loans-lite.csv"
```

```py
loans = h2o.import_file(input_csv)
```

```py
loans.dim
```

```py
loans.head()
```

`loans.dim`行给出了行数和列数，而`loans.head()`显示了前 10 行。目前非常简单的数据探索。

请注意，数据集现在已经分区并分布在 H2O 集群的内存中。从我们在 IDE 中的编码角度来看，它被视为由列和行组成的单一二维数据结构，称为**H2 of frame**。

### 清理数据

让我们执行一个简单的数据清理步骤。目标或响应列称为`bad_loan`，它分别为好贷款和坏贷款保存值 0 或 1。我们需要将该列中的整数转换为分类值，如下所示:

```py
loans["bad_loan"] = loans["bad_loan"].asfactor()
```

### 根据原始数据设计新功能

特征工程通常被认为是构建卓越预测模型的*秘方*。出于我们现在的目的，我们将通过从`issue_d`列中提取年和月作为单独的特征来进行基本的特征工程，该列将日、月和年保存为单个值:

```py
loans["issue_d_year"] = loans["issue_d"].year().asfactor()
```

```py
loans["issue_d_month"] = loans["issue_d"].month().asfactor()
```

我们刚刚在我们的`loans`数据集中创建了两个新的分类列:`issue_d_year`和`issue_d_month`。

### 模型训练

接下来我们将训练一个模型来预测不良贷款。我们首先将数据分成`train`和`test`:

```py
train, validate, test = loans.split_frame(seed=1, ratios=[0.7, 0.15])
```

我们现在需要确定我们将使用哪些列来预测贷款是否是坏账。我们将通过从当前的 loans H2OFrame 中删除两列来实现这一点，这两列保存了经过清理和设计的数据:

```py
predictors = list(loans.col_names)
```

```py
predictors.remove("bad_loan)
```

```py
predictors.remove("issue_d")
```

请注意，我们从用作特性的列中删除了`bad_loan`，因为这是我们所预测的。我们还删除了`issue_d`,因为我们在此基础上设计了新功能，不希望它成为预测器。

接下来，让我们创建一个 XGBoost 模型来预测贷款违约:

```py
from h2o.estimators import H2OXGBoostEstimator
```

```py
param = {
```

```py
         "ntrees" : 20,
```

```py
         "nfolds" : 5,
```

```py
         "seed": 12345
```

```py
}
```

```py
model = H2OXGBoostEstimator(**param)
```

```py
model.train(x = predictors,
```

```py
            y = "bad_loan",
```

```py
            training_frame = train,
```

```py
            validation_frame = validate)
```

## 第 4 步-评估和解释模型

让我们评估一下我们刚刚训练的模型的性能:

```py
perf = model.model_performance(test)
```

```py
perf
```

`perf`的输出显示了模型性能的细节，包括 MSE、Logloss、AUC 等模型指标，以及混淆矩阵、最大指标阈值和增益/提升表。

现在，让我们通过从模型结果中生成变量重要性来查看模型可解释性的一个简单视图:

```py
explain = model.explain(test,include_explanations="varimp")
```

```py
explain
```

`explain`的输出显示了针对测试数据集运行的训练模型的可变重要性。这张表列出了每个特征对模型的贡献有多大。

正如我们将在本书后面看到的，H2O 的模型可解释能力比变量重要性更进一步。

## 步骤 5–导出模型的评分工件

现在，让我们生成并将模型导出为评分工件，该工件可以由 DevOps 小组部署到生产环境中:

```py
model.download_mojo("download-destination-path")
```

当然，在现实世界中，我们会训练许多模型，并比较它们的性能和可解释性，以评估哪个(如果有的话)应该进入生产。

## 步骤 6–关闭集群

当您的工作完成时，关闭 H2O-3 集群以释放它所保留的资源:

```py
h2o.cluster().shutdown()
```

# 变化点——基本工作流程的替代和扩展

我们在这里开发的基本工作流程是一个简单的例子。对于我们执行的每一步，都有多种选择和扩展。所有的*第二部分:建造最先进的大规模模型，*致力于理解这些选择和精心制作，并把它们放在一起建造卓越的大规模模型。

让我们先来看一些关键的变化点。

## 使用企业 Steam API 和 UI 启动 H2O 集群(步骤 1)

在我们的示例中，我们使用企业 Steam UI 的便利性来配置和启动一个 H2O 集群。或者，我们可以使用 IDE 中的 Steam API 来实现这一点。关于 Python API，请参见位于[https://docs . H2O . ai/Enterprise-Steam/latest-stable/docs/Python-docs/index . html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/python-docs/index.html)的完整 H2O 企业 Steam API 文档，关于 R API，请参见[https://docs . H2O . ai/Enterprise-Steam/latest-stable/docs/R-docs/index . html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/r-docs/index.html)。

通过从我们的 IDE 中启动 H2O 集群，我们就可以完全从 IDE 中完成我们工作流的所有步骤 1–6。

## 启动 H2O-3 对比苏打水集群(步骤 1)

在我们的示例中，我们启动了一个 H2O-3 集群。我们也可以推出 H2O 苏打水集群。正如我们将看到的，苏打水集群具有与 H2O-3 集群相同的功能集，但具有将 Spark 代码和 Spark 数据帧与 H2O 代码和 H2O 数据帧集成的额外能力。在 H2O 建立模型之前，利用 Spark 进行高级数据探索和数据管理时，这一点尤为重要。

## 是否实现企业 Steam(步骤 1-2)

要知道，启动和连接到企业服务器集群并不需要 Enterprise Steam :数据科学家可以只使用 IDE 中的`h2o`(而不是`h2osteam` ) API 来配置、启动和连接到企业服务器集群，但这是底层编码和配置，需要详细的集成信息。重要的是，这种方法缺乏可靠的企业安全、治理和集成实践。

在企业设置中，企业 Steam 被视为在企业服务器集群环境中集中、管理和治理 H2O 技术和 H2O 用户的基本要素。这些功能在第 11 章 、*管理员和操作视图*中有详细说明。

## 使用个人访问令牌登录企业 Steam(步骤 2)

对于*步骤 2——连接到 H2O 集群*,我们使用 Enterprise Steam API 从我们的 IDE 向 Enterprise Steam 认证。在示例代码中，我们使用了一个明文密码(该密码与用于登录企业 Steam UI 的密码相同)。例如，如果您共享了笔记本，这是不安全的。

或者，更安全地说，您可以使用一个**个人访问令牌** ( **帕特**)作为企业 Steam 的 API 登录密码。您可以根据需要随时生成 PAT，每个新生成的 PAT 都会撤销前一个 PAT。因此，如果您使用 PAT 作为密码与您的登录凭证共享 Jupyter 笔记本，笔记本的接收者将不会知道您的 Enterprise Steam UI 登录密码，并且无法使用您共享笔记本中已撤销的密码通过 API 进行身份验证。您可以更进一步，将 PAT 实现为 ide 外部的环境变量。

Enterprise Steam 允许您从 UI 生成 PAT。要生成 PAT，请登录企业 Steam UI，单击**配置、**并遵循简短的令牌工作流程。复制结果(一个长字符串)以便在当前笔记本或脚本中使用，或者将其设置为环境变量。

## 构建模型(步骤 3)

H2O 提供了比我们的基本工作流程更强大的建模体验。这种更大的体验在这里有所涉及，并在*第 2 部分,*中进行了充分的探讨。

### 语言和 IDE

我们正在 Jupyter 笔记本上用 Python 写 H2O 代码。您还可以为企业 Steam API 选择 R，并使用您选择的 Python 或 R IDE。此外，您可以使用 H2O 的 UI 丰富的 IDE，称为 **H2O 流**来执行完整的工作流，或者快速了解从您自己的 IDE 进行的 H2O 集群工作流的各个方面。

### 导入数据

数据可以从许多来源导入 H2O 集群，包括云对象存储(例如，S3 或 Azure Delta 湖)、数据库表(通过 JDBC)、HDFS 等等。此外，源文件可以有多种格式，包括拼花、ORC、ARFF 等。

### 清理数据和工程特征

H2O-3 具有基本数据操作的能力(例如，改变列类型、合并或分割行或列、分组、估算等等)。

回想一下，启动 Sparkling Water 集群为我们提供了完整的 H2O-3 功能，以及 Spark 更强大的数据探索和工程功能。

### 模型训练

在我们的基本工作流程中，我们只研究了一种类型的模型(XGBoost ),同时只改变了几个默认参数。H2O-3(及其苏打水扩展)有一个监督和非监督学习算法的广泛列表，以及一系列广泛的参数和超参数来设置您的规格。此外，这些算法可以有力地结合到 AutoML 工作流中，该工作流探索多个模型和超参数空间，并在排名上排列产生的最佳模型。您还可以控制交叉验证技术、检查点、再训练和再现性。

## 评估和解释模型(步骤 4)

H2O 有多种解释方法和局部(个体)和全局(模型级)解释的可视化，包括残差分析、可变重要性热图、Shapley 汇总、**部分依赖图** ( **PDPs** )和**个体条件期望** ( **ICE** )。

## 导出模型的评分工件(步骤 5)

一旦您导出了模型的评分工件(称为 H2O MOJO)，就可以让 DevOps 在实时评分环境中部署和监控了。它可能会进入组织的 CI/CD 流程。我们将在第 3 部分*的这一点上继续学习，将您的模型部署到生产环境*。

## 关闭集群(步骤 6)

您可以从您的 IDE 中关闭您的集群，如我们的示例工作流所示。如果你注意到了，当在 Enterprise Steam 中配置集群时，有两个配置可以自动关闭进程:**最大空闲时间**和**最大正常运行时间**。第一种方法是在群集超过配置的使用时间后关闭群集。第二个选项是在群集运行了配置的时间后关闭群集。关闭集群(手动或自动)可以为使用企业服务器集群的其他人节省资源。

管理员为这些自动终止配置分配最小和最大值。请注意，如果由管理员启用，Enterprise Steam 会在 H2O 集群自动终止时保存所有模型和数据帧。您可以稍后重新启动集群，并从集群终止的地方开始。

# 总结

在本章中，您学习了如何从您的 IDE 启动 H2O 集群并在其上构建模型。这个基本的工作流程只是一个框架，你可以用一套先进的 H2O 模型构建技术来更全面地充实它，我们将在本书的第*部分第 2 部分“按比例构建最先进的模型”中学习这些技术。*

我们将在下一章开始这个高级旅程，在使用这些功能之前先对它们进行概述。