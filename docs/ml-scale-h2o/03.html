<html><head/><body>


	
		<title>B16721_02_Final_SK_ePub</title>
		
	
	
		<div><h1 id="_idParaDest-25"><em class="italic"> <a id="_idTextAnchor024"/>第二章</em>:平台组件和关键概念</h1>
			<p>在这一章中，我们将获得对 H2O 机器学习规模化技术的组件的基本理解。我们将查看 H2O 机器学习的一个简单代码示例，理解它做什么，并识别该示例在企业范围内与机器学习相关的任何问题。这个<em class="italic"> Hello World </em>代码示例将作为一个简单的表示，以进一步加深我们的理解。</p>
			<p>我们将大规模概述机器学习的每个 H2O 组件，确定每个组件如何实现规模，并确定每个组件如何与我们的简单代码片段相关。然后，我们将使用这些组件将这些组件连接到一个参考机器学习工作流中。最后，我们将关注这些组件中的关键概念。本章中获得的理解将是本书其余部分的基础，其中我们将实施 H2O 技术，在企业环境中大规模构建和部署最先进的机器学习模型。</p>
			<p>在本章中，我们将讨论以下主要话题:</p>
			<ul>
				<li>你好世界——H2O 机器学习代码</li>
				<li>大规模 H2O 机器学习的组成部分</li>
				<li>使用这些 H2O 组件的机器学习工作流</li>
				<li>H2O 关键概念</li>
			</ul>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/>技术要求</h1>
			<p>对于这一章，你需要在本地安装 H2O-3 来运行一个最简单的<em class="italic"> Hello World </em>工作流程。要实现它，请遵循<a href="B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268"> <em class="italic">附录</em> </a>中的说明。请注意，我们将在整本书中使用 Python API，所以请按照说明用 Python 安装它。</p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>你好，世界——H2O 机器学习代码</h1>
			<p>H2O 核心是为大规模机器学习而设计的<a id="_idIndexMarker042"/>；但是，它也可以用于用户笔记本电脑上的小型数据集。在下一节中，我们将使用 H2O-3 的最小代码示例来构建机器学习模型，并将其导出为可部署的工件。我们将使用这个示例作为理解 H2O 机器学习代码的最基本单元，就像查看人类简笔画开始学习人类生物学一样。</p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>代码示例</h2>
			<p>看看下面的<a id="_idIndexMarker043"/>代码示例。在这里，我们是用 Python 写的，它可能来自 Jupyter、PyCharm 或另一个 Python 客户端。我们将了解到 R 和 Java/Scala 是编写 H2O 代码的替代语言。</p>
			<p>让我们从导入 H2O 库开始:</p>
			<pre class="source-code">import h2o</pre>
			<p>回想一下文档，这是从 H2O 下载的，并安装在客户端或 IDE 环境中。这个<code>h2o</code>包允许我们使用 Python 编写的 H2O API 从 IDE 中运行 H2O 内存分布式机器学习。</p>
			<p>接下来，我们创建一个 H2O 集群:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>前面的代码行创建了一个叫做<strong class="bold">的 H2O 集群</strong>。这是 H2O 模型构建技术的一个关键概念。它是一种分布式内存架构。在<em class="italic"> Hello World </em>案例中，H2O 集群将作为本地主机创建在笔记本电脑上，并且不会被分发。我们将在本章的<em class="italic"> H2O 关键概念</em>部分了解更多关于 H2O 集群的信息。</p>
			<p>用于启动 H2O 集群的<code>ip</code>和<code>port</code>配置应该提供足够的线索，表明 H2O 代码将通过 API 发送到计算环境，对于企业环境来说，计算环境可以位于数据中心或云中。然而，在这里，它是在我们的本地主机上。</p>
			<p>然后，我们导入一个数据集:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>现在我们探索数据集:</p>
			<pre class="source-code">loans.describe()</pre>
			<p>这是一个<a id="_idIndexMarker045"/>最小量的数据探索。它只是返回行数和列数。</p>
			<p>好了，现在让我们为我们的模型准备数据:</p>
			<pre class="source-code">train, validation = loans.split_frame(ratios=[0.75])</pre>
			<pre class="source-code">label = "bad_loan"</pre>
			<pre class="source-code">predictors = loans.col_names</pre>
			<pre class="source-code">predictors.remove(label)</pre>
			<p>我们将数据分成训练集和验证集，训练集使用<code>0.75</code>比例。我们将预测一笔贷款是否会成为坏账(即，它是否会违约)，并将此列标识为标签。最后，我们通过使用数据集中除不良贷款列之外的所有列来定义用于预测不良贷款的列。</p>
			<p>现在，我们建立模型:</p>
			<pre class="source-code">from h2o.estimators import H2OXGBoostEstimator</pre>
			<pre class="source-code">param = {"ntrees" : 25, "nfolds" : 10}</pre>
			<pre class="source-code">xgboost_model = H2OXGBoostEstimator(**param)</pre>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>我们导入了 H2O 的<strong class="bold"> XGBoost </strong>模块<a id="_idIndexMarker046"/>，并为其配置了两个超参数。然后，我们通过将引用输入到预测器列、标签列、训练数据和测试数据来开始模型训练。</p>
			<p>XGBoost 是<code>h2o</code>模块中众多广为认可和广泛使用的机器学习算法之一。该模块公开的 H2O API 将在企业基础设施上运行 H2O 架构中的 XGBoost 模型，我们将在后面了解到。关于超参数，我们会发现，H2O 提供了一个广泛的超参数集来配置每个模型。</p>
			<p>当模型完成时，我们可以使用一行代码导出模型:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>导出的评分工件现在可以传递给 DevOps 进行部署了。<code>get_genmodel_jar=True</code>参数触发下载包含<code>h2o-genmodel.jar</code>。这是模型用于在 H2O 群集之外(即在生产环境中)评分的库。我们将在<em class="italic">第 3 节-将您的模型部署到生产环境</em>中了解更多关于生产 H2O 模型的信息。</p>
			<p>目前，我们已经完成了模型构建。因此，我们将关闭集群:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>这释放了 H2O 集群一直在使用的资源。</p>
			<p>请记住，这是一个简单的<em class="italic"> Hello World </em> H2O 模型构建示例。它旨在完成以下两项任务:</p>
			<ul>
				<li>简单介绍一下 H2O 模型建筑。</li>
				<li>作为讨论企业中规模问题的基础，我们将在下一节中讨论。</li>
			</ul>
			<p>在<em class="italic">第 2 节——使用 H2O 在大数据量上构建最先进的模型</em>中，我们将探索广泛的技术来构建高度可预测和可解释的大规模模型。让我们从讨论我们的<em class="italic"> Hello World </em>示例暴露的一些规模问题开始我们的旅程。</p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>规模的一些问题</h2>
			<p>这段<a id="_idIndexMarker048"/> <em class="italic"> Hello World </em>代码在企业设置中不会很好地伸缩。让我们重温一下代码，以便更好地理解这些缩放约束。</p>
			<p>我们在 IDE 代码中导入这个库:</p>
			<pre class="source-code">import h2o</pre>
			<p>大多数企业希望对所使用的库的版本有一些控制。此外，他们通常希望提供一个中央平台来托管和验证某项技术的所有用户，并让管理员管理该平台。我们将会发现，Enterprise Steam 在集中管理用户和 H2O 环境方面发挥着关键作用。</p>
			<p>我们初始化 H2O 集群:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>大规模机器学习需要跨服务器集群分布计算资源，以实现水平扩展(即跨许多服务器分而治之地分配计算资源)。因此，IP 地址和端口应该指向服务器群集的一个成员，而不是单个计算机，如本例所示。我们将看到 H2O 核心创建自己的自组织集群，分布和水平扩展模型构建。</p>
			<p>由于扩展是在企业服务器集群上进行的，通常由许多个人和团体使用，企业希望控制用户对该环境的访问以及用户消耗的资源数量。但是，什么会阻止用户启动多个 H2O 集群，在每个集群上使用尽可能多的资源，从而阻止其他用户使用资源呢？Enterprise Steam 管理企业服务器集群上的 H2O 用户和 H2O 资源消耗。</p>
			<p>我们导入数据集:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>大量数据需要非常长的时间在网络上传输，需要几个小时或几天才能完成传输，或者可能会提前超时。大规模建模期间的计算应该在数据驻留的地方进行，以防止数据移动中的这一瓶颈。我们将发现，在企业系统上启动的 H2O 集群将数据从存储层直接接收到服务器内存中。因为数据是跨组成 H2O 集群的服务器进行分区的，所以数据接收与这些分区并行发生。</p>
			<p>我们将看到【Enterprise Steam 如何集中用户认证，以及如何将用户的身份传递给企业系统，在企业系统中实现其本地授权机制。</p>
			<p>我们训练模型:</p>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>当然，这是模型构建过程的核心，同样也是本书大部分内容的重点:如何使用 H2O 广泛的机器学习算法和模型构建能力，针对大量数据构建世界级的机器学习模型。</p>
			<p>我们下载可部署模型:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>请记住，从商业的角度来看，直到模型被导出并部署到产品中，价值才得以实现。这样做涉及到多个企业利益相关者的复杂性。我们将了解导出的<strong class="bold"> MOJO </strong> ( <strong class="bold">模型对象，优化的</strong>)的设计和功能如何使<a id="_idIndexMarker050"/>易于部署到涉及这些利益相关者的不同软件系统。</p>
			<p>我们关闭了 H2O 集群:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>H2O 群集使用资源，不使用时应该关闭。如果不这样做，企业系统上的其他用户或作业可能会争用这些资源，从而受到影响。此外，在必须扩展基础设施之前，可以向系统添加更少的新用户。我们将看到企业级 Steam 控制着 H2O 用户如何使用企业系统上的资源。由此带来的资源效率提升允许 H2O 用户及其工作在给定的基础设施分配上更有效地扩展。</p>
			<p>现在，我们已经运行了我们的<em class="italic"> Hello World </em>示例，并探索了一些关于规模的问题，让我们继续了解用于机器学习模型构建和大规模部署的 H2O 组件。</p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>H2O 机器学习规模化的组成部分</h1>
			<p>正如前一章介绍的和本书强调的，H2O 机器学习克服了规模问题。以下是对大规模 H2O 机器学习的每个组件以及每个组件如何克服这些挑战的简要介绍。</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/> H2O 核心-内存分布式模型构建</h2>
			<p>H2O 核心<a id="_idIndexMarker053"/>允许数据科学家使用众所周知的机器学习算法编写代码来构建<a id="_idIndexMarker054"/>模型。编码体验是通过用 Python、R 或 Java/Scala 语言表达的 H2O API，并在他们最喜欢的客户端或 IDE 中编写，例如 Jupyter 笔记本中的 Python。然而，模型构建的实际计算发生在企业服务器集群(而不是 IDE 环境)上，并利用服务器集群的巨大内存池和 CPU 来针对海量数据运行机器学习算法。</p>
			<p>那么，这是如何工作的呢？首先，用于模型构建的数据由服务器集群上的 H2O 在内存中进行分区和分配。IDE 向服务器群集发送 H2O 指令。集群中的服务器接收这些指令，并将它们分发给集群中的其他服务器。这些指令在分区的内存数据上并行运行。接收指令的服务器收集和组合结果，并将它们发送回 IDE。随着代码在 IDE 中排序，这一过程会重复进行。</p>
			<p>这种<em class="italic">分而治之</em>的方法<a id="_idIndexMarker055"/>是大规模建立 H2O 模型的基础。H2O 分而治之体系结构的一个单元称为 H2O 集群，在本章的后面将作为一个关键概念进行阐述。结果是在大量数据的基础上快速建立模型。</p>
			<h3>H2O 核心的主要特征</h3>
			<p>H2O 核心的一些<a id="_idIndexMarker056"/>关键特性如下:</p>
			<ul>
				<li><strong class="bold">水平缩放</strong>:数据操作<a id="_idIndexMarker057"/>和机器学习算法并行分布在内存中，并有额外的优化，如分布式键/值存储，以在模型构建期间快速访问数据和对象。</li>
				<li><strong class="bold">熟悉的体验</strong>:数据<a id="_idIndexMarker058"/>科学家使用熟悉的语言和 ide 编写 H2O API 代码，就像我们刚刚做的一样。</li>
				<li><strong class="bold">开源</strong> : H2O 核心<a id="_idIndexMarker059"/>开源。</li>
				<li><strong class="bold">多种文件格式</strong> : H2O <a id="_idIndexMarker060"/>支持多种源数据格式。</li>
				<li><strong class="bold">数据操作</strong>:<a id="_idIndexMarker061"/>H2O API 包括广泛的任务，这些任务通常用来为机器学习准备数据。苏打水(将在下一节介绍)将数据工程技术扩展到 Spark。</li>
				<li><strong class="bold">公认的机器学习算法</strong> : H2O 使用广泛的公认的<a id="_idIndexMarker062"/>监督和非监督机器学习算法。</li>
				<li><strong class="bold">培训、测试和评估</strong>:交叉验证、网格搜索、变量<a id="_idIndexMarker063"/>重要性和性能<a id="_idIndexMarker064"/>度量的广泛技术被用于培训、测试和<a id="_idIndexMarker065"/>评估模型；这也包括模型检查点功能。</li>
				<li><strong class="bold">自动机器学习(AutoML)</strong>:H2O 核心 AutoML API 提供了一个<a id="_idIndexMarker066"/>简单的包装器函数，简洁地自动化多个模型的训练和调优，包括堆叠集成，并在排行榜中呈现结果。</li>
				<li><strong class="bold">模型可解释性</strong>:它<a id="_idIndexMarker067"/>为单个模型或 AutoML 中涉及的那些模型提供了广泛的局部和全局可解释性方法和可视化，所有这些都来自单个包装器函数。</li>
				<li><strong class="bold"> AutoDoc </strong> : It <a id="_idIndexMarker068"/>使<a id="_idIndexMarker069"/>能够自动生成标准化的 Word 文档，广泛详细地描述模型构建和可解释性；请注意，AutoDoc 不是免费的开源平台。</li>
				<li><strong class="bold">可导出的评分工件(MOJO) </strong>:它使用一行代码将模型导出为<a id="_idIndexMarker070"/>可部署的评分工件(模型部署将在<em class="italic">第 3 节——将您的模型部署到生产环境</em>中更详细地讨论)。</li>
				<li><strong class="bold"> H2O 流程网络用户界面</strong>:这个<a id="_idIndexMarker071"/>是一个可选的基于网络的交互式用户界面，以一种简单而丰富的点击式体验指导用户完成模型构建工作流程，这对于 H2O 模型的快速实验和原型制作非常有用。</li>
			</ul>
			<h3>H2O-3 和 H2O 苏打水</h3>
			<p>H2O 核心有两种口味:<strong class="bold"> H2O-3 </strong>和<strong class="bold"> H2O 苏打水</strong>。</p>
			<p>H2O-3 是 H2O 核心，如前一节所述。H2O 苏打水是 H2O-3 包装的<a id="_idIndexMarker074"/>通过火花集成。它与 H2O-3 相同，并具有以下附加功能:</p>
			<ul>
				<li><strong class="bold">Spark 和 H2O API 代码无缝集成</strong>:用户在同一个 IDE 中编写 Spark 和 H2O 代码；例如，使用 SparkSQL 代码来设计数据，使用 H2O 代码来构建世界级的模型。</li>
				<li><strong class="bold">H2O 和 Spark 数据帧之间的转换</strong>:作为无缝集成的一部分，H2O 和 Spark 数据帧<a id="_idIndexMarker076"/>相互转换；因此，SparkSQL 数据管理的结果可以作为 H2O 模型建立的输入。</li>
				<li><strong class="bold"> Spark engine </strong>:苏打水作为 Spark 框架上的原生 Spark 应用程序运行。</li>
			</ul>
			<p>H2O-3 和苏打水<a id="_idIndexMarker077"/>是更一般的 H2O 核心的模型建造替代品。在更大的企业服务器集群上推出的 H2O 集群的概念与<a id="_idIndexMarker078"/>和<a id="_idIndexMarker079"/> H2O 核心版本相似，尽管一些实施细节有所不同，这对于数据科学家来说基本上是不可见的。如上所述，苏打水对于整合 Spark 数据工程和 H2O 模型构建工作流特别有用。</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/> H2O 企业 Steam——一个受管的自助供应门户</h2>
			<p>Enterprise Steam <a id="_idIndexMarker080"/>提供了一个集中的 web UI 和<a id="_idIndexMarker081"/> API，供数据科学家初始化和终止他们的 H2O 环境(称为 H2O 集群),并供管理员管理 H2O 用户和 H2O 与企业服务器集群的集成。</p>
			<h3>企业蒸汽的主要特征</h3>
			<p>企业蒸汽的主要特性<a id="_idIndexMarker082"/>如下:</p>
			<ul>
				<li><strong class="bold">数据科学自我调配</strong>:这<a id="_idIndexMarker083"/>是数据科学家管理其 H2O 环境的一种简单、基于 UI 的方式。</li>
				<li><strong class="bold">所有 H2O 用户的中央访问点</strong>:这简化了 H2O 用户管理，并为 H2O 访问企业服务器集群提供了一个<a id="_idIndexMarker084"/>单一入口点。</li>
				<li><strong class="bold">管理用户资源消耗</strong>:管理员建立分配给用户或用户组的资源使用边界<a id="_idIndexMarker085"/>的配置文件。这限制了用户可以在企业服务器集群上分配的资源数量。</li>
				<li><strong class="bold">无缝安全</strong>:用户<a id="_idIndexMarker086"/>认证<a id="_idIndexMarker087"/>到企业级的流通过到企业服务器集群上的资源的授权。Enterprise Steam 根据企业服务器集群使用的同一身份提供者(例如，LDAP)进行身份验证。</li>
				<li><strong class="bold">配置集成</strong>:管理员<a id="_idIndexMarker088"/>配置 H2O 与企业服务器集群和身份提供者的集成。</li>
				<li><strong class="bold">管理 H2O 核心版本</strong>:<a id="_idIndexMarker089"/>管理员管理一个或多个 H2O 核心版本，数据科学家使用这些版本来创建 H2O 集群以进行建模。</li>
			</ul>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>H2O 魔咒——一种灵活、低延迟的得分神器</h2>
			<p>从 H2O 核心构建的<a id="_idIndexMarker090"/>模型<a id="_idIndexMarker091"/>被导出为名为 H2O 魔咒的可部署计分工件。MOJOs 可以在任何 JVM 环境中运行(可能除了非常小的边缘设备)。</p>
			<p>在<em class="italic">第 3 节——将您的模型部署到生产环境</em>中，我们将了解到 MOJOs 已经准备好直接部署到 H2O 软件以及许多第三方评分解决方案，无需编码。但是，如果您希望将 MOJO 直接嵌入到您自己的软件中，有一个 MOJO Java API 来构建 Java 助手类，以公开 MOJO 功能(例如，除了预测之外还输出原因代码)，并提供与您的评分输入和输出的灵活集成。</p>
			<p>在所有模型中，不管用于构建模型的机器学习算法如何，MOJOs 在<a id="_idIndexMarker092"/>构造中都是相同的。因此，从 DevOps 的角度来看，部署是可重复和可自动化的。</p>
			<h3>MOJOs 的主要特点</h3>
			<p><a id="_idIndexMarker093"/>MOJO 的主要特点如下:</p>
			<ul>
				<li><strong class="bold">低延迟</strong>:通常情况下，每次评分不到 100 毫秒。</li>
				<li><strong class="bold">灵活的数据速度</strong> : Mojos 可以对批处理、实时和流数据进行预测(例如，对整个数据库表，分别作为 REST 端点和 Kafka 主题，等等)。</li>
				<li><strong class="bold">灵活的目标系统</strong>:这适合 JVM 运行时，包括 JDBC 客户端、<strong class="bold"> REST 服务器</strong>、<strong class="bold"> AWS Lambda </strong>、<strong class="bold"> AWS SageMaker </strong>、<strong class="bold"> Kafka 队列</strong>、<strong class="bold"> Flink streams </strong>、Spark <a id="_idIndexMarker094"/>管道<a id="_idIndexMarker095"/>包括流、Hive UDF、雪花的外部函数等等。目标系统可以是<a id="_idIndexMarker096"/>专业<a id="_idIndexMarker097"/> H2O 评分软件，第三方评分<a id="_idIndexMarker098"/>软件，或者你自己的软件。一种常见的模式是将 MOJO 部署到 REST 服务器，并通过来自客户端应用程序(例如，Excel 电子表格)的 REST 调用来使用它的预测。</li>
				<li><strong class="bold">可解释性特性</strong>:除了预测，你还可以在实时评分时从 MOJO 接收 K-Lime 或 Shapley 原因代码，你可以将 MOJO 加载到 H2O 核心中进行评分和检查 MOJO 属性。</li>
				<li><strong class="bold">可重复部署</strong>:mojo 很容易集成到组织用于软件部署的现有部署自动化(CI/CD)管道中。</li>
			</ul>
			<p>请注意，除了<a id="_idIndexMarker099"/> H2O 魔咒，还有一种叫做<strong class="bold"> POJO </strong>的替代方法，用于不常见的边缘情况。这将在<a href="B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137"> <em class="italic">第 8 章</em> </a>、<em class="italic">综合</em>中进一步探讨。</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>使用 H2O 组件的工作流</h1>
			<p>现在，我们已经了解了 H2O 的大规模机器学习组件的角色和关键功能，让我们<a id="_idIndexMarker100"/>将它们结合到一个高级工作流中，如下图所示:</p>
			<div><div><img src="img/B16721_Figure_2.1.jpg" alt="Figure 2.1 – A high-level machine learning at scale workflow with H2O&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.1–H2O 的大规模高级机器学习工作流</p>
			<p>工作流程按以下顺序进行:</p>
			<ol>
				<li>管理员配置<strong class="bold"> H2O 企业蒸汽</strong>。</li>
				<li>数据科学家登录<strong class="bold"> H2O 企业蒸汽</strong>并启动<strong class="bold"> H2O 核心</strong>集群(选择<strong class="bold"> H2O-3 </strong>或<strong class="bold"> H2O 苏打水</strong>)。</li>
				<li>数据科学家使用他们最喜欢的客户端，使用 H2O 模型构建 API 的 Python、R 或 Java/Scala 语言风格来构建模型。数据科学家使用 UI 或 IDE 对<strong class="bold"> H2O 企业 Steam </strong>进行身份验证，并连接到在 H2O 企业 Steam 上启动的<strong class="bold"> H2O 集群</strong>。</li>
				<li>数据科学家使用 IDE 通过 H2O 迭代模型构建步骤。</li>
				<li>在数据科学家决定了要部署的模型之后，<strong class="bold"> H2O </strong> <strong class="bold"> AutoDoc </strong>被生成，并且<strong class="bold"> H2O MOJO </strong>被从 IDE 中导出。</li>
				<li>数据科学家要么终止<strong class="bold"> H2O 集群</strong>，要么在超过空闲或绝对正常运行时间后等待<strong class="bold"> H2O 企业蒸汽</strong>执行此操作。管理员在分配给用户的资源配置文件中配置了这些持续时间。请注意，被终止的集群检查点确实工作，并且新的<strong class="bold"> H2O 集群</strong>总是可以被启动以从终止点继续工作。</li>
				<li>模型<a id="_idIndexMarker101"/>被导出为<strong class="bold"> H2O 魔咒</strong>并被部署到任何一组不同的主机目标。模型在业务环境中被消费，业务价值的实现开始了。</li>
			</ol>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/> H2O 关键概念</h1>
			<p>在以下部分中，我们将确定并描述 H2O 的关键概念，这些概念是上一部分工作流步骤的基础。这些概念对于理解本书的其余部分是必要的。</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>数据科学家的经验</h2>
			<p><a id="_idIndexMarker102"/>数据科学家拥有构建大规模 H2O 模型的熟悉经验，同时从企业服务器集群上复杂的基础设施和架构中抽象出来。这在下图中有更详细的描述:</p>
			<div><div><img src="img/B16721_Figure_2.2.jpg" alt="Figure 2.2 – Details of the data scientist's experience with H2O Core&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.2–数据科学家使用 H2O 核心的详细体验</p>
			<p>数据科学家使用众所周知的无监督和有监督的机器学习技术，这些技术可以跨企业的分布式基础设施和架构进行扩展。这些技术是用 H2O 模型构建 API 编写的，该 API 是用熟悉的 ide(例如 Jupyter 或 RStudio)用熟悉的语言(例如 Python、R 或 Java)编写的。</p>
			<p class="callout-heading">H2O 流——一个方便的可选用户界面</p>
			<p class="callout">H2O 生成了自己的名为 H2O 流的 web 用户界面，在模型构建过程中可以选择使用。H2O 流的 UI 焦点和丰富的特性可用于完整的模型构建工作流，或利用便利的技巧，正如我们将在第 5 章 、<em class="italic">高级模型构建-第 1 部分</em>中演示的那样。</p>
			<p>因此，数据科学家在一个熟悉的世界中工作，这个世界连接到一个复杂的架构，以将模型构建扩展到大型或海量数据集。我们将在下一节探讨这个架构。</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>H2O 星团</h2>
			<p>对于所有利益相关者来说，<a id="_idIndexMarker104"/> H2O 集群可能是最需要理解的核心概念。这就是 H2O 如何创建其在企业服务器集群上构建机器学习模型的架构单元。我们可以通过下图来理解这个<a id="_idIndexMarker105"/>概念:</p>
			<div><div><img src="img/B16721_Figure_2.3.jpg" alt="Figure 2.3 – The architecture of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.3–H2O 集群的架构</p>
			<p>当一名数据科学家启动一个 H2O 集群时，他们会指定分配工作的服务器数量(也称为<em class="italic">节点</em>的数量)，以及每个节点使用的内存和 CPU 数量。我们将了解到，这可以通过手动配置或允许 Enterprise Steam 根据训练数据量自动计算这些规格来实现。</p>
			<p>当 H2O 集群启动时，IDE 将 H2O 软件(单个 JAR 文件)推送到企业服务器集群中每个指定数量的节点，其中每个节点分配指定的内存和 CPU。然后，H2O 软件组织成一个自通信集群，其中一个节点被选为与 IDE 通信并与 H2O 集群的其余节点协调的主节点。</p>
			<p>数据科学家从 IDE 连接到已启动的 H2O 集群。然后，数据科学家编写模型构建代码。代码的每一部分都由 IDE 中的 H2O 库翻译成给 H2O 集群的指令。每条指令按顺序发送到 H2O 集群上的主节点，主节点将指令分发到其他 H2O 集群成员，在那里并行执行指令。leader 节点收集和组合结果，并将它们发送回 IDE。</p>
			<p>以下是一些需要牢记的重要注意事项:</p>
			<ul>
				<li>数据直接从数据源接收到 H2O 节点的内存中。源数据在 H2O 节点之间进行分区，不会在它们之间重复。从存储层(例如，S3、HDFS 等)接收的数据是并行完成的，因此速度很快。来自外部来源的数据(例如 GitHub 存储库和 JDBC 数据库表)不是并行完成的。在所有情况下，数据都不会通过 IDE 或客户端传递。</li>
				<li>每个 H2O 集群都是独立的，与其他集群隔离开来，包括接收到其中的数据。因此，启动集群并使用相同数据源的两个用户不会共享数据。</li>
				<li>我们将<a id="_idIndexMarker107"/>看到 Enterprise Steam 的管理员为用户可以启动的并发集群数量指定了上限，以及用户在启动集群时可以指定的内存、CPU 和其他资源的数量。</li>
				<li>H2O 星团是静态的。一旦启动，节点数量和每个节点的资源数量不会改变，直到它们被终止，在这种情况下，H2O 集群被拆除。如果其中一个节点关闭，则必须重新启动 H2O 集群，并从头开始从 IDE 构建模型。对于较长时间的工作，H2O 的检查点功能可以帮助您从一个还原点继续。</li>
			</ul>
			<p>让我们看看 H2O 集群的<a id="_idIndexMarker108"/>生命周期，如下图所示:</p>
			<div><div><img src="img/B16721_Figure_2.4.jpg" alt="Figure 2.4 – The life cycle of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.4-H2O 集群的生命周期</p>
			<p>让我们一个接一个地看看生命周期的每个阶段，以了解它们是如何工作的:</p>
			<ol>
				<li value="1"><strong class="bold">启动</strong>:数据科学家从企业 Steam UI 或 API 启动 H2O 集群。选择 H2O-3 或苏打水。H2O 集群大小和资源(即节点数量、每个节点的内存和其他配置)是手动输入的，或者是由 Enterprise Steam 根据用户输入的数据量自动生成的。H2O 星系团如前所述形成。</li>
				<li><strong class="bold">连接到</strong>:数据科学家切换到他们的 IDE，通过指定集群名称连接到 H2O 集群。</li>
				<li><strong class="bold">在</strong>上建立模型:数据科学家使用 H2O 建立模型。IDE 中使用的 H2O 库将每次模型构建迭代的 H2O API 代码翻译成指令。这些数据被发送到主节点，并分布在 H2O 集群中。</li>
				<li><strong class="bold">停止</strong>:H2O 集群关闭。释放资源，并从 H2O 集群的每个节点上删除 H2O 软件。这可以由用户从 IDE 中完成，也可以在空闲一段时间后或超过 H2O 集群的绝对运行时间时自动完成(这些持续时间是在生命周期的第 1 步中的 H2O 集群启动中指定的)。尽管没有运行，但用户仍然可以获得有关该集群的信息(例如，名称、H2O 版本和大小)。</li>
			</ol>
			<p><strong class="bold">停止/保存数据&amp;重启</strong>:这是<strong class="bold">停止</strong>的替代选项，当企业 Steam 管理员为用户或用户组配置此选项时，这是可能的。在这种情况下，当 H2O 集群停止时，它将模型<a id="_idIndexMarker110"/>构建步骤中的数据保存到存储层(即保存模型构建状态)。当群集重新启动时(使用与启动时相同的名称)，群集将启动并返回到其先前的状态。</p>
			<ol>
				<li value="5"><strong class="bold">删除</strong>:这将停止集群(如果正在运行)并永久删除对 H2O 集群的所有引用。如果它已停止并保存了模型构建状态，该数据也将被永久删除。</li>
			</ol>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>企业蒸汽作为 H2O 门户</h2>
			<p>所有 H2O 管理活动都发生在企业 Steam 上，用户必须通过 Steam 启动 H2O 集群。这种<em class="italic">条条大路通企业 Steam </em>的方法意味着 Steam 在用户及其 H2O 集群被发布到企业系统之前对其进行管理。下图对此进行了详细说明:</p>
			<div><div><img src="img/B16721_Figure_2.5.jpg" alt="Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.5–企业 Steam 被视为企业集群的 H2O 网关</p>
			<p>管理员<a id="_idIndexMarker112"/>配置设置以管理 H2O 用户，并将 Enterprise Steam 与企业服务器集群集成。此外，管理员存储 H2O 软件版本，这些版本将在 H2O 群集启动时被推送到服务器群集，并在群集停止和资源释放时被删除。管理员还可以访问用户使用数据。这都是通过一个仅用于管理的 UI 来完成的。</p>
			<p>管理员配置用户以及用户如何在企业环境中启动 H2O 集群。这些配置定义了用户可以同时启动的并发集群数量、大小(即节点数量)以及为每个启动的 H2O 集群分配的资源数量(例如，每个节点的内存)。配置还定义了当用户不在 IDE 中从 H2O 模型构建代码手动停止或删除时，群集将何时停止或删除。一组这样的配置被定义为一个配置文件，一个或多个配置文件被分配给用户或用户组。因此，管理员可以将一些用户指定为高级用户，将其他用户指定为轻度用户。</p>
			<p>用户通过同一个身份提供者(例如 LDAP)向 Enterprise Steam 进行身份验证，该身份提供者用于授权访问企业服务器集群环境中的资源(例如 S3 存储桶)。当<a id="_idIndexMarker113"/>用户启动一个集群时，Enterprise Steam 传递用户身份，这个身份在企业系统上的授权质询期间使用。ide 中的用户必须通过 Enterprise Steam API 的身份验证才能连接到他们已经启动的集群。</p>
			<p class="callout-heading">H2O 核心需要企业蒸汽吗？</p>
			<p class="callout">请注意，H2O 核心不需要企业蒸汽。企业管理员可以配置其企业服务器集群基础架构，以允许在此基础架构上启动 H2O 集群。</p>
			<p class="callout">然而，这种方法并不是一种合理的企业实践。它引入了控制和治理的缺失，而 Enterprise Steam 提供了一个集中式 H2O 网关来保护、管理和登录用户，如本节所述。此外，Enterprise Steam 还为用户带来了好处，让他们在启动 H2O 集群时，不必再经历将 H2O 核心与企业集群集成的技术步骤，例如 Kerberos 安全要求。在<a href="B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207"> <em class="italic">第 11 章</em> </a>、<em class="italic">管理员和运营视图</em>以及<a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"> <em class="italic">第 12 章</em> </a>、<em class="italic">企业架构师和安全视图</em>中更详细地探讨了企业 Steam 的企业优势。</p>
			<p class="callout">此外，请记住，H2O 核心是免费和开源的，而企业蒸汽不是。</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>企业 Steam 和 H2O 核心高层架构</h2>
			<p>现在<a id="_idIndexMarker114"/>我们已经知道了 H2O 集群是如何形成的，以及 Enterprise Steam 在管理 H2O 用户和启动 H2O 集群中扮演的角色，让我们从高级部署的角度来理解 Enterprise Steam 和 H2O 核心架构。下图描述了这种部署架构:</p>
			<div><div><img src="img/B16721_Figure_2.6.jpg" alt="Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图 2.6–企业 Steam 和 H2O 核心高级部署架构</p>
			<p>Enterprise Steam <a id="_idIndexMarker115"/>运行在自己的专用服务器上，通过 HTTP(S)与企业服务器集群通信。如前所述，Enterprise Steam 存储 H2O 核心(H2O-3 或苏打水)JAR 文件，该文件被推送到服务器集群，然后服务器集群自组织成一个协调但分布式的 H2O 集群。这个 H2O 集群可以是一个 native YARN 或 Kubernetes 作业，这取决于实现了哪个后端。注意，H2O-3 是在 Map-Reduce 框架上运行的，而苏打水是在 Spark 框架上运行的。</p>
			<p>H2O-3 或苏打水 API 库被安装到 data science IDE 中(例如，Jupyter 环境中 H2O-3 包的<code>pip install</code>)。它必须与用于从 Enterprise Steam 启动集群的版本相匹配。如前所述，数据科学家使用 IDE 对企业级 Steam 进行认证，连接到 H2O 集群，并编写 H2O 模型构建代码。H2O 客户端库将 H2O 模型构建代码翻译成 REST 消息，并发送给 H2O 集群的领导节点。然后，在 H2O 集群中分配工作，并将结果返回给 IDE。</p>
			<p>请注意，企业集群可以是内部部署、云基础设施即服务或托管服务实施。例如，它们可以是内部或云中的 Kubernetes 或 Cloudera CDH，或者云中的 Cloudera CDP 或 Amazon EMR。全面部署<a id="_idIndexMarker116"/>的可能性在<a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"> <em class="italic">第 12 章</em> </a>、<em class="italic">企业架构师和安全视图</em>中有更详细的讨论。</p>
			<p class="callout-heading">H2O 平台选择</p>
			<p class="callout">在本书中，H2O 在规模技术被称为包括:H2O 企业蒸汽+ H2O 核心(H2O-3，H2O 苏打水)+ H2O MOJO。大规模 H2O 集成了用于模型构建的企业服务器集群和用于模型部署的企业评分环境。</p>
			<p class="callout">仅用上述组件就可以实现大规模 H2O。或者，大规模 H2O 可以作为更大的 H2O 机器学习平台和称为 H2O 人工智能云的能力集的子集来实现。H2O 人工智能云平台在<em class="italic">第 5 节——拓宽视野——H2O 人工智能云平台的人工智能应用数据中有更详细的描述</em>。</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>苏打水允许用户在 H2O 编码，无缝火花</h2>
			<p>下面的代码显示了一个简单的例子，火花和 H2O 集成在同一个 H2O 代码<a id="_idIndexMarker117"/>使用 H2O 苏打水:</p>
			<pre class="source-code"># import data</pre>
			<pre class="source-code">loans_spark = spark.read.load("loans.csv", format="csv", sep=",", inferSchema="true", header="true")</pre>
			<pre class="source-code"># Spark data engineering code</pre>
			<pre class="source-code">loans_spark = # any Spark SQL or Spark DataFrame code</pre>
			<pre class="source-code"># Convert Spark DataFrame to H2O Frame</pre>
			<pre class="source-code">loans = h2oContext.asH2OFrame(loans_spark)</pre>
			<pre class="source-code"># Continue with H2O model building steps as in previous code example</pre>
			<pre class="source-code">loans.describe()</pre>
			<p><a id="_idIndexMarker118"/>代码显示火花导入数据，保存为<a id="_idIndexMarker119"/>一个<strong class="bold">火花数据帧</strong>。<strong class="bold"> Spark SQL </strong>或<strong class="bold"> Spark DataFrame </strong> API 用于将该数据设计成新的数据帧，然后该 Spark DataFrame <a id="_idIndexMarker120"/>被转换成<a id="_idIndexMarker121"/>an<strong class="bold">h2of frame</strong>，从该数据帧执行 H2O 模型构建。因此，用户在相同的 API 语言和 IDE 中无缝地从 Spark 迭代到 H2O 代码。</p>
			<p>H2O 集团的想法对于苏打水仍然是基本正确的。它现在表达了 Spark 框架内的 H2O 集群架构。该架构的细节在第 12 章 、<em class="italic">企业架构师和安全视图</em>中进行了阐述。</p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>mojo 导出为 DevOps 友好的工件</h2>
			<p>数据科学家<a id="_idIndexMarker122"/>构建模型，但最终目标是将模型投入到生产环境中，在商业环境中进行预测。MOJOs 使这最后一英里的部署变得简单。MOJOs 由一行代码导出。例如，无论模型是使用 Python、R 构建的，还是使用广义线性模型、XGBoost 模型或 stacked ensemble 构建的，从 DevOps 的角度来看，所有的 MOJOs 都是相同的。这使得模型部署是可重复的，因此，能够适应整个组织中使用的现有自动化 CI/CD 管道。</p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>总结</h1>
			<p>在这一章中，我们为大规模理解 H2O 机器学习奠定了基础。我们首先回顾了一个最简单的<em class="italic"> Hello World </em>代码示例，并讨论了围绕它的规模问题。然后，我们介绍了 H2O 核心、企业 Steam 和 MOJO 技术组件，以及这些组件如何克服规模问题。最后，我们从这些技术中提取了一组关键概念来加深我们的理解。</p>
			<p>在下一章中，我们将利用这种理解开始我们的旅程，学习如何大规模地构建和部署世界级的模型。开始编码吧！</p>
		</div>
	

</body></html>