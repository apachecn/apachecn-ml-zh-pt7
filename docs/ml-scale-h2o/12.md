

# 九、制作评分和 H2O MOJO

我们花了上一节的时间来学习如何利用 H2O 的大规模数据构建世界级的模型。在本章中，我们将学习如何部署这些模型并根据它们进行预测。首先，我们将介绍将模型投入生产评分系统的背景。然后，我们将了解 H2O 如何使这变得简单而灵活。这个故事的中心是 H2O **MOJO** (简称**模型对象，优化**)，一个从您的模型构建环境中导出的随时可部署的评分工件。我们将从技术上学习什么是 MOJO 以及如何部署它。然后，我们将编写一个简单的批处理文件评分程序，并在其中嵌入一个 MOJO。我们将以一些关于 MOJO 的最后注释来结束。总之，在这一章中，你将发展以不同方式部署 H2O 模型的知识，从而开始从实时预测中获得价值。

这些是我们将在本章中涉及的主要话题:

*   将模型构建上下文与 H2O 模型的评分上下文相关联
*   认识到 H2O 车型目标生产系统的多样性
*   检查 H2O 可部署人造物品——H2O MOJO 的技术设计
*   编写自己的 H2O MOJO 批处理文件记分员，展示如何在自己的软件中嵌入 MOJO

# 技术要求

在本章中，您将需要一个 Java SE 8 或更高版本的环境。像 Eclipse 这样的 Java IDE 是可选的，但是很有用。您将在以下 GitHub 存储库中获得一个 MOJO、一个要评分的数据集和批处理文件评分程序的 Java 代码:[https://GitHub . com/packt publishing/Machine-Learning-at-Scale-with-H2O/tree/main/chapt 9](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/tree/main/chapt9)。这些工件是从第八章[](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137)**中构建的模型中生成的，将它们放在一起*。*

 *请注意，我们已经完成了模型构建，因此您不需要指向正在运行的 H2O 集群的模型构建环境。

# 模型建立和模型评分环境

在*第 2 节*、*使用 H2O 在大数据量上构建最先进的模型*中，我们花了大量精力与 H2O 一起构建世界级的大规模模型。针对大规模数据集构建高度准确和可信的模型可能会为企业带来数百万美元的收入，拯救生命，并定义新的产品领域，但只有当模型被部署到生产系统时，才能进行预测并采取行动。

在生产系统上进行部署和预测(或评分)的最后一步通常非常耗时、有问题，而且风险很大，原因稍后会讨论。H2O 使从构建(训练)模型到部署模型的过渡变得容易。它还在评分位置(设备、web 应用、数据库、微服务端点或 Kafka 队列)和数据速度(实时、批处理和流)方面提供了广泛的灵活性。而且，无论生产环境如何，H2O 部署的模型得分快如闪电。

这种易用性、灵活性和低延迟生产评分的核心是 H2O MOJO。H2O MOJO 是一个随时可以部署的评分工件，它是在您的模型构建代码的端由一个简单的导出命令生成的。不管生成 H2O mojo 的模型构建算法如何，它们都是相似的。因此，所有 H2O 型号的部署都是相似的。在进入 MOJO 并学习如何部署它之前，让我们先大致了解一下从模型训练到模型评分的过程。

## 模型训练到生产模型打分

我们将首先概述模型如何从模型训练过渡到生产评分，然后看看 H2O 是如何做到这一点的。

### 从训练到评分的通用渠道

被训练成部署模型的的通用管道可以表示如下:

![Figure 9.1 – Generalized pipeline from model training to scoring 
](img/Figure_9.1_B16721.jpg)

图 9.1–从模型训练到评分的通用管道

请注意，这个管道由称为**机器学习操作** ( **MLOps** )的实践更正式地表示和阐述，它涉及更大的关注领域，但是对于将模型部署到生产的焦点，这里的表示应该对我们有用。

每个步骤总结如下:

1.  `if-else`软件代码中的逻辑。这非常耗时，因为数据科学家必须将经过训练的模型的逻辑准确地传达给软件开发人员，而软件开发人员必须正确地实现该逻辑，然后对其进行彻底测试，以验证其准确性。这也容易出错，因此有风险，而且耗时。

最好的情况是转换工具将训练好的模型转换成可部署的工件。这可以是一种格式(例如，XML for PMML、PFA 或 ONNX ),它为准备根据声明性结构进行计算的生产系统声明逻辑，也可以是可嵌入到软件程序或框架中的可运行软件工件(例如，Python wheel 或 Java JAR 文件)。

1.  **可部署模型**:转换后的模型被部署到生产系统中。这种编写的代码或转换的工件被集成到一个软件应用或框架中，在某个时候，将数据输入到它所拥有的评分逻辑中，并输出评分结果。比如一个客户的数据进去了，流失的概率就出来了。

模型部署应该在测试和**生产** ( **生产**)环境中执行，通过一个使用**持续集成和持续部署** ( **CI/CD** )管道的正式治理过程来完成部署和提升，就像一般的软件部署一样。跨所有构建的模型(例如，在不同的 ML 算法中)可识别和标准化的可部署工件在部署期间比那些不可识别和标准化的工件更容易自动化。

1.  **生产系统**:生产现场评分。生产评分需求可以是多种多样的。例如，可能需要对一批中的整个数据库表、通过网络发送的每个实时 ATM 交易、客户的每个网页点击的 web 应用内部、或从边缘设备发送的传感器数据流进行评分。评分可以在设备上进行，也可以在云中的大型服务器上进行。通常，评分越快越好(每次评分少于 50 微秒或更快的要求并不少见)，评分器的大小和资源消耗越小，就越能部署到边缘。
2.  **预测**:对输出进行评分。评分期间模型输出预测。请注意，预测需要业务环境和行动来实现目的或价值。例如，预测会流失的客户会得到电话或特别优惠来帮助确保他们仍然是客户。通常，评分输出不仅需要预测，还需要以原因代码的形式对这些预测进行解释。在为特定客户生成预测时，模型如何衡量计分器的每个输入？换句话说，在特定的预测中，哪些因素是最重要的。这些决策权重被表示为原因代码，它们有助于在客户流失的情况下个性化电话或特价。

让我们看看 H2O 是如何实现从训练到得分的流程的。

### H2O 管道及其优势

训练有素的 H2O 模型参与到类似的管道中，但是具有重要的属性，使得它们易于部署到软件系统的不同目标，并且当它们在那里得分时也非常快。H2O 的可部署工件被称为 MOJO，它弥合了模型训练和模型评分之间的差距，故事中的中心人物也是如此。H2O 管道的属性总结如下:

![Figure 9.2 – H2O's model training-to-scoring pipeline
](img/Figure_9.2_B16721.jpg)

图 9.2-H2O 的模型训练到评分流程

让我们来阐述一下 H2O 部署模型的优势:

1.  **H2O 训练模型**:H2O mojo 从模型构建 IDE 中导出，准备部署。数据科学家通过在 IDE 中编写一行代码，将训练好的模型转换为导出的、随时可以部署的 MOJO。
2.  **H2O MOJO**:H2O MOJO 是标准化的低延迟评分工件，随时可以部署。MOJO 构造是标准化的，由所有模型类型共享，它有自己的运行时，嵌入在任何 Java 运行时中。这意味着所有的 MOJOS(模型)都相同地嵌入到任何 **Java 虚拟机** ( **JVM** )中，独立于更大的软件和硬件环境。MOJOs 也是轻量级的，可以部署到几乎所有的基础设施上(除了最小的边缘设备)。MOJOs 的评分速度非常快，可以处理任何数据速度(实时评分、批量评分和流式评分)。
3.  **生产系统** : H2O MOJOs 灵活部署到多种生产系统。MOJOs 部署到广泛的生产系统中。本章稍后将对这些系统进行概述，并详细介绍如何将 MOJOS 部署到这些系统上。
4.  **预测**:mojo 可以在他们的评分中输出很多信息。MOJO 的输入以分类的类概率、回归的预测数值和无监督问题的模型特定结果的形式返回预测。此外，可选地，MOJOs 可以 Shapley 或 K-LIME 值的形式返回原因代码，或其他属性，如预测的叶节点分配。

让我们在下一部分更具体地关注 H2O 生产评分。

# H2O 生产评分

当模型被投入生产以进行预测(或为一类无监督的问题生成无监督的结果)时，它们就实现了它们的商业价值。在本节中，我们将更详细地讨论从模型构建到生产评分的 H2O 管道。

## 与 H2O 的端到端生产评分管道

请看下图，图中显示了从模型训练到模型部署和产品评分的端到端 H2O 流程:

图 9.3-H2O 全面评分管道的高级视图

![Figure 9.3 – High-level view of full scoring pipeline with H2O 
](img/Figure_9.3_B16721.jpg)

通常，模型构建被认为是一个**开发** ( **开发**)环境，而模型评分是一个 PROD 环境，其源数据来自各个环境。

对于开发，我们已经在*第 2 节*、*中广泛讨论了特征工程和模型训练(以及许多相关步骤，如模型解释和评估)，使用 H2O* 在大数据量上构建最先进的模型。在本章的前面，我们还简要地讨论了可导出的准备部署的 H2O MOJO 评分工件，并将其部署到生产系统。

让我们确定在这个过程中需要记住的一些要点:

*您需要开发和生产之间的特性工程对等性*:这意味着任何创建训练数据集的特性工程必须与测试/生产中的评分输入相匹配。换句话说，训练数据集中的特征必须与输入模型评分的特征相同。如果在 T15 在开发中构建训练数据集之前，有多个特征工程步骤(例如，**从数据源提取、转换和加载** ( **ETL** )和 H2O 苏打水的特征工程)，测试/生产中的评分输入必须具有那些相同的工程特征。

*   话虽如此，根据 MOJO 的部署方式(H2O 计分器、第三方集成或您自己的计分器)，您可能只需要输入测试/生产训练数据集中的一部分功能。这反映了这样一个事实，即经过训练的模型通常只选择对最终模型有贡献的数据特征的子集。然而，这个子集不是必需的；MOJOs 可以接受全部或部分要素(与训练数据集相比),具体取决于您的设计方式。当我们在本章的后面更仔细地研究部署 MOJOs 时，这种灵活性将变得更加清晰。

重要说明

*   *You may need a wrapper around your MOJO (but not with H2O Scorers and most third-party integrations)*: MOJOs are ready to deploy to a Java environment. This means the MOJO is ready to convert input data to a prediction output using the mathematical logic derived from model training and held in the MOJO, and that the MOJO itself does not need compiling or modification in any way. But, you must still make sure the input (for example, CSV, JSON, batch, and so on) feeds into the MOJO in a way that the MOJO can accept. On the other side, you may want to extract more from the MOJO scoring result than only predictions, and you will need to convert the MOJO output to a format expected downstream in the application. You do this by writing a simple Java wrapper class and using the MOJO API called `h2o-genmodel` API to interact with the MOJO. These wrapper classes are not complicated. We will learn more about wrapping MOJOs with an example later in this chapter.

    H2O 计分器和许多 MOJOs 的第三方集成不需要包装器，因为它们在内部处理。在这些情况下，您需要的只是导出的 MOJO。此外，许多集成是通过 REST APIs 与部署在 REST 服务器上的 MOJOs 端点进行的。

    *您可能希望返回原因代码或其他信息以及您的预测* : MOJOs 返回监督模型的预测和非监督模型的特定于模型的输出(例如，使用`H2OIsolationForestEstimator`训练的模型会返回异常分数)。但是，还有更多的检索从 MOJO；您还可以将原因代码返回为 K-LIME 或 Shapley 值、基于树的模型所采用的决策路径或用于预测分类问题的分类标签。这些额外的输出在包装器代码中使用您构建的计分器的`h2o-genmodel` API 来实现。它们可能内置于也可能不内置于 H2O 计分器的功能或现成的第三方集成中。你需要检查这些计分器的规格。

*   *您需要一个正式的流程来部署和管理您的模型*:将模型投入生产涉及风险:一般来说，在部署期间由于错误而导致的失败或延迟的风险，以及由于部署模型的模型决策的不利后果而导致的收入或声誉风险。我们将在第十四章[*、*更大平台背景下的 H2O*中更深入地探讨这个话题。*](B16721_14_Final_SK_ePub.xhtml#_idTextAnchor256)
*   *您需要 MLOps 来监控您的模型*:PROD 中的模型通常需要被监控，以查看输入数据的值与训练数据中的值相比是否随时间而变化(这种结果称为数据漂移)。在这种情况下，模型可能需要重新训练，因为它训练所针对的信号已经改变，这可能导致模型的预测准确性降低。也可以监控偏差、预测分布和评分的其他方面。
*   模型监控超出了 MOJOs 的能力范围。MOJOs 关注的是单个分数。监控从根本上跟踪 MOJO 输入和输出的总体趋势，它是一个独立的技术领域和关注点，这里不做讨论。但是，请注意，H2O 有一个执行模型监控和治理的 MLOps 平台。在*第 16 章*、*机器学习生命周期、人工智能应用和 H2O 人工智能混合云*中对其进行了概述。

我们刚刚概述了从 H2O 模型制作到生产评分的整个流程，并确定了该流程的关键点。根据您的需求，这个管道的一部分是非常可变的:在其上部署您的 MOJO 的目标系统。让我们更详细地探讨这一点。

H2O mojo 的目标生产系统

## MOJOs 的一个大优势是它们可以被部署到广泛的生产系统中。让我们使用下图进行更深入的总结:

One large advantage of MOJOs is that they can be deployed to a wide range of production systems. Let's dig deeper using the following diagram to summarize:

图 9.4-MOJO 评分的生产系统分类

![Figure 9.4 – Taxonomy of production systems for MOJO scoring
](img/Figure_9.4_B16721.jpg)

业务需求在很大程度上决定了评分需要实时、批量还是流式，MOJOs 可以处理所有这些数据速度。

对于 MOJO 部署，将生产目标系统分为以下三个类别非常有用:

**H2O 评分系统**:这是 H2O 提供的 H2O 评分软件。这些评分器包括一个具有 MLOps 和丰富的模型监控和治理功能的 REST 服务器(以及一个生动的路线图，包括批量评分、冠军/挑战者测试、A/B 测试等)，一个用于批量数据库表评分的数据库评分器，该评分器输出到一个表或文件，一个文件批量评分器，以及用于流事件的 AMQ 和卡夫卡评分器。H2O 正在积极增加更多的得分手，所以请访问他们的网站以了解最新情况。在*第 16 章*、*机器学习生命周期、人工智能应用和 H2O 人工智能混合云*中更详细地讨论了 MLOps 计分器。

*   **第三方集成**:许多第三方集成了开箱即用的 MOJOs，用于对他们的框架或软件进行评分。其他的需要一些胶水来创建一个定制的集成。
*   **你自己的 DIY 系统**:你可以在运行 Java 环境的软件或框架集成中嵌入 MOJOs。集成将需要一个简单的 Java 包装器类来将您的应用或框架连接到 MOJO 数据输入和输出功能(例如，您的 REST 服务器需要将 JSON 转换成 MOJO 数据对象)。H2O 用它的 MOJO API 让这变得简单。用 MOJO API 包装将在本章后面的代码示例中详细讨论。
*   请注意，本章介绍了如何将 MOJOs 部署到目标系统。整个 [*第 10 章*](B16721_10_Final_SK_ePub.xhtml#_idTextAnchor178) 、 *H2O 模型部署模式、*都将致力于浏览 MOJO 部署到目标系统的多个示例。

现在我们已经了解了从模型构建到不同制作系统上的实时评分的端到端 H2O 管道，让我们更仔细地看看它的核心角色:MOJO。

H2O MOJO 深潜

# 从部署和评分的角度来看，所有的 MOJOs 基本上都是相似的。从上游模型构建的角度来看，无论 MOJO 的来源如何，也就是说，无论 H2O 广泛多样的模型构建算法(例如，广义线性模型和 XGBoost)和技术(例如，堆叠集成和 AutoML)以及训练数据集大小(从 GBs 到 TBs)中的哪一种被用于构建最终模型，都是如此。

让我们更详细地了解一下这种魔力。

什么是 MOJO？

## 一个 **MOJO** 代表优化的模型对象。通过运行下面的代码行,它从您的模型构建 IDE 中导出:

这会将一个唯一命名的`.zip`文件下载到您的 IDE 文件系统中您指定的路径。这个`.zip`文件就是 MOJO，这就是部署的内容。您不需要解压缩它，但是如果您好奇的话，它包含一个描述 MOJO 的`model.ini`文件和多个`.bin`文件，所有这些文件都由 **MOJO 运行时**使用。

```
model.download_mojo(path="path/for/my/mojo")
```

什么是 MOJO 运行时？这是一个名为`h2o-genmodel.jar`的 Java `.jar`文件，是用于所有 H2O 核心 MOJOs 的通用运行时。换句话说，MOJO 是特定于从它们中派生出来的训练模型的，并且所有的 MOJO 都被同样地加载到 MOJO 运行时中。MOJO 运行时与 Java 运行时集成(在 H2O 软件、第三方软件或您自己的软件中)。下图将 MOJO 与 MOJO 运行时相关联。

What is a MOJO runtime? This is a Java `.jar` file called `h2o-genmodel.jar` and is a generic runtime for all H2O Core MOJOs. In other words, MOJOs are specific to the trained models they are derived from, and all MOJOs are loaded identically into the MOJO runtime. The MOJO runtime integrates with a Java runtime (in H2O software, third-party software, or your own software). The following diagram relates MOJOs to the MOJO runtime.

图 9.5-MOJO 和 MOJO 运行时

![Figure 9.5 – MOJOs and the MOJO runtime
](img/Figure_9.5_B16721.jpg)

如前所述，MOJOs 被部署到一个 Java 运行时上，更正式的说法是作为一个依赖库的`h2o-genmodel.jar`来完成这项工作。软件使用`h2o-genmodel` API 将特定于模型的 MOJO 加载到通用`h2o-genmodel.jar`运行时中。应用代码中的实际评分逻辑也使用`h2o-genmodel.jar`及其 API 来实现评分和从嵌入式 MOJO 中提取结果。

让我们在下一节深入探讨。

部署 MOJO

## 如果您将 MOJO 部署到 H2O 计分器或集成了 MOJO 的第三方软件，您只需要 MOJO。在这些情况下，您不需要考虑 MOJO 运行时和 API。这是因为这些软件系统已经在幕后实现了`h2o-genmodel.jar`(使用`h2o-genmodel` API)，换句话说，在部署和运行的 H2O 计分器或第三方软件中。

在其他情况下，您需要编写嵌入 MOJO 并提取其评分结果的代码。这段代码通常是一个使用`h2o-genmodel` API 的 Java 包装类。稍后我们将使用一个代码示例来访问它。

这种区别很重要，值得加大标注。

MOJO 部署的主要区别

当部署到 H2O 评分软件或集成 MOJO 的第三方软件时，您只需要 MOJO 即可(基于配置)。

当将 MOJO 集成到您自己的软件或没有集成 MOJO 的第三方软件中时，您需要使用`h2o-genmodel` API 编写一个简单的 Java 包装类。这个包装器需要`h2o-genmodel.jar`，这是`h2o-genmodel` API 所代表的库。

(如果您正在 REST 服务器上的第三方软件或您自己的软件中使用 MOJO 预测，您当然不需要 MOJO 或 MOJO 运行时。您只需要遵守 MOJO 的 REST 端点 API。)

让我们来看看需要编写包装器的情况。

使用 H2O MOJO API 包装 MOJO

# 在学习如何将 MOJOs 包装到更大的软件程序中之前，让我们先来接触一些前兆。

获取 MOJO 运行时

## 当你在模型建立后从 IDE 下载你的 MOJO 时，你可以下载`h2o-genmodel.jar`。这只是在下载语句中添加一个新的参数，如下所示:

这种获得`h2o-genmodel.jar`的方法通常不会在受治理的生产部署中完成。这是因为`h2o-genmodel.jar`对所有的 MOJOs 都是通用的，是软件开发人员而不是数据科学家关心的问题。

```
Model.download_mojo(path="path/for/my/mojo", 
```

```
                    get_genmodel_jar=True)
```

软件开发者可以从位于 https://mvnrepository.com/artifact/ai.h2o/h2o-genmodel 的 Maven 仓库下载 MOJO 运行时。`h2o-genmodel.jar`是向后兼容的；它应该适用于 H2O-3(或苏打水)版本产生的等于或小于`h2o-genmodel.jar`版本的 MOJO。

获取 MOJO 运行时的技巧(h2o-genmodel.jar)

数据科学家不必每次从他们的建模 ide 下载 MOJO 时都下载 MOJO 运行时。这是因为 MOJO 运行时对所有 MOJO 都是通用的。最佳实践是让您的开发人员(而不是数据科学家)在需要时获取并使用 MOJO 运行时进行生产部署。这可以通过前面提到的 Maven 存储库来完成。

H2O-gen model API

## API 的 javadoc 位于[https://docs . H2O . ai/H2O/latest-stable/H2O-gen model/javadoc/index . html](https://docs.h2o.ai/h2o/latest-stable/h2o-genmodel/javadoc/index.html)。注意这是为最新的 H2O-3(或苏打水)准备的。要获得不同版本，请前往[https://docs.h2o.ai/prior_h2o/index.html](https://docs.h2o.ai/prior_h2o/index.html)。

总之，`h2o-genmodel` API 用于围绕 MOJO 构建包装器，因此您的应用可以向 MOJO 提供数据，从中提取预测和决策信息，并将这些结果转换为包装器中的代码。包装器通常是你的大型应用的一部分，可以被看作是你的应用和 MOJO 之间的粘合剂。

让我们开始吧。

包装你的魔力的通用方法

## 在编写代码之前，先看看您开发的 MOJO 包装器的应用代码的逻辑流程将会很有用。这可以从下图中看出:

It will be useful before writing code to first look at the logical flow of application code for the MOJO wrapper you develop. This can be seen in the following diagram:

图 9.6–包装 MOJO 的逻辑视图

![Figure 9.6 – Logical view of wrapping a MOJO
](img/Figure_9.6_B16721.jpg)

Java 包装器通常是它自己的类(或类的一部分),导入`h2o-genmodel.jar`,并遵循以下一般逻辑步骤:

将`yourMOJO.zip`加载到 MOJO 运行时。回想一下`h2o-genmodel.jar`是运行时，它保存了处理特定于模型的 MOJOs 的一般逻辑。这个运行时现在可以在您的特定模型上运行了。

1.  将数据输入 MOJO。为此，使用`h2o-genmodel`代码将输入的 Java 数据结构转换成 MOJO 数据结构。
2.  获得魔力。这是一行`h2o-genmodel`代码。
3.  从 MOJO 评分结果中提取您需要的信息子集。回想一下，预测结果(或无监督结果)表示预测的各个方面(标签和预测)以及评分决策的各个方面(原因代码、叶节点结果的决策路径等)。
4.  将提取的结果转换成应用下游需要的数据结构。
5.  让我们写一个包装器。

包装示例–用 Java 构建批处理文件计分器

## 我们正在编写的包装器的目标是对文件中的新数据进行批量评分。评分的输出将是输入记录、预测和原因代码，所有这些都格式化为一行 CSV。原因代码将是单个 CSV 字段，但原因代码将由管道分隔。

我们将把这个包装类编译成一个可运行的程序，它接受三个输入参数:

输入参数 1: `path/of/batch/file/to/score`

*   输入参数 2: `path/to/yourMOJO.zip`
*   Shapley 值增加了延迟
*   Input param 3 (optional): The `—shap` flag to trigger the return of Shapley reason codes in addition to the scoring prediction for each row in the file

    请记住，返回 Shapley 值会增加额外的计算，因此会增加每次评分的延迟。如果延迟很关键，您可能希望在结果中对有无 Shapley 原因代码的延迟进行基准测试，以评估是否将它们包括在评分中。

    我们将使用您在 [*第 8 章*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137) 、*中的模型构建练习结束时导出的 MOJO。*

 *代码

### 我们的批处理文件计分程序将涉及一个单一的 Java 类，不包括错误处理和其他生产质量软件设计。我们的目的是展示将 MOJO 集成到软件中的基本原理。

请注意，下面的代码示例是逐步详细说明的。要从头到尾访问完整的 Java 代码，请访问位于[https://GitHub . com/packt publishing/Machine-Learning-at-Scale-with-H2O/tree/main/chapt 9](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/tree/main/chapt9)的 GitHub 资源库。

让我们开始吧:

`BatchFileScorer`。由于这也是一个可执行程序，我们将创建一个`main`方法来启动代码执行。注意`h2o-genmodel`库包的`import`声明:

```
Import java.io.*; import hex.genmodel.easy.RowData; import hex.genmodel.easy.EasyPredictModelWrapper; import hex.genmodel.easy.prediction.*; import hex.genmodel.MojoModel;  public class BatchFileScorer {   public static void main(String[] args) throws Exception{   // we will fill with steps 2 to 4 that follows   } }
```

1.  现在，让我们用代码填充`main`方法，如以下步骤所示。

**检索输入参数**:我们从程序的参数中检索输入参数:

```
// get input parameters File fileToScore = new File(args[0]); String pathToMojo = args[1]; boolean doShapley = args.length == 3   && args[2].equals("--shap"); 
```

1.  **加载 MOJO 并将其配置为可选地返回原因代码**:我们将 MOJO 加载到 MOJO 运行时并将其配置为返回 Shapley 值:

    ```
    // Load the mojo (only once) and configure EasyPredictModelWrapper.Config config =    new EasyPredictModelWrapper.Config(); config.setModel(MojoModel.load(pathToMojo); if (doShapley) config.setEnableContributions(true); EasyPredictModelWrapper model =    new EasyPredictModelWrapper(config);
    ```

2.  在代码后面的所有评分之前，MOJO 在这里只加载一次。

重要的设计点——加载一次您的 MOJO

加载 MOJO 可能需要几秒钟，但它只需要加载到您的程序中一次。

在发出所有评分请求之前，在包装类中加载一次 MOJO(例如，当它初始化时)。你不希望你的低于 100 毫秒或低于 10 毫秒的分数之前都有几秒钟的加载时间。

现在来看看魔法:生成预测。

*步骤 1* :

```
// get each record from the file BufferedReader br = new BufferedReader(new   FileReader(fileToScore)); // we are skipping the first line (header line) br.readLine(); String record = null; while ((record = br.readLine()) != null) {   // Convert input record to type required by mojo api   RowData mojoRow = convertInput(record);   // make the prediction   BinomialModelPrediction p = model.predictBinomial(mojoRow);   // get results from p and format it to your needs   // in this case, format is csv to write to file   String outputString = formatOutput(record, p, doShapley);   // can write this to file    // but printing to screen for ease of code explanation   System.out.println(outputString);   }
```

中显示的`import`语句

1.  就是这样！您已经加载了 MOJO 并配置了评分，并且对文件的每一行进行了评分。为了评分，您已经将每条记录从它的应用表示(CSV 字符串)转换为`h2o-genmodel`表示(`DataRow`对象)。您已经编写了一行代码来记录分数。此外，您还从评分结果中检索了预测和 Shapley 原因代码(可选)。然后将它格式化为应用使用的表示形式。

深入到代码

### 让我们深入前面代码中的方法。

方法钻取–将您的应用数据对象转换为 h2o-genmodel 数据对象

#### 注意，`RowData mojoRow`是程序代码被转换成`h2o-genmodel` API 数据对象的地方。在本例中，这是通过如下所示的`convertInput(record)`方法完成的:

我们简单地使用逗号作为分隔符来分割输入，并将每个值分配给 H2O `RowData`对象，它本质上是一个键-值对的映射，其中的键代表特性名称(即列标题)。使用`RowData`还有其他选择。

```
private static RowData convertInput(String record) {
```

```
  String[] featureValues = record.split(",");
```

```
  RowData row = new RowData();
```

```
  row.put("purpose_te", featureValues[0]);
```

```
  row.put("addr_state_te", featureValues[1]);
```

```
  row.put("loan_amnt", featureValues[2]);
```

```
  row.put("term", featureValues[3]);
```

```
  row.put("installment", featureValues[4]);
```

```
  row.put("grade", featureValues[5]);
```

```
  // omitting features 6 to 24, see code in github repo 
```

```
  row.put("emp_length_missing", featureValues[25]);
```

```
  return row;
```

```
}
```

设计决策——将数据对象转换为 MOJO API 数据对象的选择

正如我们在这里所做的，使用`h2o-genmodel` API 的`RowData`类只是将应用数据对象转换成`h2o-genmodel`对象以提供给 MOJO 评分的一种方式。查看 API，了解可以为您的实现提供更好的代码设计的其他方法。

方法钻取–要评分的单行

#### 只需要一行代码来对 MOJO 评分并检索结果:

注意，你可能需要一个不同于`BinomialModelPrediction`的类，这取决于你构建的模型的类型。查看`h2o-genmodel` Javadocs，了解使用哪个 Java 类以及返回什么评分信息的详细信息。

```
BinomialModelPrediction p = model.predictBinomial(mojoRow); 
```

方法钻取–收集结果并格式化输出

#### 我们最终使用`formatOutput(record, p, doShapley)`方法从评分结果中构造了一个字符串。下面是该方法的实现方式:

这里的要点是预测结果保存在从评分返回的`h2o-genmodel` API 的`BinomialModelPrediction p`对象中。我们可以从这个物体中获取很多信息。在我们的例子中，我们检索了由`p.label`标识的预测类及其概率`p.classProbabilities[0]`。由于这是一个`BinomialModelPrediction`，其他类的概率将由`p.classProbabilities[1]`检索。

```
private static String formatOutput(String record,
```

```
  BinomialModelPrediction p, boolean doShapley) {
```

```
  // start the ouput string with the record being scored
```

```
  String outputString = record;
```

```
  // add prediction to output string
```

```
  outputString += "   PREDICTION (good=0, bad=1): " + p.label
```

```
  + " " + p.classProbabilities[0];
```

```
  // add Shapley values (bar-delimited) to output string
```

```
  if(doShapley) {
```

```
    outputString += "  SHAP VALUES > 0.01: ";
```

```
    for (int i=0; i < p.contributions.length; i++) {
```

```
        // retrieving only Shap values over 0.01
```

```
        if (p.contributions[i] <  0.01) continue;
```

```
        outputString += model.getContributionNames()[i] + ": "
```

```
        + p.contributions[i] + "|" ;
```

```
    }
```

```
    return outputString;
```

```
}
```

然后，我们遍历 Shapley 原因贡献名称(`model.getContributionNames()[i]`)和值(`p.contributions[i]`)的数组。在我们的例子中，我们只检索值超过`0.01`的原因代码。或者，以为例，我们可以按值对原因进行排序，并返回前五名。返回所有原因时，偏差作为数组中的最后一个返回，所有要素和偏差的总和等于模型的原始预测值。

总之，我们使用了一堆代码将所有这些格式化成一个 CSV 字符串，从原始记录开始，然后附加预测的类及其概率，然后是一个用竖线分隔的原因代码列表。

运行代码

### 要运行应用，将`BatchFileScorer.java`和`h2o-genmodel.jar`编译成一个名为`BatchFileScorer.jar`的可执行 JAR 文件。然后，在与`BatchFileScorer.jar`相同的目录下运行以下命令:

要检索 Shapley 原因代码，将`--shap`追加到语句中。

```
java -jar BatchFileScorer.jar \  
path/to/file/to/score \
path/to/mojo
```

关于 MOJO 的其他知识

# 现在，您已经准备好部署 MOJOs 了，无论是否需要包装器，如前一节所述。让我们通过解决下面的次要问题来总结我们的 MOJOs 知识。

检查 MOJO 决策逻辑

## 对于基于树的模型，您可以使用内置于`h2o-genmodel.jar`的实用程序来生成 MOJO 中树逻辑的图形表示。以下是方法。

让我们使用我们在前面构建包装类的编码示例中使用的相同的 MOJO。在`h2o-genmodel.jar`所在的命令行上，运行以下命令:

这将创建一个如下所示的`.png`文件:

```
java -cp h2o-genmodel.jar hex.genmodel.tools.PrintMojo \ 
-i "path/to/mojo" \
-o tree.png \
--format png \
--tree 0
```

This will create a `.png` file that looks like this:

图 9.7–print mojo 实用程序的输出

![Figure 9.7 – Output of the PrintMojo utility
](img/Figure_9.7_B16721.jpg)

注意，如果您省略了`--tree 0`，您将生成一个包含所有树的目录。我们已经指定只返回第一个。

也可以用`dot`代替`--format`。这产生了一种第三方 **Graphviz** 实用程序可以使用的格式，使图形表示比*图 9.7* 中显示的更加美观。

或者，如果您希望将这个输出包含在编程中使用，对于`–format`，声明`.json`，它将文件输出为 JSON 格式。

有关更多详细信息和配置备选方案，请参见 H2O 文档:[https://docs . H2O . ai/H2O/latest-stable/H2O-docs/productionizing . html # viewing-a-mojo-model](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html#viewing-a-mojo-model)。

MOJO 和 POJO

## 好吧，让我们这么说吧:MOJO 不是唯一的 H2O 可部署工件。在 mojo 之前，只有`h2o-genmodel` API 来构建包装器类，正如我们之前讨论的。他们也有点不同。让我们比较，对比，总结。

MOJO 和 POJO 的相似之处

### 以下是 mojo 和 POJOs 的相似之处:

它们都是在构建模型后从 IDE 中导出的(或者从 H2O 流 UI 中导出)。

*   它们都以相同的方式部署:它们都运行在 JVM 中，根据目标评分系统(H2O 评分系统、第三方或您自己的软件程序)有包装器或无包装器的区别，它们都使用 MOJO 运行时(`h2o-genmodel.jar`)和相同的 API 和 Javadoc。
*   MOJO 和 POJO 的差异

### 以下是 mojo 和 POJOs 的区别:

POJO 导出为需要编译的单个`.java`文件，而 MOJO 导出为单个`.zip`文件，如前所述。

*   POJOs 包含整个树来导航模型，而 MOJOs 包含树元数据并在`h2o-genmodel.zip`中使用通用树遍历代码来导航模型。树结构越大，POJO 就越大。
*   POJOs 比 mojo 大得多(通常大 20-25 倍)，得分时比 mojo 慢(慢 2-3 倍)。一般来说，POJO 越大，它与任何基于相同模型构建的 MOJO 相比就越慢。
*   大型 POJOs 可能会有编译问题。H2O 不支持超过 1 GB 的 POJOs。
*   何时使用 MOJO 或 POJO

### 您应该将 POJOs 视为已弃用但仍受支持(除了大于 1GB)的，并且有时在边缘情况下需要。要知道 MOJOs 并不是所有算法都完全支持的，所以在这些情况下，你不得不使用 POJOs。因此，在可能的情况下使用 MOJOs，在不太可能的情况下使用 POJOs。

部署决策–MOJO 还是 POJO？

将 MOJOs 视为当前的首选技术，将 POJOs 视为与部署类似但已被弃用但仍受支持的技术(除了大于 1 GB 的技术)。MOJOs 的优势主要在于得分速度和占地面积。

某些算法不支持 MOJOs。查看 H2O 文档，了解当前对 MOJOs 和 POJOs 的支持注意事项。

我们现在准备总结。

总结

# 我们从从模型构建到模型部署的高层次视角开始了这一章。我们看到，MOJO 为 H2O 的这一过渡搭建了桥梁，MOJO 是一种可部署的已训练模型的表示形式，易于从模型构建中生成，并且易于部署以实现快速模型评分。

然后，我们仔细研究了 MOJOs 可以部署的目标系统的范围，发现这些系统必须在 Java 运行时中运行，否则就会非常多样化。MOJOs 可以在实时、批处理和流式系统上进行评分，分为 H2O 评分器(由 H2O 提供和支持的评分软件)、第三方集成(由 H2O 以外的公司提供和支持的软件)和您的软件集成(您构建和维护的软件)。

目标系统的这种分类有助于我们确定您是否可以直接部署导出的 MOJO，或者您是否需要使用`h2o-genmodel` API 将其包装在 Java 类中，以将其嵌入评分软件中。H2O 计分器和一些第三方计分器只需要导出的 MOJO，不需要实现包装器。

然后，我们详细研究了 MOJO 和 MOJO 运行时，以及它们与需要和不需要包装器的部署之间的关系。我们描述了 MOJO 包装器的一般结构，并编写了一个包装器来对文件中的记录进行批量评分。我们的编码让我们对 MOJO API 有了更好的理解，该 API 用于与您的应用中的 MOJO 进行交互。这种理解包括如何使用 API 来加载 MOJO、将数据结构化为 MOJO 可以使用的类型、使用 MOJO 进行评分，以及从评分结果中检索预测和原因代码。

然后，我们学习了如何在 MOJO API 中使用一个方便的工具来为您的模型获取 MOJO 中决策逻辑的可视化、JSON 或 dot 表示。

最后，我们介绍了 MOJO 的前身 POJO，并将其描述为在 MOJO API 的部署和使用方面与 MOJO 相似，但不赞成使用，但仍受支持，因此用于 MOJO 不能使用的少数情况。

现在，我们非常详细地了解了 MOJO，以及它是如何灵活地部署到各种生产评分系统的。让我们进入下一章，我们将通过描述这些系统上的具体 MOJO 部署来展示这种灵活性和多样性。

Now, we understand in great detail the MOJO and how it is flexibly deployed to a diversity of production scoring systems. Let's move to the next chapter where we will exhibit this flexibility and diversity by describing concrete MOJO deployments on a handful of these systems.**