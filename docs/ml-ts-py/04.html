<html><head/><body>









  <title>Chapter_4</title>

  

  

  







  <div><h1 class="chapterNumber">四</h1>

    <h1 id="_idParaDest-64" class="chapterTitle">时间序列的机器学习导论</h1>

    <p class="normal">在前几章中，我们已经讨论了时间序列、时间序列分析和预处理。在这一章，我们将讨论时间序列的机器学习。<strong class="keyword">机器学习</strong>是<a id="_idIndexMarker238"/>通过经验改进算法的研究。这些算法或模型可以基于数据做出系统的、可重复的、有效的决策。本章旨在介绍我们将在本书剩余部分使用的大部分内容的上下文和技术背景。</p>

    <p class="normal">我们将讨论机器学习在时间序列中的不同类型的问题和应用，以及与机器学习和时间序列分析相关的分析类型。我们将解释时间序列的主要机器学习问题，如预测、分类、回归、分割和异常检测。然后我们将回顾与时间序列相关的机器学习的基础知识。然后，我们将看看时间序列的机器学习的历史和当前用途。</p>

    <p class="normal">我们将讨论以下主题:</p>

    <ul>

      <li class="bullet">基于时间序列的机器学习<ul>

          <li class="bullet-l2">监督、非监督和强化学习</li>

          <li class="bullet-l2">机器学习的历史</li>

        </ul>

      </li>

      <li class="bullet">机器学习工作流<ul>

          <li class="bullet-l2">交叉验证</li>

          <li class="bullet-l2">时间序列的误差度量</li>

          <li class="bullet-l2">比较时间序列</li>

        </ul>

      </li>

      <li class="bullet">时间序列的机器学习算法</li>

    </ul>

    <p class="normal">我们将从时间序列的机器学习的一般介绍开始。</p>

    <h1 id="_idParaDest-65" class="title">基于时间序列的机器学习</h1>

    <p class="normal">在这一节中，我将介绍时间序列机器学习的应用和主要类别。</p>

    <p class="normal">时间序列的机器学习<a id="_idIndexMarker239"/>方法在经济学、医学、气象学、人口学等领域至关重要。时序数据集<a id="_idIndexMarker240"/>无处不在，出现在医疗保健、经济学、社会科学、物联网应用、运营管理、数字营销、云基础设施、机器人系统模拟等不同领域。这些数据集具有巨大的实际重要性，因为它们可以用来更有效地预测和预测异常检测，从而支持决策制定。</p>

    <p class="normal">时间序列机器学习的技术应用在技术上比比皆是。一些应用如下:</p>

    <ul>

      <li class="bullet">曲线拟合</li>

      <li class="bullet">回归</li>

      <li class="bullet">分类</li>

      <li class="bullet">预测</li>

      <li class="bullet">细分/聚类</li>

      <li class="bullet">异常检测</li>

      <li class="bullet">强化学习</li>

    </ul>

    <p class="normal">我们将在本书中研究这些技术应用。这些不同的应用程序背后有不同的统计方法和模型，它们可以重叠。</p>

    <p class="normal">让我们简单地浏览一下这些应用程序，以便在接下来的章节中对它们有一个大致的了解。</p>

    <p class="normal"><strong class="keyword">曲线拟合</strong>是将一个数学函数(一条曲线)拟合到一系列点的<a id="_idIndexMarker241"/>任务。该数学函数由参数定义，并且这些参数通过优化来适应时间序列。曲线拟合可用作图表上的视觉辅助或用于推断(外推法)。</p>

    <p class="normal"><strong class="keyword">回归</strong>是一个<a id="_idIndexMarker242"/>总括术语，指用于寻找自变量(特征)和自变量(目标)之间关系的统计方法。例如，我们可以根据二氧化碳和甲烷的释放来预测准确的温度。如果有一个以上的结果变量，这被称为多目标(或多输出)。这方面的一个例子是同时预测不同位置的温度。</p>

    <p class="normal">当问题是给一个时间序列(或其一部分)分配标签时，这被称为<strong class="keyword">分类</strong>。回归的主要区别在于预测是分类的而不是连续的。用于分类的模型通常被称为分类器。当恰好有两个类别时，分类可以是二元的；当有更多类别时，分类可以是多类别的。一个例子是在EEG信号中检测眼球运动或癫痫。</p>

    <p class="normal">对未来做出预测被称为预测。预测只能基于时间序列值本身或其他变量。这些技术可以从曲线拟合到外推，从当前趋势和可变性的分析到复杂的机器学习技术。例如，我们可以根据过去100年的数据预测全球气温，或者我们可以预测一个国家的经济状况。预测的反义词是<strong class="keyword">回溯</strong>，我们<a id="_idIndexMarker245"/>对过去做出预测。在我们有数据可用之前，我们可以回溯温度。</p>

    <p class="normal"><strong class="keyword">分段</strong>或<strong class="keyword">聚类</strong>，是将部分时间序列分组为不同状态、行为或基线的<a id="_idIndexMarker247"/>聚类(或段)的<a id="_idIndexMarker246"/>过程。一个例子是脑电波的不同活动水平。</p>

    <p class="normal">在<a id="_idIndexMarker248"/>时间序列的背景下，<strong class="keyword">异常检测</strong>，也称为<strong class="keyword">异常检测</strong>，是<a id="_idIndexMarker249"/>识别罕见或异常事件的任务。这些可能是新奇的，政权的变化，噪音，或者只是例外。一个相当简单的例子是电压突然下降时可以检测到的电网断电。举例来说，更微妙的可能是在某段时间内呼叫中心的呼叫数量的增加。在这两种情况下，异常检测都可以提供可操作的业务洞察。异常检测技术的范围从简单的阈值或统计到一组规则，再到基于时间序列分布的基于模式的方法。</p>

    <p class="normal">最后，<strong class="keyword">强化学习</strong>是基于从一系列决策中获得最大预期回报的<a id="_idIndexMarker250"/>学习实践。强化学习算法被用在高度不确定的环境中。这可能意味着条件不稳定(高度变化)或普遍缺乏信息。应用程序是股票交易或一般拍卖中的投标和定价算法，以及控制任务。</p>

    <p class="normal">让我们深入了解一下这些术语的含义。</p>

    <h2 id="_idParaDest-66" class="title">监督、非监督和强化学习</h2>

    <p class="normal">机器<a id="_idIndexMarker251"/>学习<a id="_idIndexMarker252"/>可以大致分为有监督、无监督和<a id="_idIndexMarker253"/>强化学习，如下图所示:</p>

    <figure class="mediaobject"><img src="img/B17577_04_01.png" alt="taxonomy.png"/></figure>

    <p class="packt_figref">图4.1:将机器学习分类</p>

    <p class="normal">在<strong class="keyword">监督</strong>学习中，特征<a id="_idIndexMarker254"/>在一个被称为<strong class="keyword">预测</strong>的过程<a id="_idIndexMarker256"/>中被映射<a id="_idIndexMarker255"/>到结果<img src="img/B17577_04_001.png" alt="" style="height: 1em;"/>(有时是<strong class="keyword">推理</strong>)。</p>

    <p class="normal">在有监督的情况下，参数是从标记的观察值中估计的。我们需要将每个观察的结果作为<strong class="keyword">目标</strong>列(或复数列)提供。</p>

    <p class="normal">因此，机器学习算法找到了从X到y的映射。</p>

    <figure class="mediaobject"><img src="img/B17577_04_002.png" alt="" style="height: 2em;"/></figure>

    <p class="normal">函数<img src="img/B17577_04_003.png" alt="" style="height: 1em;"/>只是输入分布X到输出分布y的一种可能的映射或模型</p>

    <p class="normal">监督机器学习<a id="_idIndexMarker257"/>可以分为分类和<a id="_idIndexMarker258"/>回归。在回归中，我们的目标是连续的，目标是预测值。</p>

    <figure class="mediaobject"><img src="img/B17577_04_004.png" alt="" style="height: 2em;"/></figure>

    <p class="normal">目标Y可以是实值，可以是单个值，也可以是更高维度(多输出)。</p>

    <p class="normal">标注在长度上与数据集匹配，但是每个观测值也可以有多个标注(多输出)。</p>

    <p class="normal">一个例子是某一天商店售出的产品数量或下个月通过管道输送的石油数量。这些特征可以包括当前销售、需求或一周中的某一天。</p>

    <p class="normal">在<strong class="keyword">分类</strong>中，目标是预测观察值的类别。在这种情况下，<img src="img/B17577_04_005.png" alt="" style="height: 1em;"/>可以从<a id="_idIndexMarker259"/>分类分布中提取，分类分布由序数值组成，例如，像<img src="img/B17577_04_006.png" alt="" style="height: 1em;"/>中的整数。</p>

    <p class="normal">有时，我们希望找到一个函数，它能给出给定观察值的概率或分数:</p>

    <figure class="mediaobject"><img src="img/B17577_04_007.png" alt="" style="height: 1.8em;"/></figure>

    <p class="normal">在实践中，回归和<a id="_idIndexMarker260"/>分类是非常相似的问题，通常<a id="_idIndexMarker261"/>回归和分类算法可以互换使用。然而，理解这种区别对于以适当的方式处理任何特定的问题是至关重要的。</p>

    <p class="normal">在时间序列<strong class="keyword">预测</strong>中，将<a id="_idIndexMarker262"/>历史值外推至未来。唯一的特征是过去的值。例如，我们可以根据过去两年的呼叫量来估计下个月呼叫中心的呼叫量。预测任务可以是单变量的，依赖并推断单个特征，或者是多变量的，其中多个特征被预测到未来。</p>

    <p class="normal">在<strong class="keyword">无监督</strong>学习中，<a id="_idIndexMarker263"/>算法的任务是根据观察值的特征对其进行分类。无监督学习的例子是聚类或推荐算法。</p>

    <p class="normal">在本书的大部分内容中，我们将讨论有监督的算法，尽管我们也将讨论无监督的任务，如变化检测和聚类。</p>

    <p class="normal">映射函数f预测一个结果<img src="img/B17577_04_008.png" alt="" style="height: 1em;"/>每个函数由一组参数指定，并且优化产生一组使Y和<img src="img/B17577_04_009.png" alt="" style="height: 1em;"/>之间的失配最小化的参数。通常，这是启发式的。</p>

    <p class="normal">Y和<img src="img/B17577_04_010.png" alt="" style="height: 1em;"/>之间的匹配(不匹配)由误差函数<img src="img/B17577_04_011.png" alt="" style="height: 1em;"/>测量，因此优化包括估算函数f的参数<img src="img/B17577_04_012.png" alt="" style="height: 1em;"/>，使误差最小化:</p>

    <figure class="mediaobject"><img src="img/B17577_04_013.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">在这个公式中，由于<a id="_idIndexMarker264"/>误差函数是优化的一部分，<img src="img/B17577_04_014.png" alt="" style="height: 1em;"/>被称为<strong class="keyword">目标函数</strong>。</p>

    <p class="normal">在<strong class="keyword">强化学习</strong>中，<a id="_idIndexMarker265"/>智能体通过行动与环境互动，并以<a id="_idIndexMarker266"/>奖励的形式获得反馈。你可以在<em class="chapterRef">第十一章</em>、<em class="italic">时序强化学习</em>中找到更多关于时序强化学习的内容。</p>

    <p class="normal">与监督学习中的情况相反，没有标记的数据可用，而是基于对累积回报的期望来探索和利用环境。</p>

    <p class="normal"><strong class="keyword">机器学习</strong>，对随着经验而改进的算法的研究<a id="_idIndexMarker267"/>，可以追溯到20世纪60年代，那时统计方法(在<em class="chapterRef">第1章</em>、<em class="italic">用Python </em>讨论)被发现。让我们从机器学习的简史开始，给出一些背景。这将提供更多的术语和机器学习主要方向的基本概念。我们将在适当的章节中给出一些更详细的上下文。</p>

    <h2 id="_idParaDest-67" class="title">机器学习的历史</h2>

    <p class="normal">1943年，沃伦·麦卡洛克和沃尔特·皮茨将生物神经网络概念化为一种数学模型，这是人工神经网络的基础。</p>

    <p class="normal">弗兰克·罗森布拉特(Frank Rosenblatt)在1958年开发了<a id="_idIndexMarker269"/>所谓的<strong class="keyword">感知器</strong>，用今天的话来说就是<strong class="keyword">全连接前馈神经网络</strong>。这个示意图显示了一个带有<a id="_idIndexMarker270"/>两个输入神经元和一个输出神经元的感知器(基于维基共享资源上的一张图片):</p>

    <figure class="mediaobject"><img src="img/B17577_04_03.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_SIwGeX/Screenshot 2021-08-15 at 18.23.06.png"/></figure>

    <p class="packt_figref">图4.3:感知器</p>

    <p class="normal">到输出神经元<em class="italic"> y </em>的连接具有权重<em class="italic">w</em>T26】1和<em class="italic">w</em>T30】2。这是一个简单的线性模型。</p>

    <p class="normal">另一个重要的步骤是<a id="_idIndexMarker271"/>错误如何通过网络向后传播。亨利·j·凯利不久后(1960年)出版了《反向传播基础知识》( T33)作为训练这些网络的机制。</p>

    <p class="normal">然而，当马文·明斯基和西蒙·派珀特在1969年出版了《感知机》<em class="italic"/>一书时，这项研究受到了严重的打击，这本书简单地证明了线性函数(如在2层感知机中)不能模拟非线性函数。根据作者的说法，这意味着感知器在实践中不会有用或有趣。感知机可以有两层以上，其参数可以通过反向传播来学习，这一事实在书中被掩盖了。人工神经网络的研究直到20世纪80年代才再次兴起。</p>

    <p class="normal">最近邻算法是由Evelyn Fix和Joseph Hodges在1951年描述的<a id="_idIndexMarker273"/>，然后在1967年由Thomas Cover和Peter E. Hart扩展。最近邻算法可以应用于分类和回归。它通过检索新数据点和数据集中所有已知实例之间的k个最相似实例来工作(k是一个参数)。在分类的情况下，算法投票给最频繁的标签；在回归的情况下，它对标签进行平均。</p>

    <p class="normal">另一个重要的里程碑是决策树算法的发展。ID3决策树算法(迭代二分法3)由Ross Quinlan在1979年的一篇论文中发表，是今天使用的决策树的前身。</p>

    <p class="normal"><strong class="keyword"> CART </strong>算法(<strong class="keyword">分类和回归树</strong>)由Leo Breiman于1984年发表<a id="_idIndexMarker274"/>。ID3的<a id="_idIndexMarker275"/>后代<strong class="keyword"> C4.5 </strong>算法于1992年问世(Ross Quinlan)，今天被视为机器学习的里程碑。</p>

    <p class="normal">决策树的革命性之处在于它由阶跃函数组成，这些函数将数据点的特征空间划分为具有相似结果的口袋。虽然许多机器学习算法在有许多交互需要考虑时会遇到困难，但决策树在这些情况下会茁壮成长。下图说明了决策树<a id="_idIndexMarker276"/>的样子:</p>

    <figure class="mediaobject"><img src="img/B17577_04_04.png" alt="../../../../Desktop/Screenshot%202021-04-26%20at%2000.09"/></figure>

    <p class="packt_figref">图4.4:决策树</p>

    <p class="normal">树中的每个节点或分割是基于特性值的单个问题。在树构造期间的每次迭代中，应用称为分裂标准的统计函数来决定要查询的最佳特征。分割标准的典型选择是基尼系数或信息熵，这两者都可以最小化分支内目标的可变性。</p>

    <p class="normal">决策树反过来又构成了集成技术的基础，如随机森林或梯度提升树。主要有两种合奏技术:助推<a id="_idIndexMarker278"/>和装袋。<strong class="keyword"> Boosting </strong>是罗伯特·沙皮雷在1990年发明的，由一个级联的增量式<a id="_idIndexMarker279"/>增加基础学习者组成。一个<strong class="keyword">基础学习器</strong>(也叫<strong class="keyword">弱学习器</strong>)是一个非常<a id="_idIndexMarker280"/>简单的模型，它本身与目标只有微弱的关联<a id="_idIndexMarker281"/>。每次向现有基础学习者添加新的基础学习者时，训练集中数据点的重要性(权重)都会重新平衡。</p>

    <p class="normal">这意味着在每次迭代中，算法会处理越来越多的样本，从而提高基础学习者的精确度。</p>

    <p class="normal">这形成了自适应增强算法<strong class="keyword"> AdaBoost </strong>的基础<a id="_idIndexMarker282"/>，该算法为其发明者Yoav Freund和Robert Schapire赢得了哥德尔奖，这是对理论计算机科学领域杰出论文的著名认可。</p>

    <p class="normal">此图(来自维基百科)显示了每个基本分类器随后如何在数据集的不同子集上进行训练，其中每个新训练的权重都有所变化:</p>

    <figure class="mediaobject"><img src="img/B17577_04_05.png" alt="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Ensemble_Boosting.svg/1024px-Ensemble_Boosting.svg.png"/></figure>

    <p class="packt_figref">图4.5:增强</p>

    <p class="normal"><strong class="keyword">装袋</strong>是随机森林的<a id="_idIndexMarker283"/>基础，1994年由Leo Breiman发明。打包由两部分组成，引导和聚集。<strong class="keyword"> Bootstrapping </strong>是用来自训练集的替换对<a id="_idIndexMarker284"/>进行采样。可以对每个样本单独训练一个单独的模型。这些模型共同组成了一个整体。然后，可以将单个模型的预测汇总成一个组合决策，例如，通过取平均值。</p>

    <p class="normal">下图(来源:维基百科)显示了如何训练袋装集合并用于预测。这就是一个<strong class="keyword">随机森林</strong> (Leo Breiman，2001)如何以决策树作为基础学习者来学习<a id="_idIndexMarker285"/>。</p>

    <figure class="mediaobject"><img src="img/B17577_04_06.png" alt="https://upload.wikimedia.org/wikipedia/commons/b/bd/Bagging_for_Classification_with_descripitons.png"/></figure>

    <p class="packt_figref">图4.6:装袋</p>

    <p class="normal">下表显示了<a id="_idIndexMarker286"/>装袋和增压的主要区别:</p>

    <table id="table001-2" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"/>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">制袋材料</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">助推</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基础学习者接受培训:</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">独立学习(可以并行学习)</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">继续地</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">重量为:</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">保持不变</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">每次迭代后都改变</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基础学员的权重为:</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">平等地</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">根据训练表现</p>

          </td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.7:装袋和增压之间的区别</p>

    <p class="normal"><strong class="keyword">梯度增强</strong>(由Friedman等人开发)是使用非hyphenate的增强的进一步扩展。在<a id="_idIndexMarker287"/>梯度增强中，以与损失函数的负梯度最大相关的方式添加新的弱学习器。以下是梯度增强树的一些流行实现<a id="_idIndexMarker288"/>:</p>

    <ul>

      <li class="bullet">CatBoost(Yandex的安德烈·谷林和其他人)</li>

      <li class="bullet">光梯度推进机(微软的LightGBM)</li>

      <li class="bullet">XGBoost</li>

    </ul>

    <p class="normal">反向传播在1986年被大卫·鲁梅尔哈特、杰弗里·辛顿和罗纳德·j·威廉姆斯重新发现。不久之后，更深层次的网络被开发出来，可以应用于更有趣的吸引注意力的问题。</p>

    <p class="normal">1995年至1997年间，塞普·霍克雷特(Sepp Hochreiter)和于尔根·施密德胡伯(Jürgen Schmidhuber)提出了一种递归神经网络架构，即<strong class="keyword">长短期记忆</strong> ( <strong class="keyword"> LSTM </strong>)。多年来，LSTMs为语音识别、翻译等许多应用提供了最先进的<a id="_idIndexMarker290"/>。今天，递归神经网络已经在很大程度上被变压器或神经网络所取代，甚至用于序列建模任务。随着LSTM对计算资源的高需求，一些人甚至认为LSTM已经过时了。</p>

    <p class="normal"><strong class="keyword">支持向量机</strong> ( <strong class="keyword"> SVMs </strong>)是由Vladimir Vapnik和他的同事基于Vapnik和Chervonenkis描述的统计学习框架于20世纪90年代早期在贝尔实验室开发的<a id="_idIndexMarker291"/>。在分类中，支持向量机最大化投影空间中两个类别之间的距离。作为训练的一部分，构建了一个超平面，称为支持向量，用于分离正例和负例。</p>

    <p class="normal">在下一节中，我们将介绍机器学习建模的基础知识和模型验证的科学实践。</p>

    <h1 id="_idParaDest-68" class="title">机器学习工作流</h1>

    <p class="normal">在下一节中，我们将介绍时间序列和机器学习的基础知识。</p>

    <p class="normal">机器学习主要处理<a id="_idIndexMarker292"/>数字数据，这些数据以表格形式显示为大小为<img src="img/B17577_04_015.png" alt="" style="height: 0.8em;"/>的矩阵。布局一般是每行<img src="img/B17577_04_016.png" alt="" style="height: 1em;"/>代表一个观察，每列<img src="img/B17577_04_017.png" alt="" style="height: 1em;"/>代表一个特征。</p>

    <p class="normal">在时序问题中，与时间相关的列不一定作为特征，而是作为对数据集进行切片和排序的索引。然而，时间列可以被转换成特征，正如我们将在第3章、<em class="italic">预处理时间序列</em>中看到的。</p>

    <p class="normal">每个观察由M个特征的向量来描述。虽然一些机器学习算法可以在内部处理非数字数据，但通常情况下，每个特征要么是数字，要么在输入机器学习算法之前被转换为数字。转换的一个例子是将男性表示为0，女性表示为1。简而言之，每个特性可以定义如下:</p>

    <figure class="mediaobject"><img src="img/B17577_04_018.png" alt="" style="height: 2em;"/></figure>

    <p class="normal">机器学习工作流程<a id="_idIndexMarker293"/>可以分为三个过程，如下图所示。我添加了数据加载和时间序列分析，这通知了机器学习。</p>

    <figure class="mediaobject"><img src="img/B17577_04_07.png" alt="machine_learning_workflow_cropped.png"/></figure>

    <p class="packt_figref">图4.8:机器学习工作流程</p>

    <p class="normal">我们首先必须转换(或预处理)我们的数据，训练或拟合模型，然后我们可以将训练好的模型应用于新数据。这个图表，可能非常简单，把重点放在机器学习过程的三个不同阶段。对于时序数据来说，每个阶段都有自己的挑战和特殊性。</p>

    <p class="normal">这也有助于思考从输入到转换到训练再到预测的数据流。我们应该记住可用的历史数据及其局限性，以及用于预测的未来数据点。</p>

    <p class="normal">在下一节中，我们将讨论交叉验证的一般原则。</p>

    <h2 id="_idParaDest-69" class="title">交叉验证</h2>

    <p class="normal">乔治·博克斯在《机器学习》中有一句名言，我们在本书中已经见过他几次:“所有的模型都是错的，但有些是有用的。”</p>

    <p class="normal">机器学习算法可以做出可重复的决策，如果控制正确，这些决策可以摆脱人类决策中的认知偏见。重点是通过验证性能来确保我们的<a id="_idIndexMarker296"/>模型是有用的。在机器学习中，对训练中没有见过的数据测试模型的过程称为交叉验证(有时，<strong class="keyword">样本外测试</strong>)。</p>

    <p class="normal">为了确保在有限大小的数据集上估计的参数对于更多的数据仍然有效，我们必须通过验证来确保质量。为了验证，我们通常将数据集分成至少两部分，训练集和测试集。我们在训练集上估计参数，然后在测试集上运行模型，以了解模型在看不见的数据点上的质量。下图对此进行了说明:</p>

    <figure class="mediaobject"><img src="img/B17577_04_08.png" alt=""/></figure>

    <p class="packt_figref">图4.9:交叉验证</p>

    <p class="normal">通常，在机器学习中，我们会在训练和测试之间分开之前随机洗牌。然而，在时间序列中，我们会用旧的数据点进行训练，用新的数据点进行测试。例如，有了1年的客户电子邮件打开倾向数据，我们将在9个月的数据上训练模型，在2个月的数据上验证我们的模型，并在数据集上测试最终性能。</p>

    <p class="normal">在测试集检查涉及验证数据集的主测试过程的意义上，验证和测试的使用可以被视为嵌套过程。通常，验证集和测试集的分离会被忽略，因此数据集只分为定型集和测试集。</p>

    <p class="normal">关于术语的一个注意事项:当一个<strong class="keyword">损失函数</strong>是用于训练你的模型的优化的<a id="_idIndexMarker297"/>部分时，一个<strong class="keyword">度量</strong>是用于评估你的模型的<a id="_idIndexMarker298"/>。评估可以是事后的、培训后的或培训期间的，作为附加信息。在这一节中，我们将讨论度量和损失函数。</p>

    <p class="normal">在项目开始时评估如何度量性能是一个好的实践。我们需要选择如何衡量绩效，以将业务问题转化为衡量标准或损失。有些算法允许灵活选择目标函数，有些则不允许，但是我们可以用不同的度量来衡量性能。</p>

    <p class="normal">接下来，我们将讨论回归和分类的误差和损失度量。</p>

    <h2 id="_idParaDest-70" class="title">时间序列的误差度量</h2>

    <p class="normal">时序数据被定义为一组包含不同时间点细节的数据点。通常，时间序列数据包含以相等的时间间隔采样或观察的数据点。</p>

    <p class="normal">对于我们之前讨论的不同应用程序，我们需要能够量化模型的性能，无论是回归、分类还是其他类型的模型，并选择一个度量来捕获我们想要实现的性能。一旦我们为模型选择了度量标准，我们就可以构建和训练模型来改进它们。通常，我们会从一个更简单的模型开始，然后尝试改进这个更简单模型的性能作为基线。最后，我们希望根据我们的度量找到最好的模型。</p>

    <p class="normal">在这一部分，我们将讨论常用的性能指标及其属性。通常，对于一个误差度量，值越小，预测(或预报)越好。在改变我们模型的参数时，我们想减少误差。</p>

    <p class="normal">对于任何任意应用程序或数据集来说，都没有一个合适的指标。根据数据集的不同，您可能需要搜索和尝试不同的误差指标，看看哪一个最能抓住您的目标。在某些情况下，您甚至可能想要定义自己的度量标准。</p>

    <h3 id="_idParaDest-71" class="title">回归</h3>

    <p class="normal">时间序列回归<a id="_idIndexMarker300"/>的任务是识别与时间序列行为相关的特征中的模式和信号，例如，技能如何随着实践投入的时间而提高。</p>

    <p class="normal">在训练期间，当您的<a id="_idIndexMarker301"/>回归模型给出训练集的结果时，我们可以利用一个将模型输出与训练集值进行比较的指标，并且在验证期间，我们可以计算相同的度量，以了解我们的回归预测符合验证集目标的程度。误差度量总结了机器学习模型预测的值与实际值之间的差异。</p>

    <p class="normal">如果<img src="img/B17577_04_019.png" alt="" style="height: 1em;"/>是<a id="_idIndexMarker303"/>的<a id="_idIndexMarker302"/>预测，时间步长<em class="italic"> t </em>的模型<a id="_idIndexMarker304"/>，实际目标值是<em class="italic">y</em>T8】t，直观上，对于我们数据集的某个特定点<em class="italic"> t </em>，预测误差<strong class="keyword"/>(也称为<strong class="keyword">预测误差</strong>或<strong class="keyword">残差</strong>)是目标的实际值与我们的模型预测值之间的差值:</p>

    <figure class="mediaobject"><img src="img/B17577_04_020.png" alt="" style="height: 2em;"/></figure>

    <p class="normal">这将实际目标Y与预测目标进行比较<img src="img/B17577_04_021.png" alt="" style="height: 1em;"/>。根据该公式，如果预测值比实际目标值高<a id="_idIndexMarker305"/>，则误差为负。残差的<strong class="keyword">平方和</strong> (SS，也称<strong class="keyword">残差平方和</strong>)忽略了误差的方向:</p>

    <figure class="mediaobject"><img src="img/B17577_04_022.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">虽然残差和残差平方和已经可以用来衡量时间序列的预测性能，但它们通常不被用作回归度量或损失。</p>

    <p class="normal">让我们从最常用的回归度量标准<a id="_idIndexMarker306"/>开始:决定系数<strong class="keyword"/>。这是一个相对简单的公式，基于残差的平方和SS与总平方和TSS的比值，TSS是可变性的一种度量:</p>

    <figure class="mediaobject"><img src="img/B17577_04_023.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">在这个分数中，提名者是残差的平方和，SS，无法解释的方差。</p>

    <p class="normal">分母是TSS，平方和。这被定义为<img src="img/B17577_04_024.png" alt="" style="height: 3.5em;"/>，其中<img src="img/B17577_04_025.png" alt="" style="height: 1em;"/>是数列的平均值，<img src="img/B17577_04_026.png" alt="" style="height: 3em;"/>。总平方和代表时间序列的解释方差。</p>

    <p class="normal">基本上，我们测量的是残差平方和与时间序列总方差的关系。这个分数介于0和1之间，其中0是最好的，没有任何误差，通过从1中减去来反转，因此最终0是最差的，1是最好的。</p>

    <p class="normal">展开后，如下所示:</p>

    <figure class="mediaobject"><img src="img/B17577_04_027.png" alt="" style="height: 3em;"/></figure>

    <p class="normal"><img src="img/B17577_04_028.png" alt="" style="height: 1em;"/>表示从自变量可预测的因变量方差的比例。如上所述，它介于0和1之间，其中1表示有完美的关系，0表示没有任何关系。</p>

    <p class="normal"><a id="_idIndexMarker307"/>决定系数<img src="img/B17577_04_029.png" alt="" style="height: 1em;"/>不是一个误差测量值，因为误差测量值表示残差的分布，因此高是坏的，低是好的。然而，我们可以表达一个误差度量，让我们称之为<a id="_idIndexMarker308"/>的<strong class="keyword">r-误差(RE) </strong>，与上面的非常相似，如下所示:</p>

    <figure class="mediaobject"><img src="img/B17577_04_030.png" alt="" style="height: 3em;"/></figure>

    <p class="normal">这个在实际中很少用到<a id="_idIndexMarker309"/>。与re非常相似的一个误差度量是<strong class="keyword">平均相对绝对误差</strong> ( <strong class="keyword"> MRAE </strong>)，我们将在后面进一步讨论。</p>

    <p class="normal">天真地说，我们可以取平均误差，取预测误差的平均值——平均误差:</p>

    <figure class="mediaobject"><img src="img/B17577_04_031.png" alt="" style="height: 3.2em;"/></figure>

    <p class="normal">这里，<em class="italic"> N </em>是点数(或离散时间步数)。我们计算每个点的误差，然后取所有这些误差的平均值。</p>

    <p class="normal">如果ME是正的，模型系统地低估了目标，如果它是正的，它总体上高估了目标。虽然这很有用，但是对于误差度量来说，这是一个严重的问题，因为正负误差的影响会相互抵消。因此，较低的ME并不意味着预测是好的，而是平均值接近于零。</p>

    <p class="normal">此外，大多数回归模型包含一个等于目标平均值的常数项，因此该值正好为0。总之，我们的天真措施在实际环境中毫无用处。</p>

    <p class="normal">我已经包括了ME，用于讨论为什么大多数常用的度量放弃了错误的方向，以及强调基本错误度量的主要组成部分的重要性:</p>

    <ul>

      <li class="bullet">剩余操作</li>

      <li class="bullet">整合</li>

    </ul>

    <p class="normal">在ME的情况下，残差操作是identify函数，这意味着残差不会改变。更多情况下，使用平方或绝对值函数。误差的积分通常是(算术)平均值，但有时是中值；然而，它可以是更复杂的操作。</p>

    <p class="normal">实际上，<a id="_idIndexMarker310"/>最常见的误差<a id="_idIndexMarker311"/>指标是均方误差(MSE)、平均绝对误差(MAE)和均方根误差(RMSE)。下表定义了这些最重要的<a id="_idIndexMarker312"/>误差指标:</p>

    <table id="table002-1" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">度量名称</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">定义</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">均方误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_032.png" alt="" style="height: 1.76em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">平均绝对误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_033.png" alt="" style="height: 1.76em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">均方根误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"><img src="img/B17577_04_034.png" alt="" style="height: 0.76em;"/>T2】</figure></td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.10:流行的回归度量</p>

    <p class="normal">使用<strong class="keyword">均方误差(MSE) </strong>，我们<a id="_idIndexMarker313"/>计算每个点的残差，然后将它们平方，这样正负误差就不会相互抵消。然后我们取这些平方误差的平均值。MSE为0表示性能完美。这可能发生在玩具数据集上，你可以拿它来玩玩；然而，在实践中，只有当您在构建数据集或验证时犯了错误，才会发生这种情况，因为现实生活总是比您可以用模型捕捉到的更复杂。</p>

    <p class="normal"><strong class="keyword">平均绝对误差(MAE) </strong>与MSE<a id="_idIndexMarker314"/>非常相似，只是我们不是对残差求平方，而是取它们的绝对值。与MSE相反，所有误差都是线性比例的(而不是平方的)。</p>

    <p class="normal">取绝对值和取平方的主要区别在于如何处理异常值或极值。平方函数对差异很大的值施加较高的权重。对于MSE，误差以二次方增长，而不是像MAE那样以线性增长。这意味着MSE对极值的惩罚要强烈得多，因此，与MAE相比，它对数据集中的异常值不太稳健。在选择适合工作的误差度量时，误差的分布是一个主要考虑因素。</p>

    <p class="normal">另一个常见指标是<a id="_idIndexMarker315"/><strong class="keyword">均方根误差(RMSE) </strong>，或<strong class="keyword">均方根偏差(RMSD)</strong>，顾名思义，就是<a id="_idIndexMarker316"/> MSE的平方根。从这个意义上说，RMSE是MSE的缩小版。在两者之间选择哪一个是一个表示选择——两者都会导致相同的模型。</p>

    <p class="normal">作为一种选择，RMSE的有趣之处在于它与预测变量具有相同的单位和比例，这使得它更加直观。最后，RMSE相当于标准差或误差。标准偏差和误差分布之间的这种联系非常有意义，您可以用标准误差或置信区间等其他度量来总结误差分布(这两者我们已经在<em class="chapterRef">第2章</em>、<em class="italic">使用Python进行时间序列分析</em>中讨论过)。</p>

    <p class="normal">还有更多的指标，它们都有自己的用途。下表总结了时间序列建模中一些比较流行的误差指标:</p>

    <table id="table003" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">度量名称</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">定义</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">中位数绝对误差</p>

          </td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_035.png" alt="" style="height: 1.5em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">平均绝对百分比误差</p>

          </td>

          <td class="No-Table-Style"><figure class="mediaobject"><img src="img/B17577_04_036.png" alt="" style="height: 4.22em;"/>T2】</figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">对称平均绝对百分比误差</p>

          </td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_037.png" alt="" style="height: 4.22em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">归一化均方误差</p>

          </td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_038.png" alt="" style="height: 2.7em;"/> </figure></td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.11:回归的更多度量</p>

    <p class="normal"><strong class="keyword">中值绝对误差(MdAE) </strong>与MAE<a id="_idIndexMarker317"/>相似。然而，代替积分的平均运算，采用了不同的平均值，即中值。由于中位数不受尾部值的影响，这种方法甚至比MAE更稳健。</p>

    <p class="normal"><strong class="keyword">平均百分比误差(MAPE) </strong>是<a id="_idIndexMarker318"/>由目标标准化的平均误差。0代表完美的模型，高于1意味着模型的预测系统地高于目标。MAPE没有上限。此外，由于它根据目标(缩放或除以目标)处理百分比，正残差和负残差被不同地处理。因此，如果预测值大于目标值，则MAPE会高于另一个方向上相同误差的值。因此，根据残差的符号，MAPE更高或更低！</p>

    <p class="normal">分母的共同选择是目标；但是，您也可以通过预测和<a id="_idIndexMarker319"/>目标的平均值进行缩放。这被称为<strong class="keyword">对称平均绝对百分比误差(SMAPE) </strong>。SMAPE不仅有一个下限，还有一个上限，这使得百分比更容易解释。</p>

    <p class="normal">缩放也有不同的好处。如果您想要比较在不同数据集上验证的模型，前面介绍的方法不会有帮助。定型集、验证集和测试集之间的划分是随机的，因此当您比较模型性能时，任何这些度量都会混淆验证集中数据集方差的影响和模型性能本身的影响。</p>

    <p class="normal">因此，<strong class="keyword">归一化均方误差(NMSE) </strong>比<a id="_idIndexMarker320"/> MSE更直观，因为它用偏差来衡量模型的性能。NMSE对除以目标方差后获得的MSE进行归一化。</p>

    <p class="normal">还有很多其他的误差测量方法。一些误差测量将预测与返回平均目标值的简单模型的预测进行比较。</p>

    <p class="normal">这个简单模型的预测性能是:</p>

    <figure class="mediaobject"><img src="img/B17577_04_039.png" alt="" style="height: 3.5em;"/></figure>

    <p class="normal">我们可以通过将预测误差除以这个假设的预测误差来归一化预测误差。</p>

    <p class="normal">这样，我们可以<a id="_idIndexMarker321"/>定义其他几个度量:</p>

    <table id="table004" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject"> <strong class="keyword">公制名称</strong> </figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <strong class="keyword">定义</strong> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">平均相对绝对误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_040.png" alt="" style="height: 4.5em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">中值相对绝对误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_041.png" alt="" style="height: 3.33em;"/> </figure></td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style"><figure class="mediaobject">相对均方根误差</figure></td>

          <td class="No-Table-Style"><figure class="mediaobject"> <img src="img/B17577_04_042.png" alt="" style="height: 6.11em;"/> </figure></td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.12:标准化回归度量</p>

    <p class="normal">如果您对天真模型有所了解，并且希望通过除法比较具有相同误差度量的天真模型的性能，那么所有这些度量都应该是直观的。</p>

    <p class="normal"><strong class="keyword">平均相对绝对误差</strong> ( <strong class="keyword"> MRAE </strong>)与决定系数非常相似，唯一的区别是<a id="_idIndexMarker322"/>MRAE取平均值而不是总和。</p>

    <p class="normal">另一个误差是<a id="_idIndexMarker323"/><strong class="keyword">均方根对数误差</strong> ( <strong class="keyword"> RMSLE </strong>)。</p>

    <table id="table005" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-"><strong class="keyword">度量名称</strong></p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-"><strong class="keyword">定义</strong></p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">均方根对数误差</p>

          </td>

          <td class="No-Table-Style"><figure class="mediaobject">T38</figure></td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.13:均方根对数误差</p>

    <p class="normal">在RMSLE的情况下，您将残差的对数作为基本操作。这是为了避免在预测值和真实值都非常高的情况下，对误差中的较大差异进行惩罚。由于对数的拐点在1，RMLSE具有独特的性质，它对实际值低估的惩罚比对高估的惩罚更严重。当误差分布不遵循类似于我们在<em class="chapterRef">第3章</em>、<em class="italic">预处理时间序列</em>中讨论的缩放操作的正态分布时，这可能是有用的。</p>

    <p class="normal">如果我们考虑基于熵的度量，比如泰尔的不确定性，我们可以扩展度量的数量。<strong class="keyword">泰尔的U </strong>是总预测误差的<a id="_idIndexMarker324"/>标准化度量。u介于0和1之间，其中0表示完全适合。它基于条件熵的概念，也可以用作不确定性的度量，甚至可以用作分类-分类情况下的相关性度量。</p>

    <p class="normal">正如这些标题所说，前两个集中于量化模型的性能。最后一部分对于基于距离的模型很有用，它通常被用作性能的坚实基线。</p>

    <p class="normal">让我们切换到分类任务的错误度量。</p>

    <h3 id="_idParaDest-72" class="title">分类</h3>

    <p class="normal">许多度量特定于更多的<a id="_idIndexMarker325"/>二进制分类(其中正好有两个类)，尽管其中一些可以扩展到多类分类的情况，其中类的数量大于两个。</p>

    <p class="normal">在二元分类中，我们可以在<strong class="keyword">混淆矩阵</strong>中将预测与实际结果进行对比，其中<a id="_idIndexMarker326"/>预测与实际结果交叉列表如下:</p>

    <table id="table006" class="Basic-Table _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="Basic-Table">

          <td class="Basic-Table"/>

          <td class="Basic-Table"/>

          <td class="Basic-Table" colspan="2"><figure class="mediaobject"> <strong class="keyword">实际结局</strong> </figure></td>

        </tr>

        <tr class="Basic-Table">

          <td class="Basic-Table"/>

          <td class="Basic-Table"/>

          <td class="Basic-Table"><figure class="mediaobject">假</figure></td>

          <td class="Basic-Table"><figure class="mediaobject">真</figure></td>

        </tr>

        <tr class="Basic-Table">

          <td class="Basic-Table" rowspan="2"><figure class="mediaobject"> <strong class="keyword">预测结果</strong> </figure></td>

          <td class="Basic-Table"><figure class="mediaobject">假</figure></td>

          <td class="Basic-Table"><figure class="mediaobject">真阴性(TN) </figure></td>

          <td class="Basic-Table"><figure class="mediaobject">假阴性(FN) </figure></td>

        </tr>

        <tr class="Basic-Table">

          <td class="Basic-Table"><figure class="mediaobject">真</figure></td>

          <td class="Basic-Table"><figure class="mediaobject">假阳性(FP) </figure></td>

          <td class="Basic-Table"><figure class="mediaobject">真阳性(TP) </figure></td>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.14:混淆矩阵</p>

    <p class="normal">对于分类任务来说，这是一个至关重要的可视化，许多措施都是基于总结这一点。</p>

    <p class="normal">分类的两个最重要的指标是精确度和召回率。<strong class="keyword">召回</strong>是所有<a id="_idIndexMarker327"/>阳性实例中正确预测的阳性实例数量的比率。我们也可以用混淆矩阵来说明这一点，如下所示:</p>

    <figure class="mediaobject"><img src="img/B17577_04_044.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">召回率<a id="_idIndexMarker328"/>也被称为<strong class="keyword">真阳性率</strong>或<strong class="keyword">灵敏度</strong>。它专注于真实的预测，忽略了<a id="_idIndexMarker329"/>负面的实例；然而，我们可能也想知道积极的<a id="_idIndexMarker330"/>预测有多准确。这个<a id="_idIndexMarker331"/>就是<strong class="keyword">精度</strong>定义为:</p>

    <figure class="mediaobject"><img src="img/B17577_04_045.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">我们可以将这两个指标形象化如下:</p>

    <figure class="mediaobject"><img src="img/B17577_04_09.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 12)/Screenshot 2021-04-26 at 00.05.38.png"/></figure>

    <p class="packt_figref">图4.15:假阳性(FP)、真阳性(TP)和假阴性(FN)</p>

    <p class="normal">在该图中，显示了<strong class="keyword">假阳性</strong> ( <strong class="keyword"> FP </strong>)、<strong class="keyword">真阳性</strong> ( <strong class="keyword"> TP </strong>)和<strong class="keyword">假阴性</strong> ( <strong class="keyword"> FN </strong>)。您<a id="_idIndexMarker332"/>可以看到<a id="_idIndexMarker333"/>实际为真的实例，被模型分类为<a id="_idIndexMarker334"/>为真的实例，以及两个为真且被模型分类为真的实例的交集。</p>

    <p class="normal">我们可以快速统计和计算精度和召回率。我们有四个真阳性和六个假阳性。因此，本例的精度为<img src="img/B17577_04_046.png" alt="" style="height: 2.22em;"/>。</p>

    <p class="normal">我们有四个假阴性。召回是<img src="img/B17577_04_047.png" alt="" style="height: 2.22em;"/>。</p>

    <p class="normal">查全率和查准率显然都很重要，为什么不整合呢？<img src="img/B17577_04_048.png" alt="" style="height: 1em;"/>分数是精度和灵敏度的调和平均值:</p>

    <figure class="mediaobject"><img src="img/B17577_04_049.png" alt="" style="height: 3.31em;"/></figure>

    <p class="normal">我们还可以参数化召回和精度的相对重要性。这是<img src="img/B17577_04_050.png" alt="" style="height: 1em;"/>分数的一般化版本，即<img src="img/B17577_04_051.png" alt="" style="height: 1em;"/>分数:</p>

    <figure class="mediaobject"><img src="img/B17577_04_052.png" alt="" style="height: 2.9em;"/></figure>

    <p class="normal">另一个非常有用的指标<a id="_idIndexMarker335"/>来自<strong class="keyword">接受者操作者曲线(ROC) </strong>，它绘制了<a id="_idIndexMarker336"/>在不同阈值设置下<strong class="keyword">真阳性率</strong> ( <strong class="keyword"> TPR </strong>)对<a id="_idIndexMarker337"/>假阳性率 ( <strong class="keyword"> FPR </strong>)。<strong class="keyword">假阳性率</strong>，也称为<strong class="keyword">假警报率</strong>，与真阳性率<a id="_idIndexMarker338"/>(召回)类似地定义为:</p>

    <figure class="mediaobject"><img src="img/B17577_04_053.png" alt="" style="height: 2.5em;"/></figure>

    <p class="normal">ROC图显示了敏感性和特异性之间的关系，一般认为很难同时做到这两者，并找到所有的阳性实例(敏感性)并正确地做。通常情况下，你必须在敏感性和特异性之间做出妥协。这个<a id="_idIndexMarker339"/>图说明了你的模型如何处理这个问题。曲线下的<strong class="keyword">区域总结了该图，是实践中经常使用的度量标准。</strong></p>

    <p class="normal">另一个不太常见的度量是<a id="_idIndexMarker340"/>T42相关比率，它是由卡尔·皮尔逊引入的，作为分类-连续关联的度量:</p>

    <figure class="mediaobject"><img src="img/B17577_04_054.png" alt="" style="height: 3.5em;"/></figure>

    <p class="normal">其中<img src="img/B17577_04_055.png" alt="" style="height: 1em;"/>是类别<em class="italic"> x </em>中的观察数量，我们定义:</p>

    <figure class="mediaobject"><img src="img/B17577_04_056.png" alt="" style="height: 3.8em;"/></figure>

    <p class="normal">相关比率<a id="_idIndexMarker341"/>基于单个类别内的方差和整个群体的方差。<img src="img/B17577_04_057.png" alt="" style="height: 1em;"/>在[0，1]范围内，其中0表示类别不相关，1表示类别与绝对确定性相关。</p>

    <p class="normal">在下一节中，我们将检查时间序列之间的相似性度量。</p>

    <h2 id="_idParaDest-73" class="title">比较时间序列</h2>

    <p class="normal">相似性度量在搜索、聚类、预测、回归和分类的时间序列索引中有<a id="_idIndexMarker342"/>应用，但是如果我们想要确定两个时间序列是否相似，我们如何度量相似性？</p>

    <p class="normal">最简单的是使用皮尔逊相关系数；然而，其他措施可以提供更多信息。</p>

    <p class="normal">我们将通过一系列的方法来比较一对时间序列:</p>

    <ul>

      <li class="bullet">欧几里得距离</li>

      <li class="bullet">动态时间扭曲</li>

      <li class="bullet">格兰杰因果关系</li>

    </ul>

    <p class="normal"><strong class="keyword">欧几里德距离</strong>，一种通用的<a id="_idIndexMarker343"/>距离，适用于任何一对向量，包括时间序列:</p>

    <figure class="mediaobject"><img src="img/B17577_04_058.png" alt="" style="height: 3.8em;"/></figure>

    <p class="normal">欧几里德距离<a id="_idIndexMarker344"/>可能是有用的；然而，在实践中，对于时间序列，你可以做得更好。您可以在通过快速傅立叶变换转换到频域的时间序列上获取欧几里德距离。</p>

    <p class="normal">直观上，时间序列中事件的确切时间位置及其持续时间可以变化。<strong class="keyword">动态时间弯曲</strong> ( <strong class="keyword"> DTW </strong>)是<a id="_idIndexMarker345"/>用于测量两个时间序列之间相似性的算法之一，这两个时间序列的速度可能不同。直观上，时间序列中事件的确切时间位置及其持续时间可以变化。时间序列之间的相似性度量应该能够处理这些类型的移动和延长。</p>

    <p class="normal">总的来说，DTW是一种根据启发法计算两个具有特定限制和规则的给定时间序列之间的最佳匹配的方法。基本上，它尝试将第一个序列的索引与另一个序列的索引进行匹配。DTW是一个编辑距离——它表示将序列t1转换为t2的成本。</p>

    <p class="normal">DTW因其处理不同速度的能力而被应用于自动语音识别。然而，DTW未能量化非匹配序列之间的差异。</p>

    <p class="normal">DTW被独立地应用于每个特征维度，然后可以对距离求和。或者，通过将两点之间的距离计算为所有维度上的欧几里德距离，扭曲可以同时覆盖所有特征。因此，这种依赖变形(<img src="img/B17577_04_059.png" alt="" style="height: 1em;"/>)是一种多元方法。</p>

    <p class="normal"><strong class="keyword">格兰杰因果关系</strong>决定了<a id="_idIndexMarker346"/>一个时间序列是否可以帮助预测另一个时间序列。虽然衡量标准中的真正因果关系问题是有争议的，但衡量标准认为一个序列的值在时间上优先于另一个序列的值，可以认为衡量标准显示了时间关系或预测意义上的关系。</p>

    <p class="normal">格兰杰因果关系的概念和表述都非常直观。它的两个原则是(简化的):</p>

    <ol>

      <li class="numbered">原因必须先于结果</li>

      <li class="numbered">原因对结果有独特的影响</li>

    </ol>

    <p class="normal">因此，如果我们可以拟合一个模型，表明X和Y有一种关系，其中Y系统地跟随X，这就意味着X格兰杰原因Y。</p>

    <h1 id="_idParaDest-74" class="title">时间序列的机器学习算法</h1>

    <p class="normal">时间序列的机器学习中的一个重要区别是单变量和多变量之间的区别，其中算法是单变量的，这意味着它们只能处理单个<a id="_idIndexMarker347"/>特征，或者是多变量的，这意味着它们可以处理许多特征。</p>

    <p class="normal">在单变量数据集中，每个事例都有一个系列和一个类标签。早期的模型(经典建模)侧重于单变量数据集和应用。这也反映在数据集的可用性上。</p>

    <p class="normal">时间序列数据集最重要的存储库之一，<strong class="keyword"> UCR </strong> ( <strong class="keyword">加州大学河滨分校</strong>)档案馆于2002年首次发布，为<a id="_idIndexMarker348"/>单变量时间序列提供了宝贵的资源。它现在包含大约120个数据集，但缺乏多元数据集。此外，M竞赛(特别是M3，4和5)有很多可用的时间序列数据集。</p>

    <p class="normal">多元时间序列是具有多个特征维度的数据集。许多现实生活中的数据集本质上是多变量的——在实践中，多变量的情况比单变量的情况更常见。示例包括人体活动识别、基于<strong class="keyword">心电图</strong> ( <strong class="keyword">心电图</strong>)、<strong class="keyword">脑电图</strong> ( <strong class="keyword">脑电图</strong>)、<strong class="keyword">脑磁图</strong> ( <strong class="keyword">脑磁图</strong>)和<a id="_idIndexMarker351"/>系统监控。</p>

    <p class="normal">直到最近(Anthony Bagnall等人，2018)才创建了<strong class="keyword"> UAE </strong> ( <strong class="keyword">东安格利亚大学</strong>)档案库，拥有<a id="_idIndexMarker352"/> 30个多元数据集。另一个多元数据集存档是MTS存档。</p>

    <p class="normal">在下一节中，我们将简要讨论基于距离的方法。</p>

    <h2 id="_idParaDest-75" class="title">基于距离的方法</h2>

    <p class="normal">在我们之前提到的k-nearest-neighborhood<a id="_idIndexMarker353"/>方法(简称kNN)中，训练样本被存储，然后，在需要对新数据点进行预测的推断时间，预测基于最近的k个邻居。这就需要例子之间的距离度量。</p>

    <p class="normal">在本章的前面，我已经介绍了时间序列的两个度量标准，<strong class="keyword">动态时间弯曲</strong> ( <strong class="keyword"> DTW </strong>)和欧几里德距离。许多基于距离的方法都采用这两者之一作为距离度量。</p>

    <p class="normal">已经尝试的另一种方法是从时间序列中提取特征，然后存储这些<a id="_idIndexMarker355"/>提取的特征，以便用kNN进行检索。这些特征包括shapelets或<strong class="keyword">尺度不变特征</strong> ( <strong class="keyword"> SIFT </strong>)。SIFT特征是从时间序列中提取的极值周围的形状(阿狄丽娜·拜伊等人，2015)。</p>

    <p class="normal">我们已经在<em class="chapterRef">第3章</em>、<em class="italic">预处理时间序列</em>的单独章节中讨论了shapelets和ROCKET，因此我们将保持它们的描述简短，但重点关注它们在机器学习中的应用。</p>

    <h2 id="_idParaDest-76" class="title">Shapelets</h2>

    <p class="normal">我们已经在<em class="chapterRef">第3章</em>、<em class="italic">预处理时序</em>中讨论了shapelets，所以我们在这里将保持简短。<a id="_idIndexMarker356"/>时间序列的shape let在研究论文“<em class="italic">时间序列shape let</em>:<em class="italic">中提出，这是一种允许准确、可解释和快速分类的新技术</em>”(叶乐翔和埃蒙，2011)。shape let的基本思想是将时间序列分解成不同的子部分(称为<strong class="keyword">shape let</strong>)。已经提出了一些基于shapelet特征的方法。</p>

    <p class="normal"><strong class="keyword"> Shapelet变换分类器</strong>(<strong class="keyword">STC</strong>；Hills等人，2014)包括将shape let作为特征<a id="_idIndexMarker357"/>变换，然后将shape let输入到机器学习算法中。他们测试了C4.5决策树、朴素贝叶斯、1NN、SVM和旋转森林，但在分类设置中没有发现这些方法之间的任何显著差异。</p>

    <p class="normal"><strong class="keyword">广义随机小形森林</strong>(<strong class="keyword">gRFS</strong>)；Karlsson等人，2016)遵循随机森林的思想。每个<a id="_idIndexMarker358"/>树都建立在一组不同的随机长度的shapelets上，这些shapelets是从每个树的一个随机维度中提取的。在这些shapelets的基础上训练决策树。这些随机的shapelet树然后被集成为集合模型，这就是gRFS。</p>

    <h2 id="_idParaDest-77" class="title">火箭</h2>

    <p class="normal">我们已经在第三章<em class="chapterRef">、<em class="italic">预处理时序</em>中解释过<a id="_idIndexMarker359"/>火箭。每个输入特征分别由10，000个随机核进行变换(这个数字可以改变)。实际上，这是一个非常快速的过程。这些转换后的特征可以输入到机器学习算法中。其发明者Angus Dempster、Franç ois Petitjean和Geoff Webb在原始出版物(2019)中推荐了一个线性模型。</em></p>

    <p class="normal">最近，一个新的变种MINIROCKET发布了，它比ROCKET快了大约75倍，同时保持了<a id="_idIndexMarker360"/>大致相同的精度——<em class="italic">mini ROCKET:一个非常快速(几乎)确定性的时间序列分类变换</em> ( <em class="italic"> Angus Dempster，Daniel F. Schmidt和Geoff Webb，2020 </em>)。</p>

    <p class="normal">在机器学习研究中，<strong class="keyword">临界差异(CD)图</strong>是<a id="_idIndexMarker361"/>比较多种算法结果的强大可视化工具。平均等级表示算法之间的相互关系(等级越低越好)。算法结果进行统计比较——一条水平线链接算法，它们之间的差异不能从统计上分开。</p>

    <p class="normal">这里有一个关键的差异图<a id="_idIndexMarker362"/>说明了MiniRocket与其他算法的比较性能(来自Dempster等人的MiniRocket repo):</p>

    <figure class="mediaobject"><img src="img/B17577_04_10.png" alt=""/></figure>

    <p class="packt_figref">图4.16:在UCR档案馆的109个数据集上，与其他最先进的方法相比，MiniRocket在准确性方面的平均排名</p>

    <p class="normal">这些数字显示了该算法在测试中109个数据集上的排名。我们可以看到MiniRocket比Rocket好，但比TS-CHIEF和HIVE-COTE差，虽然两者之间的差异在统计上并不显著。</p>

    <p class="normal">我们将在<em class="chapterRef">第十章</em>、<em class="italic">时序深度学习</em>中讨论开始时间。下面几节将介绍提到的一些其他方法。</p>

    <h2 id="_idParaDest-78" class="title">时序森林和典型区间森林</h2>

    <p class="normal"><a id="_idIndexMarker363"/>的主要创新点<strong class="keyword">时序林</strong>(<strong class="keyword">TSF</strong>；邓厚涛等人，2013)引入了入口增益作为树节点的分割标准。他们表明，基于简单特征(如均值、偏差和斜率)的集成分类器在计算效率(由于并行性)方面优于具有DTW的1NN分类器。</p>

    <p class="normal">Geoff Webb领导的一组研究人员<a id="_idIndexMarker364"/>引入的<strong class="keyword">邻近森林(PF) </strong>是一种基于每个时间序列与一组参考时间序列的相似性(基于距离的特征)的树集合。他们发现PF达到了与BOSS和Shapelet变换相当的分类性能。</p>

    <p class="normal"><strong class="keyword"> TS-CHIEF </strong>，是<strong class="keyword">异构和集成嵌入森林</strong>的时间序列组合的缩写，来自同一个组的<a id="_idIndexMarker365"/>(Ahmed Shifaz，Charlotte Pelletier，Franç ois Petitjean和Geoff Webb，2020)，它用基于字典(BOSS)和基于区间(RISE)的拆分器扩展了PF，同时保留了PF引入的原始特性。作者声称，根据数据集的大小，它可以比HIVE-COTE快900倍到46，000倍。</p>

    <p class="normal"><strong class="keyword">规范区间森林的理念</strong>(<strong class="keyword">CIF</strong>；由Matthew Middlehurst，James Large和Anthony Bagnall于2020年完成)是用catch22特性来扩展TSF。它是基于22个捕获22特征和从相位相关间隔提取的汇总统计的时间序列树的集合。他们还对树使用了入口增益标准。</p>

    <p class="normal">在下一节中，我们将描述符号方法的演变，从BOSS到<strong class="keyword">时态字典集合</strong> ( <strong class="keyword"> TDE </strong>)。</p>

    <h2 id="_idParaDest-79" class="title">象征方法</h2>

    <p class="normal">符号方法是将数字时间序列转换为字母表中的符号的方法。</p>

    <p class="normal"><strong class="keyword">符号聚合近似</strong> ( <strong class="keyword"> SAX </strong>)是由埃蒙·基奥和杰西卡·林在2002年首次发表的<a id="_idIndexMarker367"/>。它扩展了<strong class="keyword">分段聚合近似</strong> ( <strong class="keyword"> PAA </strong>)，后者<a id="_idIndexMarker368"/>计算时间序列相等段内的平均值。在SAX中，这些平均值随后被量化(装箱)，因此字母表对应于原始数值的区间。两个重要的参数是PAA中的段的数量和仓的数量。</p>

    <p class="normal">下面的图(来自GitHub上Thach Le Nguyen的MrSEQL库)说明了SAX的工作原理:</p>

    <figure class="mediaobject"><img src="img/B17577_04_11.png" alt="https://github.com/lnthach/Mr-SEQL/raw/master/figs/sax_demo.png"/></figure>

    <p class="packt_figref">图4.17: SAX</p>

    <p class="normal">您可以看到区段是沿<em class="italic"> x </em>轴的网格，而箱是沿<em class="italic"> y </em>轴的网格。然后用平均值替换每个片段。通过在每个片段中用bin ID(图中的字母)替换时间序列，将时间序列离散化。</p>

    <p class="normal"><strong class="keyword">符号傅立叶近似</strong>(<strong class="keyword">SFA</strong>；Patrick Schä fer和Mikael hqvist，2012)也将时间序列转换为<a id="_idIndexMarker369"/>符号表示，但使用了频域。首先通过执行离散傅立叶变换、低通滤波、然后量化来降低数据集的维度。</p>

    <p class="normal">SFA符号的<strong class="keyword">包(BOSS</strong>Patrick sch fer，2015和2016)基于n-grams <a id="_idIndexMarker370"/>的直方图，从SFA表示中形成<strong class="keyword">模式包</strong> ( <strong class="keyword"> BoP </strong>)。BOSS已经<a id="_idIndexMarker371"/>在向量空间中扩展为<strong class="keyword">BOSS(<strong class="keyword">BOSS VS</strong>)。BOSS VS <a id="_idIndexMarker372"/>分类器比现有技术快一到四个数量级，并且比1-NN DTW更精确。</strong></p>

    <p class="normal">合约BOSS(cBOSS；Matthew Middlehurst，William Vickers，and Anthony Bagnall，2019)通过引入一个限制基本模型数量的新参数来加速BOSS。</p>

    <p class="normal"><strong class="keyword"> SEQL </strong> (Thach Le Nguyen，Severin Gsponer，and Georgiana Ifrim，2017)是一种符号序列学习算法，<a id="_idIndexMarker373"/>使用贪婪梯度下降为线性模型选择最具鉴别性的子序列。这里举例说明了这一点(来自MrSEQL GitHub repo):</p>

    <figure class="mediaobject"><img src="img/B17577_04_12.png" alt="/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document Being Saved By screencaptureui 11)/Screenshot 2021-04-25 at 23.48.05.png"/></figure>

    <p class="packt_figref">图4.18: SEQL</p>

    <p class="normal">多重表示<a id="_idIndexMarker374"/>序列学习器(<strong class="keyword">Mrs eql</strong>)；Thach Le Nguyen、Severin Gsponer、Iulia Ilie和Georgiana Ifrim，2019)正在通过选择多分辨率和多域的变换特征来扩展SEQL。</p>

    <p class="normal"><strong class="keyword">黄鼠狼+缪斯</strong>(Patrick sch fer和Ulf Leser，2017和2018)由两个阶段的<a id="_idIndexMarker375"/>组成。WEASEL <a id="_idIndexMarker376"/>代表<strong class="keyword">用于时间序列分类的单词提取</strong>，MUSE代表<strong class="keyword">多元无监督符号和导数</strong>。这一点值得强调——虽然WEASEL是一个单变量方法，但MUSE将该方法扩展到了多变量问题。</p>

    <p class="normal">在第一步中，WEASEL从截断傅立叶变换和离散化的多个长度的窗口中导出特征。这类似于低通滤波器，只保留第一个<em class="italic"> l </em>系数。然后这些系数被离散成固定大小的字母表，并在直方图中作为<strong class="keyword">模式包</strong> ( <strong class="keyword"> BOP </strong>)计数<a id="_idIndexMarker378"/>。这是针对每个功能单独完成的。</p>

    <p class="normal">在第二步(MUSE)中，直方图特征跨维度连接，并且统计测试(χ2测试)用于基于过滤器的特征选择，从而产生更小但更具鉴别性的特征集。</p>

    <p class="normal">然后将这些bop输入逻辑回归算法进行分类。</p>

    <h2 id="_idParaDest-80" class="title">蜂巢</h2>

    <p class="normal">基于变换的集成的<strong class="keyword">分层投票集合</strong> ( <strong class="keyword"> HIVE-COTE </strong>)在分类准确性方面是当前的<a id="_idIndexMarker379"/>技术状态。</p>

    <p class="normal">它于2016年提出，并于2020年被采用(Anthony Bagnall和其他人，2020年)，是一种集合方法，结合了不同方法的异构集合:</p>

    <ul>

      <li class="bullet"><strong class="keyword"> Shapelet变换分类器</strong> ( <strong class="keyword"> STC </strong>)</li>

      <li class="bullet"><strong class="keyword">时序森林</strong> ( <strong class="keyword"> TSF </strong>)</li>

      <li class="bullet"><strong class="keyword">符号-傅立叶近似符号的可收缩包</strong> ( <strong class="keyword"> CBOSS </strong>)</li>

      <li class="bullet"><strong class="keyword">随机区间光谱集合</strong> ( <strong class="keyword">上升</strong>)</li>

    </ul>

    <p class="normal"><strong class="keyword">随机区间光谱集成(RISE </strong>)是一种基于<a id="_idIndexMarker380"/>树的时间序列分类算法，最初作为<strong class="keyword">随机区间特征</strong> ( <strong class="keyword"> RIF </strong>)与HIVE-COTE同时推出(Jason Lines，Sarah Taylor，and Anthony Bagnall，2016)。在RISE的每次迭代中，提取一组傅立叶、自相关和部分自相关特征，并训练决策树。RISE的运行时复杂度是级数长度的二次方，这可能是个问题，已经发布了新版本，<strong class="keyword"> c-RISE </strong> ( <em class="italic"> c </em>为<em class="italic">契约</em>)，其中算法可以更早的停止。</p>

    <p class="normal">HIVE-COTE的运行时间复杂性是该系列长度的二次运行时间，是其采用的最大障碍之一。STC和另一个模型<strong class="keyword">弹性系综</strong> ( <strong class="keyword"> EE </strong>)是<a id="_idIndexMarker382"/>2016年开始的原始算法中最慢的两个基础模型。新版本(1.0)的一个主要区别包括丢弃EE。他们重新实现了STC和BOSS，让它们更高效，他们用c-RISE代替了RISE。</p>

    <p class="normal">每个基础学习者都单独接受培训。基于<a id="_idIndexMarker383"/> a <strong class="keyword">交叉验证</strong> <strong class="keyword">准确度加权概率集合</strong> ( <strong class="keyword"> CAWPE </strong>)结构对基础学习器进行概率加权(James Large、Jason Lines和Anthony Bagnall，2019)。</p>

    <p class="normal">在<a id="_idIndexMarker384"/>发布的HIVE-COTE 1.0中，该小组表明，当用TSF (2020)代替CIF，用<strong class="keyword">时态字典集成</strong> ( <strong class="keyword"> TDE </strong>，2021)代替BOSS时，集成甚至更强。</p>

    <p class="normal">在下一节中，我们将讨论不同方法的性能和权衡。</p>

    <h2 id="_idParaDest-81" class="title">讨论</h2>

    <p class="normal">通常，在准确性和预测时间之间存在权衡，在这些方法中，时间复杂性和模型准确性存在巨大差异。这个图表说明了这个<a id="_idIndexMarker385"/>折衷(来自Patrick Schä fer的SFA的GitHub库):</p>

    <figure class="mediaobject"><img src="img/B17577_04_13.png" alt=""/></figure>

    <p class="packt_figref">图4.19:机器学习算法:查询时间与准确度</p>

    <p class="normal">特征可能是简单操作的结果，也可能是机器学习模型的结果。我们可以将二阶特征想象为原始特征的组合，将三阶特征想象为二阶特征的组合，以此类推，这是一个潜在的大型预处理管道，在其中组合和创建特征。</p>

    <p class="normal">我们可以在这个表格中总结出<a id="_idIndexMarker387"/>种不同的算法:</p>

    <table id="table007" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">类型</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">单变量的</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">多变量的</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基于距离的</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">DTW，邻近森林</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">DTW D</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基于字典/符号</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">老板，CBOSS，S-BOSS，黄鼠狼，时态字典合奏(TDE)，萨克斯-VSM，老板</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">鼬+缪斯</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">Shapelets</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">Shapelet变换分类器(STC)</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基于区间和频谱</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">时间序列森林(TSF)，随机区间光谱集合(RISE)</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">深度学习</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">FCN雷斯内特，最初时间</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">TapNet</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">全体</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">基于变换集成的分层投票集合(HIVE-COTE)，异构和集成嵌入森林的时序组合(TS-CHIEF)</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

      </tbody>

    </table>

    <p class="packt_figref">图4.20:时序机器学习算法的详细分类</p>

    <p class="normal">这个分类<a id="_idIndexMarker388"/>远非完美，但希望是有用的。TDE既是一个整体，也是一个基于字典的模型。HIVE-COTE基于BOSS特性。此外，两种特征化方法——随机卷积核变换(ROCKET)和规范时间序列特征(Catch22 ),分别对特征进行操作；然而，基于这些特征作为输入进行训练和预测的机器学习算法因此可以在多变量设置中工作。火箭特征与线性分类器一起确实被发现与多元方法相比具有很强的竞争力。由于维数高，机器学习模型可能会考虑原始特征之间的相互作用。</p>

    <p class="normal">我向读者强烈推荐的一篇综述论文是亚历杭德罗·帕索斯·鲁伊斯、迈克尔·弗林和安东尼·巴格纳尔(2020)的《<em class="italic">多变量时间序列分类大赛</em>》。它在来自阿联酋档案的26个多元<a id="_idIndexMarker389"/>数据集上比较了最先进的算法(其中16个包含在分析中)。这些方法包括以下内容:</p>

    <ul>

      <li class="bullet">动态时间扭曲</li>

      <li class="bullet">缪斯+鼬</li>

      <li class="bullet">升高</li>

      <li class="bullet">CBOSS</li>

      <li class="bullet">TSF</li>

      <li class="bullet">gRSF</li>

      <li class="bullet">火箭</li>

      <li class="bullet">蜂巢1.0</li>

      <li class="bullet">到岸价(Cost Insurance and Freight)</li>

      <li class="bullet">雷斯内特</li>

      <li class="bullet">卫星追踪委员会(Satellite Tracking Committee)</li>

    </ul>

    <p class="normal">临界差异图(见<a href="http://timeseriesclassification.com">timeseriesclassification.com</a>)显示了测试中26个数据集的算法排名。算法之间的联系表明，它们之间的差异在统计上无法分开(基于Wilcoxon秩和检验):</p>

    <figure class="mediaobject"><img src="img/B17577_04_14.png" alt="../../../../Desktop/Screenshot%202021-04-25%20at%2021.24"/></figure>

    <p class="packt_figref">图4.21时序分类算法的临界差异图</p>

    <p class="normal">他们发现了一个由表现最好的分类器组成的小团体，其中排名最高的ROCKET在至少少一个数量级的时间内实现了相当大的改进。ROCKET之后是HIVE-COTE和CIF。</p>

    <p class="normal">在2019年的一项研究中，哈桑·法瓦兹(Hassan Fawaz)和其他人比较了MTSC档案馆12个多元数据集的时间序列的深度学习算法。全连接卷积网络(FCN)是最好的，其次是ResNet——在UCR知识库的85个单变量数据集上，ResNet击败FCN成为第一名(在85个数据集的50个数据集上获胜)。在一项单独的比较中，仅涉及ResNet与一些最先进的非深度学习方法在单变量和多变量数据集上的比较，他们发现ResNet的性能落后于HIVE-COTE，尽管在数据集上没有明显恶化，但击败了其他方法，如BOSS和1NN与DTW(后者在统计上达到了显著的程度)。我们将在<em class="chapterRef">第十章</em>、<em class="italic">时间序列的深度学习</em>中详细讨论这篇论文。</p>

    <p class="normal">在另一项对来自MTSC档案馆的20个数据集的多变量时间序列分类的比较研究中(Bhaskar Dhariyal、Thach Le Nguyen、Severin Gsponer和Georgiana Ifrim，2020年)，确定ROCKET在14个数据集上获胜，比大多数深度学习算法好得多，同时也是最快的方法——ROCKET在20个数据集上的运行时间为34分钟，而DTW运行了几天。</p>

    <p class="normal">以下是根据他们的结果使用Hassan Fawaz的Python脚本创建的关键图:</p>

    <figure class="mediaobject"><img src="img/B17577_04_15.png" alt="../../../../Downloads/Machine-Learning%20for%20Time-Series%20with%20Python/mtsc_cd-di"/></figure>

    <p class="packt_figref">图4.22:多元时间序列分类的临界差异图</p>

    <p class="normal">人们尝试了许多不同的特性集，其中最好的(<code class="Code-In-Text--PACKT-">9_stat_MulPAA</code>)并没有太大的变化。</p>

    <h2 id="_idParaDest-82" class="title">履行</h2>

    <p class="normal">伟大的算法如果没有软件来提供，使它们在公司的生产环境中易于使用和可靠使用，那么在实践中就没有多大价值。或者，从头开始实现算法可能需要时间，并且不是没有复杂性。因此，Python中有许多可靠、可用的实现是一件好事。</p>

    <p class="normal">下表总结了回归和分类监督算法的实现<a id="_idIndexMarker392"/>:</p>

    <table id="table008" class="No-Table-Style _idGenTablePara-1">

      <colgroup>

        <col/>

        <col/>

        <col/>

      </colgroup>

      <tbody>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">算法</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">sktime</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Heading--PACKT-">Pyts</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">自回归综合移动平均(ARIMA)</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">DTW</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">蝙蝠</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">缪斯+鼬</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">MrSEQL</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">火箭</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">老板</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">向量空间中的SFA符号包(BOSSVS)</p>

          </td>

          <td class="No-Table-Style"/>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">CBOSS</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">萨克斯-VSM</p>

          </td>

          <td class="No-Table-Style"/>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">升高</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">蜂巢</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style"/>

        </tr>

        <tr class="No-Table-Style">

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">时序森林</p>

          </td>

          <td class="No-Table-Style">

            <p class="Table-Column-Content--PACKT-">X</p>

          </td>

          <td class="No-Table-Style">sktime有这么多实现也不是<a id="_idIndexMarker393"/>偶然。东安格利亚大学Anthony Bagnall周围的小组在研究活动中积极使用它。Pyts由约翰·法乌齐和希查姆·贾纳蒂负责维护，他们是巴黎<a id="_idIndexMarker394"/>脑研究所和巴黎<strong class="keyword">应用数学中心</strong> ( <strong class="keyword"> CMAP </strong>)的博士后。约翰·法乌齐也是tslearn库的负责人，该库实现了时间序列分析和特征提取算法。</td>

        </tr>

      </tbody>

    </table>

    <figure class="mediaobject">Figure 4.23: Pyts versus SkTime implementations of machine learning algorithms</figure>

    <p class="normal">我从表中省略了深度学习算法，它们通常作为不同库的一部分来实现。请注意，sktime允许通过相同的界面使用prophet forecaster。比如sktime-DL库实现了ResNet、InceptionTime、TapNet算法，dl-4-tsc实现了十几个深度学习模型。我们将在<em class="chapterRef">第10章</em>、<em class="italic">时间序列的深度学习</em>中讨论深度学习模型的实现。</p>

    <p class="normal">脸书的先知<a id="_idIndexMarker395"/>包含单一模型，是<strong class="keyword">广义可加模型</strong> ( <strong class="keyword"> GAM </strong>)的特例<a id="_idIndexMarker396"/>。Statsmodels库<a id="_idIndexMarker397"/>包含<a id="_idIndexMarker398"/>GAM以及线性<a id="_idIndexMarker399"/>回归模型和<strong class="keyword">广义线性模型</strong>(<strong class="keyword"/>)<strong class="keyword">移动平均</strong>(<strong class="keyword">MA</strong>)<strong class="keyword">自回归综合移动平均</strong>(<strong class="keyword">ARIMA</strong>)<strong class="keyword">向量自回归</strong> ( <strong class="keyword"> VAR </strong>)。</p>

    <p class="normal">Darts库为时序处理和预测的多个模型提供了一致的接口。它包括经典和深度学习算法:</p>

    <p class="normal">指数平滑法</p>

    <ul>

      <li class="bullet">ARIMA</li>

      <li class="bullet">时间卷积网络</li>

      <li class="bullet">变压器</li>

      <li class="bullet">n拍</li>

      <li class="bullet">这就结束了我们对Python中时序机器学习库的概述。</li>

    </ul>

    <p class="normal">摘要</p>

    <h1 id="_idParaDest-83" class="title">在这一章中，我们已经讨论了时间序列机器学习的背景和技术背景。机器学习算法或模型可以基于数据做出系统的、可重复的、有效的决策。我们解释了时间序列的主要机器学习问题，如预测、分类、回归、分割和异常检测。然后，我们回顾了与时间序列相关的机器学习的基础知识，并查看了时间序列的机器学习的历史和当前用途。</h1>

    <p class="normal">我们根据所使用的方法和特性讨论了不同类型的方法。此外，我们讨论了许多算法，集中在最先进的机器学习方法。</p>

    <p class="normal">我将在专门的章节中讨论包括深度学习或经典模型(如自回归和移动平均)在内的方法(例如，在<em class="chapterRef">第5章</em>、<em class="italic">用移动平均和自回归模型进行时间序列预测</em>，以及<em class="chapterRef">第10章</em>、<em class="italic">时间序列的深度学习</em>)。</p>

    <p class="normal">I will discuss approaches including deep learning or classical models, such as autoregressive and moving averages, in chapters dedicated to them (for example, in <em class="chapterRef">chapter 5</em>, <em class="italic">Time-Series Forecasting with Moving Averages and Autoregressive Models</em>, and <em class="chapterRef">chapter 10</em>, <em class="italic">Deep Learning for Time-Series</em>).</p>

  </div>



</body></html>