<title>B18335_09_ePub</title>

# *第九章*:漂移和漂移检测

在前面的章节中，你已经发现了很多方法来构建以在线方式工作的**机器学习** ( **ML** )模型。他们能够从一次观察中更新他们学习到的决策规则，而不是像大多数 ML 模型中常见的那样必须完全重新训练。

这很棒的一个原因是流，因为这些模型将允许你不断地工作和学习。然而，我们可以认为传统的 ML 模型也可以根据单个观察值进行预测。即使是批量学习和离线模型也可以一次预测一个新的观察结果。为了更深入地了解在线 ML 的附加价值，本章将深入探讨漂移和漂移检测。

为了更好地理解这些概念，本章将从什么是漂移的深入描述开始。然后你会看到不同类型的漂移，包括概念漂移、数据漂移和再培训策略问题。

在那之后，你将会接触到许多检测数据漂移和概念漂移的方法。你还会看到许多抵消漂移的方法，并且会被介绍到模型的可解释性和再训练策略。

现在，让我们从基础开始，深入了解漂移的定义。

本章将涵盖以下主题:

*   定义漂移
*   引入模型显式性
*   测量漂移
*   在 Python 中测量漂移
*   抵消漂移

# 技术要求

你可以在 GitHub 上找到这本书的所有代码，链接如下:[https://GitHub . com/packt publishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python)。如果您还不熟悉 Git 和 GitHub，下载笔记本和代码示例的最简单方法是执行以下操作:

1.  转到存储库的链接。
2.  转到绿色的**代码**按钮。
3.  选择**下载 zip 文件**。

当您下载 ZIP 文件时，您将它解压缩到您的本地环境中，您将能够通过您喜欢的 Python 编辑器访问代码。

## Python 环境

要阅读本书，您可以下载存储库中的代码，并使用您喜欢的 Python 编辑器执行它。

如果你还不熟悉 Python 环境，我建议你去看看 Anaconda([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual))，它带有 Jupyter Notebook 和 JupyterLab，这两个工具都非常适合执行笔记本。还自带 Spyder 和 **Visual Studio 代码** ( **VS 代码**)用于编辑脚本和程序。

如果你在你的机器上安装 Python 或相关程序有困难，你可以查看一下**Google Colabatory**(**Google Colab**)(【https://colab.research.google.com/】T4)或 Kaggle Notebooks([https://www.kaggle.com/code](https://www.kaggle.com/code))，它们都允许你在网上免费运行 Python 代码，不需要任何设置。

注意

书中的代码一般会使用 Python 3 . 7 . 13 版本的 Colab 和 Kaggle 笔记本，你可以设置自己的环境来模仿这个。

# 定义漂移

众所周知，随着时间的推移，模型的表现会越来越差，这是一个常见的问题。无论您的衡量标准是准确性、R2 分数、F1 分数还是其他任何东西，如果您将模型投入生产并且不更新它们，您将会看到随着时间的推移，性能会缓慢但稳定地下降。

根据您的使用情况，这种减少可能会很快或很慢地出现问题。一些用例需要有连续的、近乎完美的预测。在某些用例中——例如，对于模型对生活有直接影响的专业 ML——如果您观察到 1%的下降，您会非常震惊。在其他用例中，ML 更多地用于自动化，而不是预测，业务伙伴可能甚至没有注意到 5%的减少。

它是否会影响你不是这里的问题。可以肯定的是，总的来说，你会看到你的模型在减少。本章的目标是确保找出模型性能下降的原因，如何测量它，以及如果您认为它对您的用例来说问题太大，可以做些什么。

在下一节中，我们将首先介绍您在流用例中可能遇到的三种不同类型的漂移。

## 三种类型的漂移

对于流数据，通常认为漂移有两个原因:概念漂移和数据漂移。在这一部分，你将首先发现概念和数据漂移，但你也将看到再训练策略如何影响你的模型偏离数据，而不是相反。

### 概念漂移

在概念漂移中，我们试图通过我们正在建模的概念的变化来解释模型性能的恶化。这意味着目标变量的统计属性正在改变，因此该模型不再适合我们的用例。

概念变化的一个简化示例是一个试图预测某个酒吧的热巧克力销售的模型。也许这个模式在某个时候是完美的，但是在某个时候，这个地区出现了一个竞争的酒吧。潜在的需求过程已经改变，这在逻辑上没有包括在模型中，因为竞争在模型建立时是不相关的。

当概念改变时，模型需要更新以考虑最近的过程，因为模型不再适合用例。下面的示意图显示了在概念漂移的情况下会出现什么问题:

![Figure 9.1 – Concept drift
](img/B18335_09_1.jpg)

图 9.1–概念漂移

既然您已经看到了概念漂移背后的理论，下一节将介绍数据漂移—第二种重要的漂移类型。

### 数据漂移

当我们谈论数据漂移时，我们谈论的是独立变量统计特性的变化。这主要是在我们已经处理了数据样本(可能只是基于我们现有的数据)时，但是我们开始意识到样本不再代表我们当前接收的数据。

例子包括测量机器的变化，其中新的测量设备可能给出与旧材料略有不同的测量值。想象一下，我们改变了温度计，新的温度计比旧的温度计高 0.5 度。您可以理解，该模型无法考虑这种类型的信息，并且会做出错误的预测，因为该模型采用的温度高于其应有的温度。

下面的示意图显示了在数据漂移的情况下会出现什么问题:

![Figure 9.2 – Data drift
](img/B18335_09_2.jpg)

图 9.2–数据漂移

已经讨论了漂移的两个重要原因，下一节将介绍模型衰减和错误设定——第三个与漂移相关的问题。

### 模型衰减和错误设定

虽然在文献中一般不认为是漂移的问题，但我发现也提及模型的问题作为漂移和衰减性能背后的问题之一是很重要的。在现实生活中，人类是不完美的，会犯错误。理论上，我们应该期望模型被很好地指定，因此不会成为任何问题的原因。

然而，在实践中，模型的再训练可能被错误地自动化，从而引入小问题，随着时间的推移，这些小问题慢慢地累积成大问题，并且这可能是模型衰退和降低性能的重要原因。

下面的示意图显示了在模型问题的情况下，由于任何原因(如错误设定或再训练问题)而出现的问题:

![Figure 9.3 – Model-induced problems
](img/B18335_09_3.jpg)

图 9.3-模型引发的问题

已经看到了流模型中漂移的三个潜在原因，下一节将解释如何使用模型可解释性作为解决漂移的方法。

# 引入模型可解释性

当模特在网上学习时，他们会反复学习。这个重新学习过程是自动发生的，人类用户通常不可能持续关注模型。此外，这将违背进行 ML 的主要目标，因为目标是让机器——或模型——接管，而不是持续的人工干预。

当模型学习或重新学习时，数据科学家通常会面临程序化的模型构建界面。想象一个随机森林，其中数百棵决策树同时行动，预测新观察的目标变量。即使是打印和查看所有这些决定也是一项艰巨的任务。

模型可解释性是 ML 最新进展中的一个大话题。通过向数据科学用例扔黑盒模型，大错误正在发生。一个例子是，当自动驾驶汽车在包含太多白人的有偏见的样本上进行训练时，这些汽车被测量出与黑人发生更多事故，这只是因为一个数据科学错误。了解您的模型中发生了什么可以产生挽救生命的影响。

考虑模型中的漂移时，了解模型中发生的情况也很重要。您部署的第一个模型可能非常接近您的预期。之后，模型将从它遇到的每个数据点重新学习。如果数据中存在偏差，或者如果偏差是由于过度拟合或拟合不足而产生的(当模型自主运行时就会发生这种情况)，那么在某些时候，您可能会错过这些趋势。

您需要确保为模型的可解释性建立一个初始方法，并继续研究这个主题。在本章中，我们将重点关注数据漂移和概念漂移，但请记住，模型设定错误也是降低准确性的一个巨大因素。这将在第十一章 的 [*中更深入地讨论。*](B18335_11_ePub.xhtml#_idTextAnchor215)

现在，让我们继续讨论一些测量漂移的方法。

# 测量漂移

对于漂移，有两个重要的事情需要考虑。我们首先应该能够测量漂移，因为我们不能抵消我们不知道的东西。第二，一旦我们意识到漂移，我们应该定义正确的策略来对抗它。让我们首先讨论漂移的测量。

## 测量数据漂移

如前所述，数据漂移意味着测量值随时间缓慢变化，而基本概念保持不变。为了衡量这一点，描述性统计非常有用。由于你在前面的章节中已经看到了大量的描述性统计数据，我们就不重复这背后的理论了。

要应用描述性统计来测量数据漂移，我们可以简单地设置一些描述性统计，并随着时间的推移跟踪它们。对于每个变量，您可以设置以下内容:

*   中心性的测量(平均值、中值、众数)
*   变异的度量(标准差、方差、 **四分位距**或 **IQR** )
*   变量之间的事件相关性

除此之外，有必要在特定的时间尺度上跟踪漂移。如果您希望漂移持续很长时间，您可以按月甚至按年计算这些描述性统计数据，但是为了更快地检测，可以按周、按天、甚至按小时或更频繁地计算。

随着时间的推移，这些指标的比较将允许您检测数据中的变化，这将是您的模型漂移的常见原因。

## 测量概念漂移

当测量概念漂移时，最好的办法是随着时间的推移建立对模型性能的全面跟踪。您使用的性能指标将取决于您的用例以及您使用的模型类型，但可能包括用于回归、准确性的 R2 分数、用于验证的 F1 分数，甚至更多。

当随着时间的推移测量模型性能时，如果没有进行模型更新，您可能会看到性能下降。随着在线模型在每个数据点上重新学习，理论上这应该不是一个问题。当您确实看到性能下降时，这表明您的系统中的某个地方出了问题。

如果您已经在测量数据漂移，这将是一个很好的第一件事，因为数据漂移可能会导致模型性能下降。如果没有发生数据漂移，那么您的系统可能会出现概念漂移。

重要的是要记住，测量模型漂移和数据漂移在实践中是紧密联系在一起的:很难将性能下降归因于一个特定的根本原因。目标应该是保持模型的高性能，并在出现问题时找到解决方案。同时衡量绩效和个人统计数据，甚至更多指标，这将使您的策略更有效地应对漂移。

现在让我们看一些如何在建模中检测漂移的 Python 例子。

# 在 Python 中测量漂移

测量漂移时，首先要做的是确保您的模型以某种方式写出日志或结果。对于以下示例，您将使用数据集，其中记录了每个预测，这样我们就有了每个预测的输入变量、预测、实际情况以及预测和实际情况之间的绝对差异作为误差指标。

如果你想研究漂移探测，记录你的模型的行为是一个绝对的先决条件。让我们从一些基本的测量开始，这些测量可以帮助您使用 Python 来检测漂移。

## 测量漂移的基本直观方法

在本节中，您将发现一种测量漂移的直观方法。以下是我们将遵循的步骤:

1.  为了开始测量我们记录的结果数据的漂移，我们首先将数据作为`pandas`数据帧导入。这是在下面的代码块中完成的:

代码块 9-1

```
import pandas as pd
data = pd.read_excel('chapter9datafile.xlsx')
data
```

您将获得如下所示的表格:

![Figure 9.4 – The data
](img/B18335_09_4.jpg)

图 9.4-数据

1.  现在您已经有了漂移检测数据，让我们通过在当天执行`groupby`操作并查看平均误差来查看误差随时间的发展，如下所示:

代码块 9-2

```
data.groupby('Day')['Error'].mean()
```

您将获得以下结果:

![Figure 9.5 – The result
](img/B18335_09_5.jpg)

图 9.5-结果

您可以清楚地看到，误差随着时间的推移而大幅增加，因此我们可以相当肯定，这里存在模型漂移问题。当然现在还没有界定这个问题是数据上的问题还是概念上的问题。

1.  让我们对目标变量进行分析，看看随着时间的推移，目标是否经历了大的变化。以下代码计算每天的实际值的平均值，以查看目标变量是否有明显的漂移:

代码块 9-3

```
data.groupby('Day')['Ground Truth'].mean()
```

结果看起来像这样:

![Figure 9.6 – The result (continued)
](img/B18335_09_6.jpg)

图 9.6-结果(续)

在这段时间里，我们确实看到了一个相当重要的平均变化。

1.  让我们进一步检查，并对每个独立变量进行分析。下面的代码每天计算三个独立变量的平均值，看看是否有明显的变化:

代码块 9-4

```
data.groupby('Day')[['X1', 'X2', 'X3']].mean()
```

您将获得以下结果:

![Figure 9.7 – The groupby result
](img/B18335_09_7.jpg)

图 9.7–分组结果

我们看到第三个解释变量`X3`发生了非常明显的变化。这很有可能是我们模式转变的原因。

## 使用坚固的工具测量漂移

如果您正在处理小型用例，并且不希望与大型外部平台集成，前面的例子确实不错。然而，如果你在一家资源有限的公司工作，从头开始开发通用用例的代码可能是不可能的或者不值得的。

漂移检测是一个目前相当受欢迎的用例，因此越来越多的强大解决方案正呈现在公众面前，无论是付费程序、云程序还是开源解决方案。

接下来，我将介绍一些有用的解决方案，如果您对采用外部平台进行模型性能跟踪和漂移检测用例感兴趣，您可以看看这些解决方案。由于这些平台是由公司拥有的，有时是付费的，我不想在这里深入探讨，但如果你对此感兴趣，给你一些提示是很好的。

### Soda SQL

一个有趣的解决方案是 Soda SQL。这是一个专门针对数据质量的工具，因此不一定针对 ML 用例进行调整。然而，数据质量问题几乎必然会导致有问题的模型，所以我发现讨论这个解决方案是有价值的。

你可以在这里找到完整的信息:【https://docs.soda.io/】T4。Soda SQL 是一个真正面向数据工程的工具，所以我不会在这里详细介绍，但是我建议您在使用案例中记住它。

### MLflow with whylogs

一个更加面向生产中的 ML 模型的工具是开源 Python 库，它集成了 WhyLabs 应用程序([whylabsapp.com](http://whylabsapp.com))。如果您注册了 WhyLabs 的帐户，您可以使用他们的**应用程序编程接口** ( **API** )并将您的模型日志直接发送到他们的数据库，在那里它将被分析并供您访问。

### 海王星

Neptune ( [neptune.ai](http://neptune.ai) )正在提供一个类似的工具。Neptune 的目标也是提供一个**ML operations**(**MLOps**)平台，您可以将来自基本上任何 Python(或其他)模型环境的日志数据发送到这个平台。之后，您可以在他们的 web 平台上访问性能，所有用于漂移检测的重担都从您的肩上卸下。

你现在已经看到了一些测量和检测漂移的理论方法，以及一些初创平台，如果你没有能力提供这种服务，它们会建议为你做这类工作。然而，我们还没有谈到同样重要的东西，即抵制漂移。

# 抵消漂移

正如在简介中所讨论的，模型漂移是必然会发生的。也许它发生得很慢，也许它发生得很快，但如果我们不试图积极应对，这是无法避免的。

在接下来的章节中，你会意识到在线学习，这在本书中已经被广泛讨论过，实际上是一种非常有效的对抗漂移的方法。虽然我们还没有明确定义漂移，但你现在会明白在线学习在这里有很大的附加值。

现在，我们将根据你正在做的工作类型，总结两种抵消漂移的方法，如下所示:

*   离线学习的再培训
*   在线学习

让我们从最传统的案例开始，这是离线学习，针对模型衰退实施再训练策略。

## 离线学习，具有针对漂移的再训练策略

离线学习仍然是 ML 最常用的方法。在离线学习中，模型被训练一次，然后仅用于预测。下面的示意图描述了离线学习过程:

![Figure 9.8 – Schematic diagram of offline learning
](img/B18335_09_8.jpg)

图 9.8–离线学习示意图

要更新模型，通常需要重新训练完整的模型，并将新版本部署到您的生产环境中。如图 9.9 中的*所示。*

这种方法的优点是模型构建者可以完全控制他们的模型。没有模型学习新的错误过程的风险。这是以数据或概念漂移发生时不更新为代价的。这样，它的优点和缺点与在线学习正好相反。

## 在线学习对抗漂移

正如你在本书中所看到的，在线学习是离线学习的一种替代方式，并且允许模型在新的数据点到来时进行更新。下图说明了再培训策略的工作原理:

![Figure 9.9 – Schematic diagram of online learning
](img/B18335_09_9.jpg)

图 9.9-在线学习示意图

使用在线学习，模型在更新方面有一定的自主权，理论上将更接近数据:应该会出现更少的漂移。然而，这是以模型构建者不能完全控制理论模型为代价的。学习可能会走向错误的方向，模型会学习不需要的决策规则。

优势与线下学习相反，选择在线学习还是线下学习将真正取决于业务案例。

# 总结

在这一章中，你首先已经了解了模型漂移的基本原理。您已经看到，在现实环境中的 ML 模型中，随着时间的推移，模型漂移和模型性能下降是意料之中的。

性能下降通常可归因于数据漂移、概念漂移或模型引发的问题。当数据测量值随时间变化，但模型背后的基本理论概念保持不变时，就会出现数据漂移。概念漂移抓住了学习过程的理论基础的问题。

模型和模型再训练相关的问题通常不被认为是漂移的标准原因，但它们仍然应该被监控和认真对待。根据您的业务情况，重新学习——尤其是在缺乏监控的情况下——可能会给 ML 系统带来大问题。

数据漂移通常可以通过使用描述性统计来很好地测量。概念漂移通常很难测量，但是它的存在可以从模型性能中无法解释的下降中推断出来。一般来说，这里的重要性不在于将性能下降归因于特定的原因，而在于使用所提供的解决方案之一来解决问题。

再训练策略通常可以用于离线模型。它们是一种更新模型的方法，而不会放弃对已学决策规则的控制。在线模型，正如本书前几章所介绍的，是重新训练离线模型的一个很好的选择。使用在线模型的最大好处是，在线模型是专门为再培训而制作的。这些模型允许更大程度的自治，并且将在许多商业案例中被证明是有用的，只要数据和模型的监控被正确地实现。

在下一章中，你将看到如何调整**特征转换** ( **FT** )和缩放以适应在线建模的情况。FT 和缩放是许多 ML 用例中的标准做法，但由于数据漂移和窗口偏差，这带来了一些需要考虑的理论困难。

# 延伸阅读

*   模型漂移:[https://www.ibm.com/cloud/watson-studio/drift](https://www.ibm.com/cloud/watson-studio/drift)
*   数据漂移:[https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-monitor-datasets？tabs=python](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python)
*   概念漂移:[https://www . iguazio . com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/](https://www.iguazio.com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/)
*   应对概念漂移:[https://neptune.ai/blog/concept-drift-best-practices](https://neptune.ai/blog/concept-drift-best-practices)
*   再培训攻略:[https://www . kdnugges . com/2019/12/ultimate-guide-model-retaining . html](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)