

# 六、在线分类

在前两章中，你已经了解了分类的一些基本概念。您首先看到了一个用例，其中 River 中的在线分类模型用于构建一个模型，该模型可以根据植物的一些特征来识别鸢尾属物种。这个虹膜数据集是世界上最著名的数据集之一，也是一个非常常见的分类起点。

之后，您查看了异常检测。我们讨论了如何将分类模型用于异常检测，在这些情况下，我们可以将异常标记为一类，将非异常标记为另一类。特定的异常检测模型通常更擅长这项任务，因为它们努力只理解非异常。分类模型将努力理解每一类。

在这一章中，你将更深入地了解分类。本章将首先提出什么是分类以及分类的用途的定义。然后，您将看到许多分类模型，您将了解它们的在线和离线对应物之间的差异。您还将使用 River 包在 Python 中实现多个示例。最终，这将会产生一个用例的模型基准研究，稍后将会介绍。

本章将涵盖以下主题:

*   定义分类
*   识别分类的用例
*   河流分类算法

# 技术要求

你可以在 GitHub 上找到这本书的所有代码，链接如下:[https://GitHub . com/packt publishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python)。如果您还不熟悉 Git 和 GitHub，下载笔记本和代码示例的最简单方法如下:

1.  转到存储库的链接。
2.  点击绿色的**代码**按钮。
3.  选择**下载压缩文件**。

当您下载 ZIP 文件时，在您的本地环境中解压缩它，您将能够通过您喜欢的 Python 编辑器访问代码。

## Python 环境

要阅读本书，您可以下载存储库中的代码，并使用您喜欢的 Python 编辑器执行它。

如果你还不熟悉 Python 环境，我建议你去看看 Anaconda([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual))，它带有 Jupyter Notebook 和 JupyterLab，这两个工具都非常适合执行笔记本。它还带有 Spyder 和 VSCode，用于编辑脚本和程序。

如果你在你的机器上安装 Python 或相关程序有困难，你可以看看谷歌 Colab(【https://colab.research.google.com/】)或 Kaggle 笔记本([【https://www.kaggle.com/code】](https://www.kaggle.com/code))，它们都允许你在网上免费运行 Python 代码，不需要做任何设置。

# 定义分类

在这一章中，你会发现分类。分类是一项受监督的机器学习任务，其中构建一个模型，将观察结果分配给一个类别。

每个人都知道的最简单的分类模型是决策树。让我们考虑一个如何使用决策树进行分类的超级简单的例子。

假设我们有一个数据集，其中有关于五个人和五种动物的观察结果。目标是使用这些数据建立一个决策树，可以用于任何新的，看不见的动物或人类。

数据可以按如下方式导入:

代码块 6-1

```
import pandas as pd
```

```
# example to classify human vs animal
```

```
#dataset with one variable
```

```
can_speak = [True,True,True,True,True,True,True,False,False,False]
```

```
has_feathers = [False,False,False,False,False,True,True,False,False,False]
```

```
is_human = [True,True,True,True,True,False,False,False,False,False]
```

```
data = pd.DataFrame({'can_speak': can_speak, 'has_feathers': has_feathers, 'is_human': is_human})
```

```
data
```

数据如下图所示:

![Figure 6.1 – The data
](img/B18335_06_1.jpg)

图 6.1-数据

现在，为了构建决策树，你通常会使用机器学习，因为这比手工构建树要有效得多。然而，对于本例，让我们做一个简单的决策树，如下图所示:

![Figure 6.2 – The example decision tree
](img/B18335_06_2.jpg)

图 6.2–示例决策树

当然这是一个模型，所以只是部分代表了真相。它对于包含 10 个观测值的当前数据集非常有效，但是随着数据点的增加，您将会遇到各种类型的异常，因此您需要更多的变量。

您可以用 Python 为这个模型编写一个`human`对`not human`分类的代码，如下所示:

代码块 6-2

```
def self_made_decision_tree(observation):
```

```
    if observation.can_speak:
```

```
        if not observation.has_feathers:
```

```
            return 'human'
```

```
    return 'not human'
```

```
for i,row in data.iterrows():
```

```
    print(self_made_decision_tree(row))
```

结果如下:

![Figure 6.3 – The predicted outcomes
](img/B18335_06_3.jpg)

图 6.3–预测结果

这背后的一般思想是，分类模型是任何机器学习模型，其使用数据来生成决策规则，以将观察分配给特定的类。在下一节中，我们将研究分类的一些用例，以便更好地了解它在实践中的用途。

# 识别用例的分类

分类的用例是巨大的；这是许多项目中非常常用的方法。尽管如此，让我们看一些例子来更好地理解可以从分类方法中获益的不同类型的用例。

## 用例 1–垃圾邮件分类

通常基于分类的第一个用例是电子邮件中的**垃圾邮件检测**。垃圾邮件已经存在很长时间了。发送虚假邮件来窃取人们钱财的商业模式是一个大问题，收到许多垃圾邮件会对您的电子邮件体验产生负面影响。

电子邮件服务提供商在自动检测垃圾邮件并将其发送到您的垃圾邮件/垃圾邮件箱方面取得了长足的进步。现在，这些都是自动完成的，并且非常依赖于机器学习。

如果您将这与我们的超小型分类示例进行比较，您可以想象决策树(或任何其他模型)可以获取关于每封收到的电子邮件的几种信息类型，并使用它们来决定该电子邮件是否应该被分类为垃圾邮件。这必须实时完成，因为没有人希望等待垃圾邮件检测服务最终发送他们的电子邮件。

您可以在以下资源中阅读关于此使用案例的更多信息:

*   [https://www . science direct . com/science/article/pii/s 2405844018353404](https://www.sciencedirect.com/science/article/pii/S2405844018353404)
*   [https://www . enjoy algorithms . com/blog/email-spam-and-non-spam-filtering-using-machine-learning](https://www.enjoyalgorithms.com/blog/email-spam-and-non-spam-filtering-using-machine-learning)

## 用例 2–手机摄像头中的人脸检测

分类的第二个例子是当你想解锁手机时的人脸检测。你的手机必须在瞬间决定它看到的这张脸是不是它主人的脸。

这个决定是分类决定，因为它归结为是/否决定:它*是*所有者，或者它*不是*所有者。这个决定通常将由机器学习做出，因为规则将非常复杂，并且很难写为`if` / `else`语句。如今，机器学习算法在这类用例方面相对较好。

有关此用例的其他更多详细示例，您可以查看以下链接:

*   [https://www . xfinity . com/hub/mobile/face-recognition-on-phone](https://www.xfinity.com/hub/mobile/facial-recognition-on-phone)
*   [https://www . nytimes . com/wire cutter/blog/how-face-recognition-works/](https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/)

## 用例 3–在线营销广告选择

前两个例子的最后一个例子是在线营销广告选择。现在许多网站展示个性化广告。这意味着你会看到一个与你作为客户相匹配的广告。

尽管个性化广告系统并没有发明广告；他们必须做出决定，在多个可用的广告中做出选择，以了解哪一个最适合你。这样，它就是一个分类，因为它必须在多种选择中做出决定。

如你所知，页面加载必须很快，因此，广告选择也必须在瞬间完成。实时响应是模型提供任何价值的关键。

以下链接更深入地讨论了这个用例:

*   [https://www . owox . com/blog/articles/机器学习营销/](https://www.owox.com/blog/articles/machine-learning-in-marketing/)
*   [https://www . IBM . com/Watson-advertising/think-leadership/benefits-of-machine-learning-in-advertising](https://www.ibm.com/watson-advertising/thought-leadership/benefits-of-machine-learning-in-advertising)

在下一节中，您将看到分类更实际的一面，因为您将在 River Python 库中发现几种分类算法。

# 河流分类算法概述

河流在线机器学习包中有大量在线分类模型可用。

一些相关的例子如下:

*   `LogisticRegression`
*   `Perceptron`
*   `AdaptiveRandomForestClassifier`
*   `ALMAClassifier`
*   `PAClassifier`

## 分类算法 1–物流回归

逻辑回归是最基本的统计分类模型之一。它对一个因变量(目标变量)建模，该因变量有两个类别(1 或 0)，并且可以使用多个自变量进行预测。

该模型将每个独立变量组合成对数优势；你可以把它看作线性回归中的系数，除了它们是每个变量的对数优势。模型中的分割基于逻辑函数。

您可以看到这个想法的简化示意图如下:

![Figure 6.4 – The logistic curve
](img/B18335_06_4.jpg)

图 6.4–逻辑曲线

### 河流中的逻辑回归

对于在线逻辑回归，可以使用 River 的`linear_model`部分中的`LogisticRegression`类。现在让我们来看一个例子:

1.  首先，可以从使用 sklearn 内置的`make_blobs`函数制作分类数据集开始，这个函数制作分类数据集。为此，您可以使用以下代码:

代码块 6-3

```
from sklearn.datasets import make_blobs
X,y=make_blobs(shuffle=True,centers=2,n_samples=2000)
```

1.  要看这个数据集是什么样子，做个图很重要。为此，您可以使用以下`matplotlib`代码:

代码块 6-4

```
import matplotlib.pyplot as plt
plt.scatter(X[:,0], X[:,1], c=y)
```

你应该获得以下情节，或类似的东西:

![Figure 6.5 – The data
](img/B18335_06_5.jpg)

图 6.5-数据

1.  为了确保你的模型评估是公平的，对数据进行训练测试是很重要的。你可以用 sklearn 的`train_test_split`做到这一点，如下图:

代码块 6-5

```
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

1.  现在让我们继续讨论逻辑回归模型的应用。以下代码显示了如何一次拟合一个数据点的模型。注意，您应该对`x`的输入数据使用 JSON 转换，因为这是 River 所要求的:

代码块 6-6

```
!pip install river
from river import linear_model
model=linear_model.LogisticRegression()
for x_i,y_i in zip(X_train,y_train):  
    x_json = {'val1': x_i[0], 'val2': x_i[1]}
    print(x_json, y_i)
    model.learn_one(x_json,y_i)
```

打印出来的数据看起来会像这样:

![Figure 6.6 – The output of Code Block 6-6
](img/B18335_06_6.jpg)

图 6.6–代码块 6-6 的输出

1.  您也可以一个接一个地进行预测，或者您可以使用`predict_many`一次对测试集进行所有的预测。结果不会有任何不同。在下面的代码中，使用了`predict_many`:

代码块 6-7

```
import pandas as pd
preds = model.predict_many(pd.DataFrame(X_test,columns=['val1', 'val2']))
```

1.  为了获得这个预测的质量度量，让我们使用`scikit-learn`的准确度分数。正如您在下面的代码块中看到的，该模型在 blob 数据示例上获得了 100%的准确性。必须说明的是，这个 blob 数据示例是一个简单的预测任务，因为数据可以通过直线完全分离，如前面显示的图表所示:

代码块 6-8

```
from sklearn.metrics import accuracy_score
accuracy_score(y_test, preds)
```

这应该产生以下输出:

![Figure 6.7 – The output of Code Block 6-8
](img/B18335_06_7.jpg)

图 6.7–代码块 6-8 的输出

## 分类算法 2–感知器

感知器是针对分类问题进行监督学习的另一种算法。它接受输入，将它们乘以权重，并通过一个激活函数对它们求和。输出是最终的分类。下图显示了一个示例:

![Figure 6.8 – Schematic overview of a perceptron
](img/B18335_06_8.jpg)

图 6.8-感知器的示意图

### 河流中的感知器

像逻辑回归一样，感知器是一个常用的离线模型，它已经被改造成 River 的在线模型。在 River 中，感知器已经被实现为逻辑回归的一个特例。

你可以像逻辑回归一样使用感知器。您可以使用与前一种情况相同的代码示例，如下所示:

代码块 6-9

```
# make data
```

```
from sklearn.datasets import make_blobs
```

```
X,y=make_blobs(shuffle=True,centers=2,n_samples=2000)
```

```
# train test split
```

```
from sklearn.model_selection import train_test_split
```

```
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

```
# build the model
```

```
from river import linear_model
```

```
model=linear_model.Perceptron()
```

```
# fit the model
```

```
for x_i,y_i in zip(X_train,y_train):
```

```
    x_json = {'val1': x_i[0], 'val2': x_i[1]}
```

```
    model.learn_one(x_json,y_i)
```

```
# predict on the test set
```

```
import pandas as pd
```

```
preds = model.predict_many(pd.DataFrame(X_test,columns=['val1', 'val2']))
```

```
# compute accuracy
```

```
from sklearn.metrics import accuracy_score
```

```
accuracy_score(y_test, preds) 
```

结果是`1.0`，不出所料，与逻辑回归结果的相同。

## 分类算法 3–AdaptiveRandomForestClassifier

在介绍中，你已经看到了决策树背后的总体思路。随机森林是改进决策树的集合模型。

随机森林背后的想法是，它们通过制作大量略有不同的决策树来减少单个决策树的错误。大量决策树中最常见的预测被保留为最终预测。

决策树的制作略有不同，方法是将每一棵决策树拟合到一个略有不同的数据集上，该数据集是通过对观测数据进行重采样而创建的。还有一个变量子集用于创建决策树拆分。

### 河流中的随机森林

对于在线学习来说，需要将数据逐个拟合到随机森林中，这并不是一件容易的事情。River 的实现基于随机森林的两个关键元素，即重采样和可变子集。他们还为每个决策树增加了漂移检测:

1.  让我们使用另一个数据创建函数，它创建的数据比 blobs 更难分离。从`sklearn`开始的这个功能被称为`make_classification`:

代码块 6-10

```
# make data
from sklearn.datasets import make_classification
X,y=make_classification(shuffle=True,n_samples=2000)
pd.DataFrame(X).head()
```

数据如下图所示:

![Figure 6.9 – The new data
](img/B18335_06_9.jpg)

图 6.9–新数据

1.  默认情况下总共生成 20 个变量，其中一些会自动变得更加相关，而一些则基本不相关。让我们像之前一样做一个训练测试分割:

代码块 6-11

```
# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

1.  使用这种训练测试分割，我们可以继续构建模型:

代码块 6-12

```
from river import ensemble
model = ensemble.AdaptiveRandomForestClassifier()
# fit the model
for x_i,y_i in zip(X_train,y_train):
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
    model.learn_one(x_json,y_i)
```

1.  既然模型是合适的，我们可以对测试集进行预测。这里没有`predict_many`函数，需要用`predict_one`反复做一个循环:

代码块 6-13

```
# predict on the test set
import pandas as pd
preds = []
for x_i in X_test:
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
    preds.append(model.predict_one(x_json))
```

1.  作为最后的步骤，让我们计算这个模型的准确性:

代码块 6-14

```
# compute accuracy
from sklearn.metrics import accuracy_score
accuracy_score(y_test, preds)
```

1.  结果是`0.86`。当然，数据集更难预测，所以不要被误认为是一个糟糕的分数。作为额外的衡量标准，我们可以查看分类报告以了解更多信息:

代码块 6-15

```
# classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, preds))
```

结果是下图所示的:

![Figure 6.10 – The output of Code Block 6-15
](img/B18335_06_10.jpg)

图 6.10–代码块 6-15 的输出

在这个分类报告中，您可以看到准确率和召回率以及正面和负面的得分都相对相等。这表明分类器中不存在不平衡，这在依赖准确度分数时是重要的。

## 分类算法 4–alma classifier

既然已经看到了一些常用的机器学习模型以适应在线学习的方式进行分类，现在是时候看看一些更具体的模型了。第一个是 ALMA 分类器。

**近似大间隔算法** ( **ALMA** )分类器是分类常用的机器学习模型**支持向量机** ( **SVMs** )的增量实现。

你在前一章看到了支持向量机的改编:单类 SVM 经常用于异常检测。对于分类，您可以使用常规的(两类)SVM。

### 河流中的分类器

让我们看看 ALMAClassifier 如何通过对相同的数据执行来比较和自适应随机森林:

1.  我们从应用之前已经定义的相同代码开始:

代码块 6-16

```
# make data
from sklearn.datasets import make_classification
X,y=make_classification(shuffle=True,n_samples=2000)
# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
from river import linear_model
model = linear_model.ALMAClassifier()
# fit the model
for x_i,y_i in zip(X_train,y_train):
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
    model.learn_one(x_json,y_i) 
# predict on the test set
import pandas as pd
preds = []
for x_i in X_test:
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
    preds.append(model.predict_one(x_json))
# compute accuracy
from sklearn.metrics import accuracy_score
accuracy_score(y_test, preds)
```

1.  结果是`0.77`，不如随机森林。让我们也检查一下分类报告，看看那里是否有什么变化:

代码块 6-17

```
# classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, preds))
```

1.  结果如下图所示:

![Figure 6.11 – The output of Code Block 6-17
](img/B18335_06_11.jpg)

图 6.11–代码块 6-17 的输出

这里有一点更多的变化，但没有什么看起来太令人震惊。总的来说，随机森林对于这些数据来说更好。

## 分类算法 5–PAC classifier

**被动-主动** ( **PA** )分类器是一个在线机器学习模型，与任何现有的离线模型都不相关。它基于在每一步更新模型的想法，从而解决以下问题:

*分类器的更新通过解决约束优化问题来执行:我们希望新的分类器尽可能地接近当前的分类器，同时在最近的例子上实现至少一个单位余量。*

这段引文摘自下面这篇关于 PA 算法的论文，也是进一步阅读的有趣参考:[https://jmlr . csail . MIT . edu/papers/volume 7/crammer 06 a/crammer 06 a . pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf)。

名称*被动-主动*来源于这样一种想法，即从每个新数据点快速学习的算法被认为过于主动。PA 没有那么咄咄逼人。

### 河流分类器

让我们看看 PA 分类器如何执行与前两个模型相同的任务:

代码块 6-18

```
# make data
```

```
from sklearn.datasets import make_classification
```

```
X,y=make_classification(shuffle=True,n_samples=2000)
```

```
# train test split
```

```
from sklearn.model_selection import train_test_split
```

```
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

```
from river import linear_model
```

```
model = linear_model.PAClassifier()
```

```
# fit the model
```

```
for x_i,y_i in zip(X_train,y_train):
```

```
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
```

```
    model.learn_one(x_json,y_i)
```

```
# predict on the test set
```

```
import pandas as pd
```

```
preds = []
```

```
for x_i in X_test:
```

```
    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}
```

```
    preds.append(model.predict_one(x_json))
```

```
# compute accuracy
```

```
from sklearn.metrics import accuracy_score
```

```
accuracy_score(y_test, preds)
```

得到的分数为`0.85`。以下部分总结了我们获得的所有分数。

## 评估基准结果

这给我们留下了过去三个模型的以下准确度分数:

![Table 6.1 – The table with the results
](img/B18335_06_Table_01.jpg)

表 6.1-结果表

AdaptiveRandomForest 获得的最好成绩是，PAClassifier 位居第二。ALMAClassifier 表现较差，得分为`0.77`。

# 总结

在本章中，您首先看到了分类及其使用案例的概述。您已经了解了它与异常检测的不同之处，但是它有时仍然可以应用于异常检测用例。

您已经了解了五种用于在线分类的模型，其中一些主要是离线模型的改编，其他的是专门为在线工作方式设计的。这两种类型都存在，在选择最终模型之前，拥有测试模型性能的工具是很重要的。

您在 Python 中执行的模型基准测试是以这样一种方式完成的，即在测试集上找到模型准确性方面的最佳模型。您已经看到了基准测试模型之间的明显差异，这是模型基准测试重要性的一个很好的展示。

在接下来的章节中，你将会做相同类型的模型基准测试练习，但是这一次，你将会关注于一个回归用例，它的目标与分类有着根本的不同。这带来了关于测量误差和基准的一些变化，但是从一个高层次的角度来看，与您在本章中使用的分类基准用例有许多共同之处。

# 延伸阅读

*   *logistic regression*:[https://river ml . XYZ/latest/API/linear-model/logistic regression/](https://riverml.xyz/latest/api/linear-model/LogisticRegression/)
*   *感知器*:[https://riverml.xyz/latest/api/linear-model/Perceptron/](https://riverml.xyz/latest/api/linear-model/Perceptron/)
*   *AdaptiveRandomForestClassifier*:[https://river ml . XYZ/latest/API/ensemble/AdaptiveRandomForestClassifier/](https://riverml.xyz/latest/api/ensemble/AdaptiveRandomForestClassifier/)
*   *阿尔玛*:[https://riverml.xyz/latest/api/linear-model/ALMAClassifier/](https://riverml.xyz/latest/api/linear-model/ALMAClassifier/)
*   *ALMA*:[https://www . jmlr . org/papers/volume 2/gentile 01 a/gentile 01 a . pdf](https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf
)
*   https://riverml.xyz/latest/api/linear-model/PAClassifier/的*分类器*
*   *p 分类器*:[https://jmlr . csail . MIT . edu/papers/volume 7/crammer 06 a/crammer 06 a . pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf
)
*   *make _ class ification*:[https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . make _ class ification . htm](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.htm
)
*   *make _ blobs*:[https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . make _ blobs . html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)